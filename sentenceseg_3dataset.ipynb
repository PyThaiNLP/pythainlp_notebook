{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG5AWbsciF6b"
   },
   "source": [
    "# CRF-Cut: Sentence Segmentation\n",
    "---\n",
    "This notebook combine 3 datasets (ted, orchid and fake review) to train a model and validate separated datasets\n",
    "\n",
    "The result of CRF-Cut is trained by datasets are as follows:\n",
    "\n",
    "| dataset_train              | dataset_validate | E_f1-score |\n",
    "|----------------------------|------------------|------------|\n",
    "| Ted                        | Ted              | 0.72       |\n",
    "| Orchid                     | Orchid           | 0.77       |\n",
    "| Fake review                | Fake review      | 0.97       |\n",
    "| Ted + Orchid + Fake review | Ted              | 0.72       |\n",
    "| Ted + Orchid + Fake review | Orchid           | 0.69       |\n",
    "| Ted + Orchid + Fake review | Fake review      | 0.97       |\n",
    "\n",
    "We sample 25% from each dataset to train and validate because it does not have memory enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMMkzFSrnEYh",
    "outputId": "3694a9bb-ab03-42f3-8057-905923d0e2de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pythainlp'...\n",
      "remote: Enumerating objects: 18158, done.\u001b[K\n",
      "remote: Counting objects: 100% (1356/1356), done.\u001b[K\n",
      "remote: Compressing objects: 100% (751/751), done.\u001b[K\n",
      "remote: Total 18158 (delta 840), reused 1062 (delta 604), pack-reused 16802\n",
      "Receiving objects: 100% (18158/18158), 47.05 MiB | 23.83 MiB/s, done.\n",
      "Resolving deltas: 100% (12302/12302), done.\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/PyThaiNLP/pythainlp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oazevYonHVQ",
    "outputId": "7bcd538c-faea-44cd-ab40-f27c9dc33248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/pythainlp\n"
     ]
    }
   ],
   "source": [
    "# cd pythainlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install .[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3Q6HPEtLfXYw",
    "outputId": "9eba0611-462a-4e9f-ca8b-41c282cb326c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-crfsuite in /usr/local/lib/python3.6/dist-packages (0.9.7)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "--2021-07-21 15:25:24--  https://raw.githubusercontent.com/vistec-AI/ted_crawler/master/data/orchid_corpus/orchid97.crp.utf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11173797 (11M) [text/plain]\n",
      "Saving to: ‘data/orchid97.crp.utf’\n",
      "\n",
      "orchid97.crp.utf    100%[===================>]  10.66M  9.56MB/s    in 1.1s    \n",
      "\n",
      "2021-07-21 15:25:26 (9.56 MB/s) - ‘data/orchid97.crp.utf’ saved [11173797/11173797]\n",
      "\n",
      "--2021-07-21 15:25:27--  https://github.com/vistec-AI/ted_crawler/raw/master/data/checkpoint/ted_fake.zip\n",
      "Resolving github.com (github.com)... 13.229.188.59\n",
      "Connecting to github.com (github.com)|13.229.188.59|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://github.com/vistec-AI/crfcut/raw/master/data/checkpoint/ted_fake.zip [following]\n",
      "--2021-07-21 15:25:27--  https://github.com/vistec-AI/crfcut/raw/master/data/checkpoint/ted_fake.zip\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/vistec-AI/crfcut/master/data/checkpoint/ted_fake.zip [following]\n",
      "--2021-07-21 15:25:27--  https://raw.githubusercontent.com/vistec-AI/crfcut/master/data/checkpoint/ted_fake.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49723732 (47M) [application/zip]\n",
      "Saving to: ‘data/ted_fake.zip’\n",
      "\n",
      "ted_fake.zip        100%[===================>]  47.42M  45.4MB/s    in 1.0s    \n",
      "\n",
      "2021-07-21 15:25:33 (45.4 MB/s) - ‘data/ted_fake.zip’ saved [49723732/49723732]\n",
      "\n",
      "Archive:  ted_fake.zip\n",
      "  inflating: fake-review-all-sentences.npy  \n",
      "  inflating: ted-all-sentences.npy   \n"
     ]
    }
   ],
   "source": [
    "# uncomment if running from colab\n",
    "!pip install python-crfsuite\n",
    "!mkdir models data\n",
    "!wget -P data https://raw.githubusercontent.com/vistec-AI/ted_crawler/master/data/orchid_corpus/orchid97.crp.utf\n",
    "!wget -P data https://github.com/vistec-AI/ted_crawler/raw/master/data/checkpoint/ted_fake.zip\n",
    "!cd data; unzip ted_fake.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TScUQecyU8MK"
   },
   "outputs": [],
   "source": [
    "#adapted from @bact at https://colab.research.google.com/drive/1hdtmwTXHLrqNmDhDqHnTQGpDVy1aJc4t\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pycrfsuite\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.tag import pos_tag\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_rows', 10)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "uMZ81x1yfN7j",
    "outputId": "367d5d0e-caa8-441d-e605-420564b7e45f"
   },
   "outputs": [],
   "source": [
    "orchid = pd.read_csv('data/orchid97.crp.utf',sep='\\t',header=None)\n",
    "orchid.columns = ['text']\n",
    "#remove weird words\n",
    "orchid['first_char'] = orchid.text.map(lambda x: x[0])\n",
    "orchid = orchid[(orchid.first_char!='%')&(orchid.first_char!='#')][['text']]\n",
    "#get word,pos\n",
    "orchid['word'] = orchid.text.map(lambda x: x.split('/')[0])\n",
    "orchid['word'] = orchid.word.map(lambda x: ' ' if (x=='<space>')|(x=='') else x)\n",
    "orchid['pos'] = orchid.text.map(lambda x: x.split('/')[1] if len(x.split('/'))==2 else None)\n",
    "#labels\n",
    "orchid['lab'] = orchid.apply(lambda row: 'E' if row['text']=='//' else 'I',1)\n",
    "orchid = orchid[(orchid.lab=='E')|(~orchid.pos.isna())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "Ooc2oE7ME9dh",
    "outputId": "f2770e4d-7ec2-4cc7-cb27-10e6e8298444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 487 ms, total: 487 ms\n",
      "Wall time: 486 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ted_all_sentences = np.load('data/ted-all-sentences.npy') \n",
    "fake_review_all_sentences = np.load('data/fake-review-all-sentences.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_IZ7w-6p4mI_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['บนหลังอาชาแห้งกร่องดอนกิโฆเต้ พระเอกของเราบุกตะลุยสู้กับกองทัพยักษ์ |ในสายตาของเขา มันเป็นหน้าที่ของเขาที่จะปราบอสูรร้ายเหล่านี้ในนามแห่งหญิงอันเป็นที่รักของเขา ดุลสิเนอา |ทว่า การกระทำอันหาญกล้านี้ก็สูญเปล่า |เมื่อซานโซ่ ปันซ่า ผู้รับใช้ของเขาอธิบายครั้งแล้วครั้งเล่า ว่าสิ่งเหล่านี้จะเป็นยักษ์ก็หาไม่พวกมันเป็นเพียงกังหันลมเท่านั้น |ดอนกิโฆเต้ หาได้เสียความแน่วแน่แทงทวนของเขาเข้าไปยังใบพัดอย่างจัง |ด้วยพลังใจที่ไม่เคยถดถอยอัศวินผู้นั้นยืนขึ้นอย่างภาคภูมิและยิ่งเชื่อมั่นในปฏิบัติการของเขามากขึ้น |ลำดับเหตุการณ์นี้ครอบคลุมเรื่องราวส่วนใหญ่ของดอนกิโฆเต้ ที่เป็นที่รักมหากาพย์ ไร้ตรรกะ และมีชีวิตชีวาของ อลองโซ กีฆานาผู้กลายเป็น ดอนกิโฆเต้ แห่งลามันช่าผู้ซุ่มซ่ามแต่กล้าหาญหรือที่รู้จักกันในนาม ขุนนางต่ำศักดิ์นักฝัน |แต่เดิมวรรณกรรมนี้มีสองเล่มบรรยายเรื่องราวของดอนกิโฆเต้ในขณะที่เขาเดินทางผ่านตอนกลาง และตอนเหนือของสเปนเพื่อต่อสู้กับบรรดาปิศาจร้าย |แม้จินตนาการในเรื่อง ดอนกิโฆเต้ จะสูงล้ำเหนือเมฆผู้ประพันธ์ มิเกล เด เซร์บันเตสก็ไม่เคยนึกฝันว่าหนังสือของเขาจะกลายเป็นนิยายที่ขายดีที่สุดตลอดกาล |5 ปี ในฐานะทหารและอีก 5 ปีที่ถูกโจรสลัดจับเป็นเชลยเซร์บันเตส ใช้ชีวิตส่วนใหญ่ในฐานะกวีและนักเขียนบทละครตกอับ |จนถึงช่วงปลายยุค 50เขาตีพิมพ์ผลงานที่ยอดเยี่ยมที่สุดของเขานิยายมหากาพย์เสียดสีเกียรติแห่งอัศวิน |ณ เวลานั้นหนังสือในยุคกลางที่บันทึกเรื่องราวการผจญภัยและคติธรรมของอัศวินกำลังเป็นที่นิยมในวัฒนธรรมยุโรป |แม้ว่า เซร์บันเตส จะชื่นชมมันเขาก็เอือมเต็มทนกับเนื้อหาที่ซ้ำซากนั้นที่ให้ความสนใจกับการกระทำแบบวีรบุรุษมากกว่าการพัฒนาตัวละคร |เพื่อท้าทายสิ่งนั้น เขาประพันธ์ดอนกิโฆเต้เรื่องราวของฮิดาลโก หรือขุนนางขี้เกียจผู้ใช้เวลาทั้งวันทั้งคืนอ่านนิยายอัศวิน |ด้วยความคลั่งไคล้เรื่องราวเหล่านี้เขาตั้งตนเป็นผู้พิชิตเพื่อช่วยผู้ถูกกดขี่ |ทุกคนในหมู่บ้านของเขาพยายามโน้มน้าว ให้เขาล้มเลิกเรื่องวิกลจริตนี้จนถึงขั้นเผาหนังสือเก่าเก็บในห้องสมุดส่วนตัวของเขา |แต่ก็ไม่มีใครฉุดดอนกิโฆเต้อยู่ |เขาสวมชุดเกราะวาบวับเก่า ๆขึ้นควบอาชาแห้งกร่องและเผ่นออกจากหมู่บ้าน เพื่อเสาะหาความรุ่งโรจน์ |นิยายของเซร์บันเตสเผยเรื่องราวเป็นตอน ๆที่ให้รายละเอียดเกี่ยวกับ ความพิกลของอัศวินผู้กล้ารายนี้ |นอกจากนี้ สิ่งที่ต่างจาก หนังสือเกี่ยวกับอัศวินและนิยายที่เคยมีมาก่อนหน้านี้เรื่องราวของเซร์บันเตส เจาะลึกลงไปในชีวิตส่วนตัวของตัวละครเอก |ดอนกิโฆเต้ ค่อย ๆ พัฒนาบทบาท เมื่อเรื่องราวดำเนินไปมีการเปลี่ยนแปลงที่เห็นได้ชัด |การค้นพบใหม่ทางวรรณกรรมนี้ทำให้นักวิชาการมากมายกล่าวว่าดอนกิโฆเต้คือนิยายยุคใหม่เรื่องแรก |และพัฒนาการของตัวละครนี้ก็ไม่ได้เกิดขึ้นอย่างเป็นเอกเทศ |ในตอนต้น ดอนกิโฆเต้ได้ชาวบ้านที่ผันตัวมาเป็นผู้ติดตามนามว่า ซานโซ่ ปันซ่า |ซานโซ่ และดอนกิโฆเต้คือกรณีศึกษาที่มีลักษณะตรงข้ามกันคนหนึ่งมีพื้นฐานเป็นคนสมเหตุสมผลอีกคนเป็นยึดถืออุดมการณ์ |มิตรภาพอันสดใสที่ค่อย ๆ เติบโตของพวกเขามักถูกมองว่าเป็นต้นตำรับ ความสัมพันธ์แบบพระเอกและพระรองที่เป็นแรงบันดาลใจให้กับมิตรภาพ ในนิยายต่อมาอีกหลายศตวรรษ |ดอนกิโฆเต้ได้รับความสำเร็จอย่างมาก |มันถูกพิมพ์มากมายหลายครั้ง ไปทั่วทั้งยุโรปในศตวรรษที่สิบเจ็ด |แม้แต่ในทวีปอเมริกาซึ่งศาสนาคริสต์บัญญัติว่านิยายเป็นสิ่งต้องห้ามผู้อ่านก็ยังลักลอบอ่าน |หนังสือได้รับความนิยมอย่างมากจนผู้อ่านเรียกร้องอยากได้อีก |หลังจากนักเขียนคู่แข่งพยายามที่จะสร้างนิยายเลียนแบบเซร์บันเตสก็เขียนภาคต่อออกมา |ตอนนี้ นิยายเล่มสองถูกตีพิมพ์ ด้วยกันกับเล่มแรกเล่าเรื่องราวต่อจากปมที่ทิ้งไว้ทำให้มันเป็นนิยายที่สมบูรณ์เพียงแต่ตอนนี้ ดอนกิโฆเต้และซานโซ่ ได้กลายเป็นวีรบุรุษในตำนาน |เซร์บันเตส นำเอาความสำเร็จ ในโลกแห่งความเป็นจริงไปรวมไว้ในโลกของตัวละครของเขาด้วย |ความเชื่อมโยงที่แปลกนี้สร้างความซับซ้อนทางปรัชญาขึ้นมาเมื่ออัศวินและผู้ติดตามของเราคิดคะนึงถึงความหมายของเรื่องราวตนเอง |น่าเสียดาย ที่เซร์บันเตสขายลิขสิทธิ์การตีพิมพ์หนังสือเล่มนี้ ด้วยราคาที่ถูกมาก |เขาเสียชีวิตรวยแต่เพียงชื่อเสียง |แต่ผลงานที่ทรงพลังความคิดสร้างสรรค์และความมีตัวตนเป็นเอกลักษณ์ ได้ส่งแรงบันดาลใจให้กับศิลปะวรรณกรรมวัฒนธรรมร่วมสมัยแม้กระทั่งการปฎิวัติทางการเมือง |ดอนกิโฆเต้แย้งว่าจินตนาการของเรา ส่งผลต่อการกระทำของเราอย่างยิ่งมันทำให้เรามีศักยภาพที่จะเปลี่ยนแปลงและนั่นเอง ทำให้เราเป็นมนุษย์ ',\n",
       "       'ตอนหนูอายุแปดขวบหนูได้ยินเรื่องการเปลี่ยนแปลงสภาพภูมิอากาศ หรือโลกร้อนเป็นครั้งแรก |แน่ละ ภาวะนี้เกิดจาก การใช้ชีวิตของคนเรานี่เอง |ใครๆ ก็บอกให้หนูปิดไฟ เพื่อประหยัดพลังงานบอกให้รีไซเคิลกระดาษ เพื่อประหยัดทรัพยากร |หนูเคยคิดว่า มันแปลกมากที่คนเรา ซึ่งก็เป็นสัตว์ประเภทหนึ่งจะสามารถเปลี่ยนแปลงสภาพภูมิอากาศของโลกได้ |เพราะถ้าเราทำได้ และถ้า การเปลี่ยนแปลงนี้กำลังเกิดขึ้นจริงเราต้องไม่พูดถึงเรื่องอื่น นอกจากเรื่องนี้ |พอเปิดทีวี ก็จะต้องมีแต่เรื่องนี้ |พาดหัวข่าว วิทยุ หนังสือพิมพ์เราจะไม่ได้อ่านหรือได้ยินเรื่องอื่นๆ เลยเหมือนว่ากำลังเกิดสงครามโลกขึ้น |แต่หนูไม่เห็นมีใครพูดถึงเรื่องนี้เลย |ถ้าการเผาไหม้เชื้อเพลิงฟอสซิลเป็นสิ่งไม่ดี จนคุกคามชีวิตของพวกเราแล้วเรายังทำมันเหมือนเดิมได้ยังไงทำไมไม่มีการควบคุมทำไมถึงไม่ผิดกฎหมายหนูคิดว่ามันไม่มีเหตุผล |ไม่น่าเชื่อเลย |พอหนูอายุ 11 ขวบ ก็เริ่มป่วย |หนูเป็นโรคซึมเศร้าไม่พูดกับใครและไม่กินอะไรเลย |น้ำหนักหนูลดลงไป 10 กิโล ภายในสองเดือน |หมอวินิจฉัยว่าหนูเป็น โรคแอสเพอร์เกอร์ซินโดรมโรคย้ำคิดย้ำทำ  และ ภาวะไม่พูดในบางสถานการณ์ |คือหนูจะพูดเมื่อคิดว่าจำเป็นต้องพูดและตอนนี้หนูว่ามันจำเป็น |พวกเราที่เป็นโรคนี้มักจะตรงไปตรงมา |เราโกหกไม่เก่งและเราก็ไม่ค่อยชอบเข้าสังคมแบบที่พวกคุณดูเหมือนจะชอบ |หนูว่าคนออทิสติกอย่างเรา ก็เป็นคนธรรมดาในหลายๆ เรื่องแต่คนอื่นๆ นั่นแหละที่ออกจะแปลกๆโดยเฉพาะกับเรื่อง วิกฤติการณ์ความยั่งยืนทุกคนพูดว่าการเปลี่ยนแปลงสภาพภูมิอากาศ เป็นสิ่งที่คุกคามชีวิตของพวกเราและเป็นปัญหาที่สำคัญที่สุดแต่ทุกคนก็ยังทำทุกอย่างเหมือนเดิม |หนูไม่เข้าใจเลยเพราะถ้าต้องหยุดการปล่อยมลพิษเราก็ต้องหยุด |หนูว่ามันตรงไปตรงมาเลยละ |ถ้าเป็นเรื่องของความอยู่รอด มันไม่มีความคลุมเครือเลย |ว่าเราจะสร้างความเจริญต่อไปหรือจะหยุด |เราต้องเปลี่ยนแปลง |ประเทศที่ร่ำรวยอย่างสวีเดน ต้องเริ่มลดการปล่อยมลพิษอย่างน้อย 15 เปอร์เซ็นต์ทุกปี |นั่นถึงจะทำให้อุณหภูมิของโลกเพิ่มขึ้น น้อยกว่า 2 องศาเซลเซียสที่ตั้งเป้าไว้ |แต่คณะกรรมการ IPCC เพิ่งจะรายงานว่าการตั้งเป้าที่ 1.5 องศาเซลเซียสจะช่วยลดผลกระทบต่อ สภาพภูมิอากาศได้มากกว่า |แต่เราคงได้แค่จินตนาการ ว่าการลดการปล่อยมลพิษมันเป็นยังไง |เราคงคิดว่าสื่อและผู้นำประเทศของเราทุกคนควรจะต้องพูดกันแต่เรื่องนี้แต่พวกเขาก็ไม่เคยเอ่ยถึง |ไม่เคยมีใครพูดว่าก๊าซเรือนกระจกเกิดขึ้นบนโลกนี้แล้ว |มลพิษทางอากาศกำลังทำให้โลกร้อนขึ้นแม้ว่าเราจะหยุดเผาไหม้เชื้อเพลิงฟอสซิลอุณหภูมิของโลกก็เพิ่มขึ้นมาอีกระดับแล้วอาจจะสูงถึง 0.5 ถึง 1.1 องศาเซลเซียสเลย |แทบไม่มีใครพูดถึงเรื่องที่ว่าเราอยู่ในยุคการสูญพันธุ์ใหญ่ครั้งที่ 6สิ่งที่มีชีวิตถึง 200 ชนิด กำลังสูญพันธุ์ไปทุกๆ วันอัตราการสูญพันธุ์วันนี้อยู่ระหว่าง 1,000 ถึง 10,000 เท่าเทียบกับอัตราปกติ |แทบไม่มีใครพูดในมุมของความเท่าเทียม หรือความเป็นธรรมทางภูมิอากาศที่พูดถึงอยู่มากมายในความตกลงปารีสและจำเป็นที่ต้องทำให้สำเร็จในระดับโลก |นั่นหมายความว่าประเทศที่ร่ำรวยทั้งหลายต้องหยุดปล่อยมลพิษภายใน 6 ถึง 12 ปีด้วยอัตราการปล่อยมลพิษทุกวันนี้ |เพื่อให้คนในประเทศที่ยากจนกว่ามีโอกาสยกระดับมาตรฐานการใช้ชีวิตให้สูงขึ้นโดยสร้างสาธารณูปโภคพื้นฐาน ที่เรามีอยู่แล้วเช่น ถนน โรงเรียน โรงพยาบาลน้ำดื่มสะอาด ไฟฟ้า และอื่นๆ อีกมากมาย |เราไม่ควรคาดหวังให้ ประเทศอย่างอินเดียหรือไนจีเรียสนใจเรื่องการเปลี่ยนแปลงสภาพภูมิอากาศถ้าแม้แต่เราที่มีทุกอย่างพร้อม ยังไม่สนใจเรื่องนี้หรือเรื่องข้อผูกพันของเรา ในความตกลงปารีสเลยสักนิดอย่างนี้แล้ว ทำไมเราไม่ลดการปล่อยมลพิษยังกลับเพิ่มขึ้นด้วยซ้ำเรากำลังทำให้เกิดการสูญพันธุ์ครั้งใหญ่เหรอเราเป็นคนเลวจริงเหรอเปล่า ไม่ใช่เลย |คนเราทำสิ่งที่ทำอยู่ไปเรื่อยๆเพราะคนส่วนใหญ่ไม่รู้เลยว่าสิ่งที่ทำมีผลต่อชีวิตประจำวันยังไงและไม่รู้ว่าต้องเปลี่ยนแปลงทันที |เราคิดว่าเรารู้ และคิดว่าทุกๆ คนก็รู้แต่จริงๆ แล้วเราไม่รู้หรอก |จะรู้ได้ยังไงล่ะถ้ามีวิกฤติการณ์จริงๆและวิกฤติการณ์นี้เกิดจากการปล่อยมลพิษเราก็น่าจะได้เห็นสัญญาณอะไรบ้าง |ไม่ใช่แค่น้ำท่วมเมือง คนหลายหมื่นคนล้มตายซากตึกถล่มกองทับถมเต็มเมือง |เราน่าจะได้เห็นการควบคุมบ้าง |แต่ไม่เลย |ไม่มีใครพูดถึงเรื่องนี้เลย |ไม่มีการเรียกประชุมด่วน ไม่มีพาดหัวข่าว หรือ ข่าวด่วนอะไรเลย |ไม่มีใครลงมือทำอะไรที่ควร จะทำถ้าเราอยู่ในขั้นวิกฤต |แม้แต่นักภูมิศาสตร์หรือ นักการเมืองที่เป็นนักอนุรักษ์ยังไม่หยุดบินไปบินมารอบโลก ยังคงกินเนื้อและผลผลิตจากสัตว์ |ถ้าหนูอยู่ถึง 100 ปี หนูจะยังมีชีวิตอยู่ในปี 2103 |เวลาที่เราพูดถึงอนาคต เราจะไม่นึกไกลไปกว่าปี 2050 |ถ้าโชคดี เมื่อถึงเวลานั้น หนูยังใช้ชึวิตไม่ถึงครึ่งชึวิตด้วยซ้ำ |แล้วจะเกิดอะไรขึ้นพอถึงปี 2078 หนูก็จะฉลองวันเกิดครบ 75 ปี |ถ้าหนูมีลูกหลาน พวกเขาคงอยู่ฉลองกับหนู |พวกเขาอาจจะถามหนูเรื่องพวกคุณพวกคุณที่มีชึวิตอยู่ในปี 2018 |พวกเขาอาจจะถามว่าทำไมพวกคุณไม่ทำอะไรเลยในขณะที่ยังมีเวลาพอทำได้ |สิ่งที่เราทำหรือไม่ทำตอนนี้ จะส่งผลต่อชีวิตหนูในอนาคตและชีวิตของลูกหลานหนูด้วย |สิ่งที่เราทำหรือไม่ทำตอนนี้ในอนาคต หนูและลูกหลานหนูจะแก้ไขมันไม่ได้ |พอโรงเรียนเปิดเมื่อเดือนสิงหาคมนี้หนูเลยตัดสินใจว่าพอกันที |หนูไปนั่งอยู่หน้ารัฐสภาสวีเดน |หยุดเรียนประท้วงให้กับสภาพภูมิอากาศ |บางคนบอกว่าหนูควรไปเรียนจะดีกว่า |บางคนบอกว่าหนูควรเรียนเป็นนักภูมิศาสตร์จะได้ \"แก้ปัญหาวิกฤติการณ์สภาพภูมิอากาศ\"แต่วิกฤติการณ์นี้แก้ไขได้แล้ว |เรามีข้อมูลและทางออกอยู่แล้ว |สิ่งที่เราต้องทำก็คือลุกขึ้นมาเปลี่ยนแปลง |แล้วทำไมหนูต้องเรียน เพื่ออนาคตที่ไม่มีวันมาถึงทั้งๆ ที่ไม่มีใครทำอะไรเพื่ออนาคตเลยแล้วมันจะมีประโยชน์อะไร ที่จะเรียนในระบบโรงเรียนเมื่อความรู้ที่สำคัญที่สุดที่ได้มาจากวิทยาศาสตร์อันแสนวิเศษ จากระบบโรงเรียนเดียวกันนี้ไม่ได้มีความหมายอะไรเลย กับนักการเมืองและสังคมของเรา |บางคนบอกว่าสวีเดนเป็นแค่ประเทศเล็กๆสิ่งที่เราทำไม่มีประโยชน์อะไรแต่หนูคิดว่าถ้าเด็กแค่ไม่กี่คน สามารถเป็นข่าวไปทั่วโลกได้แค่หยุดโรงเรียนเพียงไม่กี่อาทิตย์ลองคิดดูว่าเราทุกคนจะสามารถทำอะไรได้บ้าง ถ้าเราตั้งใจทำจริงๆ |เอาละค่ะ หนูใกล้จะพูดจบแล้วและตอนนี้มักจะเป็นตอนที่เราพูดถึงความหวังไม่ว่าจะเป็น แผงโซล่าร์เซลล์ พลังงานลม เศรษฐกิจหมุนเวียน และอื่นๆ อีกมากมายแต่หนูจะไม่พูดหรอก |เราใช้เวลา 30 ปีพูดให้กำลังใจกัน ขายฝันต่างๆ นานา |เสียใจด้วยค่ะ มันไม่มีประโยชน์เลย |ถ้ามันมีประโยชน์จริงการปล่อยมลพิษคงจะหมดไปนานแล้ว |แต่ไม่ใช่เลย |ใช่ค่ะ เราต้องการความหวังเราต้องการมันแน่นอน |แต่ที่เราต้องการมากกว่าความหวัง ก็คือการลงมือทำ |เมื่อเราเริ่มลงมือทำ ความหวังก็จะเกิดขึ้น |แทนที่จะเฝ้ารอความหวังลงมือทำเสียเลยดีกว่า |และเมื่อนั้น ความหวังก็จะเกิดขึ้นเอง |ในแต่ละวัน เราใช้น้ำมันดิบ 100 ล้านบาร์เรล |ไม่มีนโยบายการเมืองไหนคิดจะเปลี่ยนมัน |ไม่มีกฎให้เก็บรักษาน้ำมันดิบไว้ใต้ดิน |เราเลยแก้ปัญหาไม่ได้ถ้ามัวแต่ทำตามกฎเพราะกฎก็ต้องเปลี่ยน |ทุกอย่างต้องเปลี่ยนแปลงและต้องเริ่มเดี๋ยวนี้ |ขอบคุณค่ะ ',\n",
       "       'ณ เวลานี้ขณะที่เรากำลังหายใจอยู่นี้มหานครหลายแห่งทั่วโลกซึ่ง ตั้งอยู่แถบสามเหลี่ยมปากแม่น้ำ กำลังจมลงซึ่งรวมถึง นิวยอร์ค ลอนดอนโตเกียว เซี่ยงไฮ้ นิวออลีนส์และกรุงเทพมหานคร ซึ่งเป็นบ้านเกิดของฉัน |นี่คือรูปแบบปกติ ของการเปลี่ยนแปลงภูมิอากาศ |นี่คือแบบของฉัน |ก็ไม่มีอะไรมากแค่มีจระเข้อยู่บนถนนเท่านั้นเอง |นี่คือผลกระทบฉับพลัน ของภูมิอากาศที่เปลี่ยนแปลงบนเมืองที่กำลังจมค่ะ |ภาพนี้ คุณจะเห็น การขยายตัวของกรุงเทพฯในทุกทิศทางจากเมืองการเกษตรบนผืนดินที่สามารถหายใจ และดูดซับน้ำได้กลายเป็นป่าคอนกรีต |นี่คือสภาพของเมืองบางส่วน หลังจากฝนตกเพียง 30 นาที |และทุกครั้งที่ฝนตกฉันอยากให้รถของฉันกลายร่างเป็นเรือได้ |ในผืนดินนี้ ไม่มีที่รองรับน้ำอีกต่อไป |มันสูญเสียความสามารถในการดูดซับน้ำ |ความเป็นจริงของอาณาเขต มหานครกรุงเทพฯคือเมืองที่คนกว่า 15 ล้านคนอยู่อาศัย ทำงาน และเดินทาง บนผืนดินเลนปากแม่น้ำ |กรุงเทพฯ กำลังจมลง มากกว่าหนึ่งเซนติเมตรต่อปีซึ่งเร็วเป็นสี่เท่า ของระดับน้ำทะเล ที่คาดการณ์ว่าจะเพิ่มขึ้น |และพวกเราอาจอยู่ใต้น้ำกันภายในปี ค.ศ. 2030ซึ่งคงมาถึงอีกไม่นาน |มันไม่ใช่เรื่องบังเอิญ ที่ขณะนี้ฉันเป็นภูมิสถาปนิก |ตอนฉันยังเด็ก ฉันเติบโตอยู่ในตึกแถวติดกับถนนอันแสนวุ่นวาย ที่การจราจรคับคั่งตลอดเวลา |หน้าบ้านของฉัน เป็นลานจอดรถคอนกรีต และนั่นคือสนามเด็กเล่นของฉัน |สิ่งมีชีวิตเดียวที่ฉันเจอและเล่นสนุกด้วยได้คือเจ้าต้นไม้น้อย ๆ ที่พยายาม เติบโตผ่านรอยแตกร้าวของพื้นคอนกรีต |เกมโปรดของฉันกับเพื่อนคือการเล่นขุดรูผ่านรอยแตกนี้ ให้ใหญ่ขึ้น ใหญ่ขึ้นเพื่อให้เจ้าต้นไม้น้อยคืบคลานได้มากยิ่งขึ้น |และภูมิสถาปัตยกรรมคือโอกาสการสานต่อ ความปรารถนาอันแรงกล้าในการสร้างรอยแตกนั่นเพื่อเชื่อมต่อพื้นคอนกรีตนี้ ให้ผสานกับธรรมชาติ |แต่ก่อน ชาวไทย คนประเทศฉันวิธีชีวิตเราปรับเปลี่ยนไปกับฤดูฝน และฤดูแล้งคุณอาจเรียกเราว่าพวกสะเทิ้นน้ำสะเทินบก |พวกเราอาศัยอยู่ทั้งบนพื้นดิน ในในท้องน้ำ |เราปรับตัวกับสองรูปแบบนี้ได้ |และน้ำท่วมคือช่วงเวลาความสุข น้ำนำพาความอุดมสมบูรณ์มาสู่ผืนดินของเรา |แต่ปัจจุบัน น้ำท่วมคือ |หายนะ |ในปี ค.ศ. 2011ประเทศไทยถูกกระหน่ำจากอุทกภัยที่รุนแรง และมีมูลค่าความสูญเสียมากที่สุดในประวัติศาสตร์ |อุทกภัยนี้เปลี่ยนภาคกลางของไทยให้กลายเป็น ทะเลสาปสุดลูกหูลูกตา |ตรงกลางของภาพนี้ คุณคงเห็นพื้นที่น้ำท่วมและขนาดของกรุงเทพฯ ในกรอบสีเหลือง |น้ำไหลบ่ามาจากทางเหนือไหลมาเรื่อย ๆ ผ่านหลายจังหวัด |คนหลายล้านในประเทศของฉันรวมถึงฉันและครอบครัวด้วยต้องพลัดถิ่น และเป็นคนไร้บ้าน |บ้างก็หนีออกจากเมือง |บางคนกลัวการสูญเสียบ้าน และสิ่งของต่าง ๆพวกเขาจึงทนอยู่กับน้ำท่วม โดยไม่มีไฟฟ้า และน้ำสะอาด |สำหรับฉันแล้ว น้ำท่วมครั้งนี้ ได้สะท้อนชัดเจนว่าโครงสร้างพื้นฐานสมัยใหม่ของเราและโดยเฉพาะความคิดของเรา ที่จะต่อสู้กับน้ำท่วมด้วยคอนกรีตทำให้เราเปราะบางที่สุด ต่อความไม่แน่นอนของภูมิอากาศ |แต่ใจกลางหายนะนี้ฉันเจอเสียงเรียกภายในของฉัน |ที่ฉันไม่สามารถนั่งนิ่งเฉย ในขณะที่เมืองของฉันกำลังจมไปเรื่อย ๆ |เมืองนี้ต้องการฉันและฉันก็มีความสามารถ ที่จะแก้ปัญหานี้ได้ |หกปีที่แล้วฉันได้เริ่มโครงการ |ทีมงานและฉันได้ชนะการประกวดออกแบบ อุทยาน 100 ปี จุฬาลงกรณ์มหาวิทยาลัย |นี่คือภารกิจชิ้นใหญ่และหาญกล้า ของมหาวิทยาลัยแห่งแรกของประเทศไทยในการเฉลิมฉลองครบรอบ 100 ปีโดยการมอบพื้นที่แห่งนี้ ให้เป็นสวนสาธารณะของเมืองเรา |การมีสวนสาธารณะฟังดูธรรมดา สำหรับเมืองอื่น ๆแต่ไม่ใช่กับกรุงเทพฯเมืองที่มีพื้นที่สาธารณะสีเขียวต่อประชากร ต่ำที่สุดเมืองหนึ่งในบรรดาเมืองใหญ่ในทวีปเอเชีย |โครงการของพวกเรากลายเป็น สวนสาธารณะแห่งใหม่ในรอบเกือบ 30 ปี |สวนพื้นที่ 28 ไร่รอยแตกสีเขียวรอยใหญ่ ใจกลางกรุงเทพฯได้เปิดตัวขึ้นเมื่อปีที่แล้ว |ขอบคุณค่ะ |กว่าสี่ปี ที่พวกเราผลักดัน ผ่านการประชุมนับครั้งไม่ถ้วนเพื่อโน้มน้าว และไม่ยอมแพ้ ในการโน้มน้าวว่าสวนแห่งนี้ไม่ใช่เพื่อความสวยงาม หรือการพักผ่อนเท่านั้นมันต้องช่วยเมืองรับมือกับน้ำช่วยเมืองเผชิญหน้ากับ การเปลี่ยนแปลงภูมิอากาศด้วย |และนี่คือการทำงานของสวนแห่งนี้ค่ะ |กรุงเทพฯ เป็นเมืองบนที่ราบดังนั้นเราจึงควบคุมแรงโน้มถ่วง โดยการเอียงสวนทั้งหมดเพื่อรวมน้ำฝนทุกหยด |แรงโน้มถ่วงจะช่วยให้น้ำ ไหลจากจุดสูงสุดลงสู่จุดต่ำสุด |ส่วนแห่งนี้มีองค์ประกอบหลักสามประการ ที่ทำงานเป็นระบบเดียวกัน |ส่วนแแรก หลังคาสีเขียว |ซึ่งเป็นหลังคาสีเขียวที่ใหญ่ที่สุด ในประเทศไทยที่มีถังเก็บน้ำฝนหลายใบ และพิพิธภัณฑ์อยู่ข้างใต้ |ในช่วงฤดูแล้งน้ำฝนที่เก็บไว้นั้น สามารถใช้ดูแลรดน้ำในอุทยานได้ถึงหนึ่งเดือน |น้ำที่ไหลจากหลังคาสีเขียว ไหลลงสู่พื้นที่ชุ่มน้ำที่มีพืชน้ำพื้นถิ่น คอยช่วยกรองและทำความสะอาดน้ำ |และในส่วนที่ต่ำที่สุดเป็นบ่อเก็บน้ำ |บ่อน้ำแห่งนี้ มีจักรยานน้ำ |คนสามารถปั่น เพื่อช่วยทำความสะอาดน้ำได้ |ซึ่งการออกกำลังกายของพวกเขากลายเป็น องค์ประกอบเชิงรุกของระบบจัดการน้ำในสวน |เมื่อชีวิตให้น้ำมาซะท่วมเราก็สนุกกับน้ำซะเลย |อุทยาน 100 ปีให้พื้นที่ทั้งกับคน และกับน้ำซึ่งเป็นสิ่งที่พวกเราและเมืองต้องการ อย่างแท้จริง |นี่คือการออกแบบ ที่เผชิญทั้งสภาวะเปียกและแห้ง |อุทยานแห่งนี้ไม่ได้กำจัดน้ำท่วมออกไป |แต่เป็นการสร้างวิถีอยู่ร่วมกับมันต่างหาก |และไม่มีฝนแม้แต่หยดเดียว ในอุทยานแห่งนี้ที่สูญเปล่า |อุทยานแห่งนี้สามารถกักและเก็บ น้ำกว่าล้านแกลลอนได้ค่ะ |ขอบคุณค่ะ |ทุกโครงการที่ได้รับมอบหมาย มันคือโอกาสสำหรับฉันที่จะสร้างรอยแตกสีเขียวเพิ่ม ผ่านป่าคอนกรีตด้วยการใช้ภูมิสถาปัตยกรรมในการแก้ปัญหาเหมือนกับการเปลี่ยนหลังคาคอนกรีตนี้ เป็นพื้นที่เกษตรในเมืองที่ช่วยดูดซับน้ำฝนบรรเทาปรากฎการณ์เกาะร้อนและปลูกพืชผักกินได้ ที่ใจกลางเมืองนำโครงสร้างคอนกรีตรกร้างกลับมาใช้ใหม่เปลี่ยนให้เป็นสะพานคนเดินสีเขียวและหลังคาสีเขียวกันน้ำท่วมอีกแห่ง ที่มหาวิทยาลัยธรรมศาสตร์ซึ่งเกือบจะเป็นหลังคาสีเขียวที่ใหญ่สุด ในสถานศึกษาของเอเซียตะวันออกเฉียงใต้ |อุทกภัยร้ายแรงเป็นเรื่องปกติใหม่ของเราที่ทำให้ภูมิภาคเอเซียตะวันออกเฉียงใต้ภูมิภาคที่มีชายฝั่งมากที่สุดอยู่ในภาวะเสี่ยงอย่างสูง |การสร้างสวนสาธารณะเป็นแค่หนึ่งทางแก้ |การตระหนักรู้สภาพอากาศที่เปลี่ยนไปคือสิ่งที่พวกเราทุกคน ทุกสายอาชีพ ต้องร่วมมือต้องถือเป็นภาระ ที่จะเข้าใจความเสี่ยงจากภูมิอากาศและนำสิ่งที่เรากำลังทำ ไปเป็นส่วนหนึ่งของการแก้ปัญหา |เพราะถ้าเมืองของพวกเรายังคงดำเนินไปอย่างที่เป็นอยู่นี้ภัยพิบัติที่เกิดขึ้นแล้ว ก็จะเกิดขึ้นซ้ำอีก |ซ้ำอีก |การสร้างทางแก้ไขปัญหา ของเมืองที่กำลังจมนี้คือการสร้างสิ่งที่เป็นไปไม่ได้ให้เป็นไปได้ |และด้วยเหตุนี้ฉันอยากจะแบ่งปันคำหนึ่ง ที่ฉันยึดถือไว้ในใจเสมอมาก็คือ \"ตั้งใจ\"แปลแบบตรงตัวคือ \"ตั้ง\" แปลว่า การยืนอย่างมั่นคงและ \"ใจ\" หมายถึง หัวใจการ ตั้ง ใจเรา ไว้ที่ จุดมุ่งหมาย |ในภาษาไทย เมื่อคุณ มุ่งมั่นที่จะทำอะไรบางอย่างคุณจะนำคำว่า ตั้งใจ ไว้หน้าคำนั้นเพื่อที่ใจของคุณ จะได้อยู่กับการกระทำนั้น |ไม่ว่าเส้นทางมันจะยากแค่ไหนอุปสรรคจะยิ่งใหญ่แค่ไหนคุณจะผลักดันไปถึงจุดหมายของคุณเพราะนั่นคือที่ที่หัวใจคุณตั้งอยู่ |และใช่ ประเทศไทยคือบ้าน |ผืนแผ่นดินนี้คือบ้านหลังเดียวของฉันและนั่นคือที่ที่ใจฉันตั้งมั่น |แล้วใจคุณละคะ ตั้งอยู่ที่ใดขอบคุณค่ะ |ขอบคุณค่ะ |ขอบคุณค่ะ ',\n",
       "       ...,\n",
       "       'ราว 10 ปีก่อน ผมได้รับงานสอนวิชา global developmentให้กับนักศึกษาปริญญาตรีชาวสวีเดน ซึ่งเป็นช่วงหลังจากที่ผมได้ใช้เวลา |ประมาณ 20 ปี ร่วมกับสถาบันในแอฟริกาเพื่อศึกษาเรื่องความอดอยากในแอฟริกา ผมจึงคาดหวังว่า จะรู้เรื่องเกี่ยวกับโลกบ้างและผมได้เริ่มทำงานที่มหาวิทยาลัยแพทย์ Karolinska Institute ของเรา |ภาควิชาปริญญาตรีที่ชื่อ Global Health แต่เมื่อคุณมีโอกาสนั้น |คุณจะรู้สึกประหม่าอยู่บ้าง ผมคิดว่านักศึกษาเหล่านี้ที่เข้ามาเรียนที่มหาวิทยาลัยของเรา มีผลการเรียนสูงสุด |ในระบบวิทยาลัยของสวีเดน พวกเขาน่าจะมีความรู้เต็มเปี่ยม |ในเรื่องที่ผมจะสอนพวกเขา ผมจึงได้ทำการทดสอบเมื่อพวกเขามาถึงและหนึ่งในคำถามที่ผม ได้เรียนรู้อย่างมากก็คือคำถามนี้\"ประเทศใดในห้าคู่นี้มีอัตราการเสียชีวิต ของเด็กมากว่าคู่ของตน\" |แล้วผมผมก็จับคู่ประเทศ เพื่อให้แต่ละคู่ของประเทศนั้น |มีประเทศหนึ่งที่มีอัตราการเสียชีวิตของเด็ก มากว่าคู่ของตนเป็นสองเท่าตัวหมายความว่า มีความแตกต่าง มากกว่าความไม่แน่นอนของข้อมูลผมจะเฉลยให้เลยว่าคือประเทศตุรกีซึ่งมีอัตราสูงสุด รวมถึงโปแลนด์ รัสเซีย ปากีสถาน และ แอฟริกาใต้ |และนี่เป็นผลการทดสอบ ของนักศึกษาชาวสวีเดน ซึ่งทำให้ผมได้ช่วงความเชื่อมั่นของข้อมูล ซึ่งค่อนข้างแคบ และผมก็ดีใจ |แน่นอน มีการตอบถูก 1.8 ข้อ จากความน่าจะเป็น 5 ข้อ ซึ่งหมายความว่ามีตำแหน่งสำหรับศาสตราจารย์สอนภาควิชา international health -- | และสำหรับวิชาของผม |แต่กลางดึกคืนหนึ่ง เมื่อผมทำการรวบรวมรายงาน |ผมได้ตระหนักถึงสิ่งที่ผมค้นพบจริงๆ ผมพบว่า |นักศึกษาชาวสวีเดนระดับชั้นนำนั้น รู้เกี่ยวกับโลกในเชิงสถิติน้อยกว่าลิงชิมแปนซีอย่างมากมาย |เพราะว่าลิงชิมแปนซี จะตอบถูกสักครึ่งหนึ่งหากผมให้กล้วย 2 ใบกับศรีลังกาและตุรกี ลิงคงจะตอบถูกซักครึ่งหนึ่ง |แต่นักเรียนตอบได้ไม่ถึงครึ่ง สำหรับผมแล้วปัญหาไม่ใช่ความไม่รู้แต่เป็นเพราะความเชื่อผิดๆ |ผมยังได้ทำการศึกษาที่ผิดหลักศีลธรรม เกี่ยวกับศาสตราจารย์ที่ Karolinska Institute-- ซึ่งเป็นผู้มอบรางวัลโนเบลสาขาอายุรศาสตร์ |ซึ่งพวกเขาก็อยู่ในระดับเดียวกับชิมแปนซี | |สิ่งนี้ทำให้ผมรู้ว่า มีความจำเป็นที่จะต้องสื่อสารกันอย่างจริงจังเพราะข้อมูลของสิ่งที่กำลังเกิดขึ้นในโลกนี้และสุขภาพของเด็กๆ ในทุกๆ ประเทศนั้น เป็นเรื่องสามัญที่ทุกคนรู้เราพัฒนาโปรแกรมนี้ซึ่งแสดงผลออกมาดังนี้ วงกลมแต่ละวงคือประเทศ |ประเทศตรงนี้คือประเทศจีน ตรงนี้คือประเทศอินเดียขนาดของวงกลมคือจำนวนประชากร และบนแกนนี้ผมใส่อัตราการเจริญพันธุ์เนื่องจากนักศึกษาของผม สิ่งที่พวกเขาพูดเมื่อพวกเขามองดูโลก แล้วผมได้ถามพวกเขาว่า\"คุณมีความคิดยังไงเกี่ยวกับโลก\" |อันดับแรก ผมได้ค้นพบว่าตำราเรียน ก็คือหนังสือการ์ตูนดีๆ นี่เอง | |แล้วพวกเขาตอบว่า \"โลกนี้ยังคงแบ่งเป็น \"เรา\" กับ \"เขา\" |เราคือประเทศโลกตะวันตก และเขาคือประเทศโลกที่สาม |ผมถามว่า \"ประเทศโลกตะวันตกที่คุณว่ามันคืออะไร\"\"ก็คือประเทศที่มีอายุยืนและมีครอบครัวเล็ก ส่วนประเทศโลกที่สามมีอายุสั้นและครอบครัวใหญ่\" |นี่คือสิ่งที่ผมแสดงได้ที่นี่ ผมจัดอัตราการเจริญพันธุ์ ไว้ที่นี่: จำนวนเด็กต่อผู้หญิงหนึ่งคนจำนวนเด็ก 1 2 3 4 สูงถึง 8 คน ต่อผู้หญิงหนึ่งคนเรามีข้อมูลที่ดีมากตั้งแต่ปี 1962 – 1960 ในเรื่องขนาดของครอบครัวในทุกประเทศข้อมูลที่ผิดพลาดมีน้อย ผมใส่อายุขัยเฉลี่ยไว้ที่แกนนี้ |ตั้งแต่ 30 ปีในบางประเทศ จนถึง 70 ปีและในปี 1962 จริงๆ แล้ว มีกลุ่มประเทศอยู่ตรงนี้เป็นประเทศอุตสาหกรรม และมีครอบครัวขนาดเล็กและมีอายุยืนและประเทศเหล่านี้คือประเทศที่กำลังพัฒนา |พวกเขามีครอบครัวที่ใหญ่ และมีอายุค่อนข้างสั้น |มีอะไรเกิดขึ้นหลังนับจากปี 1962 เราต้องการจะเห็นความเปลี่ยนแปลงนักศึกษาพูดได้ถูกต้องหรือไม่ ยังมีกลุ่มประเทศ 2 แบบอยู่หรือไม่ |หรือประเทศที่กำลังพัฒนาเหล่านี้ มีครอบครัวเล็กลง และอยู่ตรงนี้หรือพวกเขามีอายุยืนยาวขึ้น และย้ายมาอยู่ตรงนั้นมาดูกัน เราหยุดโลกไว้ที่นี่ นี่คือสถิติทั้งหมดของสหประชาชาติ |ที่มีอยู่ เอาล่ะ คุณเห็นมั้ยประเทศจีนอยู่นั้น เคลื่อนที่ สู่ความมีสุขภาพดีตรงนั้น พัฒนาขึ้นตรงนั้น |ประเทศลาตินอเมริกาสีเขียวทั้งหมด กำลังเคลื่อนไปสู่ครอบครัวที่เล็กลง |และสีเหลืองทางนี้คือกลุ่มประเทศอาหรับพวกเขามีครอบครัวที่ใหญ่ขึ้น ไม่สิ พวกเขามีชีวิตยืนยาวขึ้น แต่ไม่มีครอบครัวใหญ่ขึ้น |กลุ่มประเทศแอฟริกาคือวงกลมสีเขียว ข้างล่างนี้ พวกเขายังคงอยู่ที่นี่นี่คืออินเดีย ส่วนอินโดเนเซีย นั้นเคลื่อนไหวค่อนข้างเร็ว |และในยุค 80 นี้ประเทศบังคลาเทศยังคงอยู่ ในส่วนเดียวกับกลุ่มประเทศแอฟริกาทางนั้น |แต่ตอนนี้ ประเทศบังคลาเทศ ได้เกิดปาฏิหาริย์ขึ้นในช่วงทศวรรษที่ 80 |โต๊ะอิหม่ามเริ่มสนับสนุนการวางแผนครอบครัว |พวกเขาขยับไปอยู่ที่มุมนั่น และในช่วงทศวรรษ ที่ 90 เรามีการระบาดร้ายแรงของเชื้อ HIVซึ่งลดค่าอายุขัยเฉลี่ย ของกลุ่มประเทศแอฟริกาลงและประเทศอื่นๆ ก็ขยับขึ้นไปสู่หัวมุมที่เรามีอายุยืนและมีครอบครัวเล็ก แล้วเราก็ มีโลกใบใหม่ที่แตกต่างไปจากเดิมโดยสิ้นเชิง | |ขอให้ผมทำการเปรียบเทียบโดยตรง ระหว่างสหรัฐอเมริกาและเวียตนามในปี 1964 อเมริกา มีครอบครัวเล็กและมีชีวิตยืนยาว |เวียตนามมีครอบครัวใหญ่และมีชีวิตสั้น และนี่คือสิ่งที่เกิดขึ้น |ข้อมูลในช่วงสงครามบ่งบอกว่า แม้จะมีจำนวนคนตายทั้งหมดมากแต่มีการพัฒนาของอายุขัยเฉลี่ย ในช่วงท้ายของปี |การวางแผนครอบครัวได้เริ่มต้นขึ้นในเวียตนาม และพวกเขามีครอบครัวที่เล็กลง |และสหรัฐข้างบนนั้นเริ่มมีอายุยืนยาวขึ้น |ด้วยการควบคุมขนาดครอบครัว และในยุค 80 |พวกเขาเลิกการวางแผนแบบคอมมิวนิสต์ และเริ่มเข้าสู่เศรษฐกิจการตลาดและระบบเคลื่อนที่เร็วกว่าชีวิตทางสังคม และในปัจจุบันนี้ เรามีอายุขัยเฉลี่ยและขนาดครอบครัว |ในเวียตนาม ปี 2003 นี้เ ท่ากับในสหรัฐฯ ปี 1974 ช่วงสงครามสิ้นสุดผมคิดว่าเราทุกคน -- หากไม่ดูข้อมูลแล้ว -- |เราประเมินการเปลี่ยนแปลง ขนานใหญ่ในเอเชียต่ำเกินไป ซึ่งมีการเปลี่ยนทางสังคมก่อนที่เรา จะเห็นการเปลี่ยนทางเศรษฐกิจลองไปอีกวิธีการหนึ่งทางนี้ ที่เราสามารถแสดง |การกระจายรายได้ในโลก นี่คือ การกระจายรายได้ของประชากรในโลก1 ดอลลาร์ 10 ดอลลาร์ หรือ 100 ดอลลาร์ ต่อวันไม่มีช่องว่างระหว่างคนจนกับคนรวยอีกต่อไป ความเชื่อนี้เป็นแค่ตำนานมีเนินอยู่ตรงนี้ แต่ทั้งหมดนี้คือผู้คนทั้งหมด |และถ้าเราดูที่ๆ รายได้ตกอยู่ -- รายได้ --นี่คือรายได้ต่อปีของทั้งโลก 100% และคนรวยที่สุด 20%ซึ่งมีรายได้เป็น 74% ของรายได้ทั้งโลก และคนจนที่สุดจำนวน 20% |มีรายได้เป็น 2% ของรายได้ทั้งโลก ซึ่งแสดงให้เห็นว่าหลักการ |ของประเทศที่กำลังพัฒนานั้นไม่น่าเป็นไปได้ ซึ่งเราคิดถึงการให้ความช่วยเหลือเช่นคนส่วนนี้ให้ความช่วยเหลือคนตรงส่วนนี้ แต่ในระหว่างกลาง |เรามีประชากรของโลกมากที่สุด และพวกเขา มีรายได้เป็น 24% ของรายได้ทั้งโลกเราเคยได้ยินในรูปแบบอื่น และคนเหล่านี้เป็นใครกัน |อยู่ในประเทศใดบ้าง ผมสามารถแสดงแอฟริกาให้คุณดูได้นี่คือแอฟริกา มีจำนวนประชากรเป็น 10% ของโลกส่วนใหญ่อยู่ในความยากจน |นี่คือ OECD ประเทศที่ร่ำรวย สโมสรของสหประชาชาติพวกเขาอยู่ด้านนี้ มีความเหลื่อมล้ำกัน อย่างมากระหว่างแอฟริกากับ OECDและนี่คือลาตินอเมริกา ซึ่งมีทุกสิ่งทุกอย่างบนโลกนี้ |จากผู้คนที่จนที่สุดถึงผู้คนที่รวยที่สุด ในลาตินอเมริกาและนอกเหนือจากนั้น เราสามารถ ใส่ยุโรปตะวันออก และเอเชียตะวันออกแล้วเราใส่เอเชียใต้เข้าไป และเมื่อเรา ย้อนไปในอดีตแล้วจะเป็นอย่างไรถึงช่วงปี 1970 ตอนนั้นเนินจะค่อนข้างสูงกว่า |และเราเห็นว่าคนจนสาหัสส่วนใหญ่ คือชาวเอเชียปัญหาของโลกคือความยากจนในเอเชีย และหากผมปล่อยให้เวลาในโลกผ่านไปคุณจะเห็นว่าในขณะที่จำนวนประชากรเพิ่มขึ้น จะมี |ประชากรกว่าร้อยล้านคนในเอเชีย ที่พ้นจากความยากจน และบางรายเข้าสู่ความยากจน และนี่คือรูปแบบ ที่เรามีอยู่ในปัจจุบันและการคาดการณ์ที่ดีที่สุดจากธนาคารโลก ก็คือ สิ่งนี้จะเกิดขึ้น |และเราจะไม่มีโลกที่ถูกแบ่งแยก เราจะมีโลกที่ผู้คนส่วนใหญ่อยู่ตรงกลาง |แน่นอนนี่คือการวัดระดับแบบลอการิธึ่ม |แต่แนวคิดด้านเศรษฐกิจของเราคือ การเติบโตพร้อมเปอร์เซ็นต์ เมื่อเราดูข้อมูล |ในฐานะความเป็นไปได้ของการเพิ่มเปอร์เซ็นต์ ถ้าผมเปลี่ยนตรงนี้ แล้ว |เอาค่า GDP ต่อหัวแทนที่จะใช้รายได้ครอบครัว แลัวผมเปลี่ยน |ข้อมูลของแต่ละคนไปเป็นข้อมูลระดับภูมิภาค ของผลิตภัณฑ์มวลรวมภายในประเทศและนำภูมิภาคนี้มาไว้ที่นี่ ขนาดของวงกลม ยังคงเป็นจำนวนประชากรอยู่ |คุณมีกลุ่มประเทศ OECD ตรงนั้น แล้วมีกลุ่ม ประเทศแอฟริกาต่อจากทะเลทรายซาฮาร่าตรงนั้นและเราแบ่งชาติอาหรับออกมาไว้ตรงนั้น |ซึ่งมาจากทั้งแอฟริกาและเอเชีย แล้วเราเอาไปไว้แยกต่างหาก |เราสามารถขยายแกนนี้ได้ แล้วผมจะเพิ่มมิติใหม่ที่ตรงนี้โดยการเพิ่มคุณค่าทางสังคมตรงนั้น คืออัตราการรอดชีวิตของเด็ก |ตอนนี้ ผมมีเงินอยู่บนแกนนั้น และมีความ เป็นไปได้ของการรอดชีวิตของเด็กตรงนั้นในบางประเทศ มีอัตราการรอดชีวิต ของเด็กจนกระทั่งอายุได้ 5 ปี สูงถึง 99.7% |ส่วนประเทศอื่นมีเพียง 70 และดูหมือนจะมีช่องว่างอยู่ตรงนี้ระหว่าง OECD ลาตินอเมริกา ยุโรปตะวันออก เอเชียตะวันออก |ชาติอาหรับ เอเชียใต้ และกลุ่มประเทศแอฟริกา ต่อจากทะเลทรายซาฮาร่า |ค่าความคลาดเคลื่อนเชิงเส้นระหว่าง อัตราการรอดชีวิตของเด็กและเงินค่อนข้างชัดเจนแต่เมื่อผมลองแยกกลุ่มประเทศแอฟริกา ต่อจากทะเลทรายซาฮาร่าออก ซึ่งมีสุขภาพที่ดีตรงนั้นผมไปที่นี่ แล้วแยกกกลุ่มประเทศแอฟริกาต่อจากทะเลทรายซาฮาร่าออกเป็นแต่ละประเทศ |ซึ่งเมื่อแตกออก ขนาดของวงกลมประจำประเทศ คือขนาดของจำนวนประชากร |ประเทศเซียร์ราลีโอนอยู่ข้างล่างนี้ มอริเทียสอยู่บนนั้น มอริเทียสเป็นประเทศแรกที่รอดพ้นจากการกีดกั้นการค้า และพวกเขาสามารถขายน้ำตาลได้ |พวกเขาสามารถขายสินค้าสิ่งทอได้ในข้อตกลง ที่เท่าเทียมกับผู้คนในยุโรปและในอเมริกาเหนือ |มีความแตกต่างใหญ่หลวงระหว่างประเทศในแอฟริกา และมีประเทศกาน่าอยู่ตรงกลาง |ในเซียร์ราลีโอน ความช่วยเหลือด้านมนุษยธรรม |ในอูกานด้า การช่วยเหลือด้านการพัฒนา เหมาะแก่การลงทุนตรงนั้นกลายเป็นประเทศท่องเที่ยวไป มีความแตกต่างมหาศาล |ภายในแอฟริกาซึ่งเราไม่ค่อยจะทำ นั่นคือ เท่าเทียมกันทุกอย่างผมแยกเอเชียใต้ตรงนี้ อินเดียคือวงกลมใหญ่ตรงกลาง |แต่ความแตกต่างอย่างมากระหว่าง ประเทศอัฟกานิสถานและประเทศศรีลังกาผมสามารถแยกชาติอาหรับออกจากกัน พวกเขาเป็นอย่างไร ภูมิอากาศแบบเดียวกันวัฒนธรรมเดียวกันศาสนาเดียวกัน แต่มีความแตกต่างกันมาก แม้กระทั่งระหว่างประเทศเพื่อนบ้าน |ในประเทศเยเมน เกิดสงครามกลางเมือง สหรัฐอาหรับเอมิเรตส์ มีเงินระดับเท่าๆ กันและนำไปใช้อย่างฉลาด |ต่างจากในความเชื่อ และนั่นรวมถึงลูกๆ ของคนงานต่างด้าวที่อยู่ในประเทศด้วย |ข้อมูลมักจะดีกว่าที่คุณคิด หลายๆ คน บอกว่าข้อมูลเป็นสิ่งไม่ดีมันมีช่วงข้อมูลที่ไม่แน่นอน แต่เรา ก็สามารถเห็นความแตกต่างได้ดังนี้กัมพูชา สิงคโปร์ มีความแตกต่างมากกว่าความอ่อนแอของข้อมูล ทางด้านยุโรปตะวันออกเศรษฐกิจของโซเวียตเป็นเวลานาน แต่พวกเขาก็หลุดพ้นออกมาหลังจาก 10 ปี |แตกต่างจากเดิมมากๆ ส่วนนี่คือลาตินอเมริกาในปัจจุบันเราไม่ต้องไปถึงคิวบา เพื่อหาประเทศที่มีสุขภาพดีในลาตินอเมริกาชิลีจะมีอัตราการเสียชีวิตของเด็ก ต่ำกว่าคิวบาในอีกไม่กี่ปีข้างหน้า |และที่นี่เรามีประเทศที่มีรายได้สูงในกลุ่ม OECD |แล้วเราก็จะได้รูปแบบของทั้งโลกมาซึ่งไม่น่าต่างจากที่นี่เท่าไหร่ และเมื่อเราดู |ว่าเป็นอย่างไร ในช่วงปี 1960 เริ่มมีการเปลี่ยนแปลง 1960 |นี่คือประธานเหมาเจ๋อตง เขานำสุขภาพที่ดี มาสู่จีนหลังจากนั้นเขาก็ตายไปหลังจากนั้น เติ้งเสี่ยวผิงเข้ามาดำรงตำแหน่ง และนำความมั่งคั่งมาสู่จีน และพาจีนเข้าสู่เวทีโลกอีกครั้งและเราได้เห็นประเทศที่เคลื่อนไป ในทิศทางที่แตกต่างกันแบบนี้ซึ่งทำให้เป็นการยากที่จะยกตัวอย่างประเทศที่แสดงรูปแบบของโลก |ผมขอพาคุณกลับมาที่นี่ ประมาณปี 1960ผมอยากเปรียบเทียบเกาหลีใต้ ซึ่งก็คือตรงนี้ กับบราซิลซึ่งคืออันนี้ สลากอยู่ห่างจากผมมาก แล้วผมอยากจะเปรียบเทียบอูกานด้าซึ่งอยู่ตรงนั้น แล้วพอผมเร่งเวลาต่อไปแบบนี้คุณจะเห็นได้ว่าเกาหลี มีความก้าวหน้าอย่างรวดเร็วมากในขณะที่บราซิลจะช้ากว่ามาก |และหากเราย้อนกลับมาอีกครั้ง ตรงนี้ แล้วเราลองจับตาการเคลื่อนไหวของพวกเขาแบบนี้คุณจะเห็นอีกครั้งว่าความเร็วของการพัฒนา |นั้นต่างกันมาก และทั้ง 2 ประเทศเคลื่อนที่ไปในในอัตราที่ค่อนข้างเหมือนกันในด้านเงิน และสุขภาพ แต่ดูเหมือนว่าคุณจะ |เคลื่อนได้เร็วกว่า หากคุณมีสุขภาพดี ก่อนแทนที่จะมีความร่ำรวยก่อนและเพื่อแสดงให้เห็น คุณสามารถใช้วิธีเดียวกัน กับสหรัฐอาหรับเอมิเรตส์พวกเขามาจากจุดนี้ โดยที่เป็นประเทศ ผู้ส่งออกแร่ และส่งออกน้ำมัน |พวกเขาร่ำรวย แต่สุขภาพไม่สามารถ หาซื้อได้จากซุปเปอร์มาเก็ต |คุณต้องลงทุนในเรื่องสุขภาพ คุณต้องให้การศึกษาแก่เด็กๆ |คุณต้องฝึกพนักงานดูแลสุขภาพ คุณต้องให้การศึกษาแก่ประชากร |และ Sheikh Sayed ก็ทำได้ดีเลยทีเดียว |และถึงแม้ว่ามีราคาน้ำมันที่ตกลง เขาก็พาประเทศของเขาขึ้นมาอยู่ที่นี่ดังนั้น เราได้มีรูปแบบหลักในโลกมากขึ้น |เมื่อทุกประเทศมักจะใช้เงินงบประมาณ |ได้ดีกว่าที่พวกเขาเคยใช้มาในอดีต ซึ่งในปัจจุบันก็ไม่แตกต่างกันมากเมื่อคุณดูที่ข้อมูลเฉลี่ยของประเทศ ข้อมูลจะเป็นแบบนี้นี่เป็นสิ่งอันตรายมากที่จะใช้ข้อมูลเฉลี่ย เพราะมีความแตกต่าง |มากภายในประเทศเหล่านั้น ดังนั้นถ้าผมดูที่นี่ เราจะเห็น |ว่าอูกานด้าในปัจจุบันอยู่ในตำแหน่ง ที่เกาหลีใต้เคยอยู่เมื่อปี 1960 และหากผม |แยกอูกานด้าออกก็จะเห็นความแตกต่างมากภาย ในอูกานด้า นี่คือลำดับชั้นของเศรษฐานะของอูกานด้า |กลุ่มประขากรที่ร่ำร่วยที่สุดจำนวน 20% ของอูกานด้าอยู่นั่น |กลุ่มที่จนที่สุดอยู่ที่นี่ หากผมแยก แอฟริกาใต้ออกจะเป็นอย่างนี้ |และหากลงไปดูไนเจอร์ ซึ่งมึความอดอยากแร้งแค้นมากท้ายที่สุด จะเป็นแบบนี้ กลุ่มที่ยากจน ในไนเจอร์จำนวน 20% อยู่ตรงโน้น |และ 20% ที่รวยที่สุดของแอฟริกาใต้จะอยู่ที่นั่น |แต่เรามักจะอภิปรายกันถึงวิธีแก้ไขปัญหาในแอฟริกา |แอฟริกามีทุกอย่างในโลกนี้ และคุณไม่สามารถปรึกษาถึงการแจกจ่ายยาสำหรับโรค HIV สำหรับลำดับชั้นของเศรษฐานะบนนี้ |ด้วยยุทธศาตร์เดียวกันกับที่ด้านล่างนี้ การพัฒนาของโลกต้องทำแบบดูตามความเป็นจริงโดยละเอียด และไม่ถูกต้องที่จะทำในระดับภูมิภาค เราจะต้องลงลึก ในรายละเอียดมากกว่านั้น |เราพบว่านักศึกษาตื่นเต้นมาก เมื่อมีโอกาสได้ใช้สิ่งนี้ |โดยเฉพาะนักวางแผนนโยบาย และกลุ่มธุรกิจก็อยากที่จะเห็นว่าโลกกำลังเปลี่ยนแปลงไปอย่างไร แล้วทำไมมันถึงไม่เกิดขึ้น |ทำไมเราถึงไม่ใช้ข้อมูลที่เรามี เรามีข้อมูลอยู่ในสหประชาชาติ |ในสำนักสถิติแห่งชาติและในมหาวิทยาลัยและองค์กรเอกชนอื่นๆ |เพราะว่าข้อมูลถูกซ่อนลึกอยู่ในฐานข้อมูล |เรามีสาธารณชนและอินเตอร์เน็ตแล้ว แต่เราไม่ได้ใช้สิ่งเหล่านี้อย่างเต็มประสิทธิภาพข้อมูลที่เราได้เห็นที่เปลี่ยนแปลงในโลก |ยังไม่รวมถึงข้อมูลทางสถิติที่สาธารณะ ให้การสนับสนุน มีหน้าเว็บไซต์บางหน้า |เช่นหน้านี้ แต่ข้อมูลได้รับการหล่อเลี้ยง มาจากฐานข้อมูลแต่พวกเขากลับตั้งราคากับข้อมูล รหัสผ่านที่งี่เง่า และข้อมูลสถิติที่น่าเบื่อ |  |และวิธีนี้ไม่ได้ผล แล้วอะไรคือ สิ่งที่จำเป็นล่ะ เรามีฐานข้อมูล |คุณไม่ต้องการฐานข้อมูลใหม่ เรามีเครื่องมือช่วยออกแบบที่วิเศษและหลายๆ สิ่งถูกเพิ่มเข้าไป เราจึงได้เริ่ม |การลงทุนที่ไม่หวังผลกำไรที่เราเรียกว่า เชื่อมข้อมูลเข้ากับการออกแบบ --เราเรียกว่า Gapminder ได้ชื่อมาจาก รถไฟใต้ดินของลอนดอนซึ่งเขาเตือนคุณว่า |\"mind the gap\" ซึ่งเราคิดว่า Gapminder เหมาะสมดี |เราได้เริ่มพัฒนาซอฟท์แวร์ที่สามารถ เชื่อมโยงข้อมูลได้แบบนี้ |ไม่ได้เป็นการยากนัก แต่เราต้องใช้เวลาเป็นปีๆ และเราได้ทำสื่ออนิเมชั่นคุณสามารถนำชุดข้อมูลมาไว้ที่นี่ |เราปลดปล่อยข้อมูลของสหประชาชาติ องค์กรของสหประชาชาติบางแห่งบางประเทศยินยอมว่าฐานข้อมูล ของเขาสามารถออกสูสายตาชาวโลกได้แต่สิ่งที่เราต้องการจริงๆ คือ ฟังชั่นการหาข้อมูล |ฟังชั่นการหาข้อมูลที่เราสามารถคัดลอกข้อมูล ได้ถึงรูปแบบที่สามารถทำการหาได้ |และเผยแพร่ข้อมูลสู่โลก และเมื่อเราลองไปถามความเห็นจากแหล่งข้อมูลต่างๆผมได้ทำการศึกษาทางมนุษยวิทยา กับหน่วยสถิติหลัก ทุกคนพูดว่า |\"เป็นไปไม่ได้ ไม่สามารถทำได้ ข้อมูลของเรานั้นเฉพาะเจาะจง |ในรายละเอียดอย่างมาก จึงไม่สามารถ ทำการค้นหาเหมือนอย่างข้อมูลอื่นๆ ได้ |เราไม่สามารถให้ข้อมูลฟรีแก่นักศึกษา แก่ผู้ประกอบการของโลกได้\" |แต่นี่คือสิ่งที่เราอยากจะเห็นใช่ไหมข้อมูลสถิติที่สาธารณะสนับสนุน ทุนจะอยู่ข้างล่างนี้ |และเราอยากให้ดอกไม้แห่งความรู้ เจริญงอกงามในอินเตอร์เน็ตและหนึ่งในสิ่งสำคัญยิ่งคือการที่จะ ทำให้ข้อมูลถูกค้นหาได้ จากนั้นผู้คนสามารถใช้เครื่องมือออกแบบที่แตกต่างกัน เพื่อแสดงข้อมูลแบบนั้นและผมมีข่าวดีมากมาบอกคุณ ผมมีข่าวดีว่าในตอนนี้หัวหน้ากองสถิติของสหประชาขาติ ไม่ได้บอกว่าเป็นไปไม่ได้เขาแค่บอกว่า \"เราไม่สามารถทำได้\" |ต้องนับว่าเขาเป็นคนฉลาดมากคนหนึ่งเลย ใช่ไหม | |ดังนั้น เราจะเห็นสิ่งที่เกิดขึ้นมากมาย กับข้อมูลในอนาคตอันใกล้เราจะสามารถดูการกระจายรายได้ ในวิธีที่ใหม่โดยสิ้นเชิง |นี่คือการกระจายรายได้ของจีนในปี 1970 |การกระจายรายได้ของสหรัฐฯ ในปี 1970 |แทบจะไม่มีการเหลื่อมล้ำกันเลย แล้วได้เกิดอะไรขึ้น |สิ่งที่เกิดขึ้นคือ จีนกำลังเจริญเติบโต ไม่ได้เท่าเทียมกันอีกต่อไป |และได้มาปรากฏอยู่ตรงนี้ คอยตามหลังสหรัฐฯ ไปเหมือนผีเลยว่ามั้ย |มันค่อนข้างน่ากลัว แต่ผมคิดว่า การมีข้อมูลทั้งหมดนี้เป็นสิ่งสำคัญเราจำเป็นต้องดูข้อมูลจริงๆ และแทนที่จะดูที่นี่ |ในที่สุด ผมอยากจะแสดงต่อ ผู้ใช้งานอินเตอร์เน็ตนับพันในซอฟท์แวร์นี้ เราเข้าถึงตัวแปรประมาณ 500 ตัว จากประเทศทั้งหมดได้อย่างง่ายดาย |ถึงจะใช้เวลาพอสมควรในการเปลี่ยนแต่บนแกนเหล่านี้ คุณสามารถจะได้ตัวแปรใดๆ ที่ต้องการได้ค่อนข้างง่ายดีเดียว |โดยการตั้งฐานข้อมูลที่เข้าถึงได้ฟรี |การทำให้ฐานข้อมูลสามารถถูกค้นหาได้ และด้วยการคลิกครั้งที่สอง |จะนำมาอยู่ในรูปแบบกราฟิกที่คุณ สามารถเข้าใจข้อมูลได้ทันที |นักสถิติกลับไม่ชอบวิธีนี้ เพราะพวกเขาบอกว่า |วิธีนี้จะไม่แสดงความเป็นจริง เราจำเป็น ต้องมีกรรมวิธีวิเคราะห์ข้อมูลทางสถิติ |แต่นี่เป็นการสร้างข้อมูลสมมุติฐานผมจะจบด้วยโลกของเรา ตรงนั้น อินเตอร์เน็ตกำลังมาจำนวนผู้ใช้อินเตอร์เน็ตเพิ่มขึ้นแบบนี้ และนี่คือ GDP ของประชากรต่อหัว |และเป็นเทคโนโลยีแบบใหม่ที่เข้ามา แต่ก็น่าแปลกใจที่เทคโนโลยีนี้เข้ากันได้กับเศรษฐกิจของประเทศ เพราะฉะนั้น คอมพิวเตอร์ราคาประหยัดจึงมีความสำคัญมาก แต่ก็ถือเป็นแนวโน้มที่ดี |เหมือนกับว่าโลกแบนลงใช่ไหม ประเทศเหล่านี้ |พัฒนามากกว่าเพียงด้านเศรษฐกิจ และเป็นสิ่งน่าสนใจอย่างยิ่งที่จะติดตามสถานการณ์ในปีต่อไป ซึ่งผมอยากทำได้ด้วยข้อมูลที่สาธารณะออกทุน ขอบคุณทุกคนมากครับ ',\n",
       "       'สวัสดีครับ เป็นอย่างไรกันบ้าง? เยี่ยมไปเลยใช่มั้ยล่ะครับ? ผมน่ะ ประทับใจมากเลย |ผมก็เลยจะกลับแล้วล่ะ เห็นด้วยไหมครับว่ามีแนวคิดอยู่ 3 รูปแบบ |ในการสัมนาครั้งนี้ ซึ่งเกี่ยวข้องกับ |สิ่งที่ผมกำลังจะพูดถึงต่อไปเรื่องแรกคือ หลักฐานที่มหัศจรรย์เกี่ยวกับความคิดสร้างสรรค์ของมนุษย์ในการนำเสนอทั้งหมดที่เราได้รับทราบมา |และในตัวของทุกๆ ท่าน ที่อยู่ ณ ที่นี้ มันช่างหลากหลายและกว้างไกลเหลือเกินครับ และเรื่องที่สองก็คือความคิดสร้างสรรค์ได้นำพวกเราไปสู่ที่แห่งหนึ่ง ที่เราไม่สามารถรู้ได้เลยว่าจะมีอะไรเกิดขึ้นในอนาคต ไม่รู้เลยจริงๆ |ว่ามันจะเป็นอย่างไรผมมีความสนใจในเรื่องการศึกษาที่จริงแล้ว ผมพบว่า ทุกๆ คน มีความสนใจในเรื่องของการศึกษา |จริงไหมครับ น่าสนใจนะครับ |สมมติว่าคุณอยู่ในงานเลี้ยงอาหารค่ำ แล้วคุณพูดว่า |คุณทำงานด้านการศึกษา |ทั้งที่จริง ถ้าคุณทำงานในแวดวงการศึกษา คุณจะไม่ค่อยได้อยู่ในงานเลี้ยงอาหารค่ำบ่อยนักหรอก คือว่าคุณจะไม่ได้รับเชิญตั้งแต่แรกน่ะ |ประหลาดนะครับ คุณไม่แย้งผมด้วยเอาเป็นว่าถ้าคุณได้รับเชิญไปงาน แล้วคุยกับคนอื่นๆ ในงาน |เกิดมีคนถามคุณว่า \"คุณทำงานอะไร\"แล้วคุณตอบว่า ผมทำงานด้านการศึกษา |คุณจะเห็นว่า หน้าพวกเขาจะซีดลงทันที พวกเค้าจะคิดในใจว่าโธ่ ซวยจริง ๆ ทำไมต้องเป็นฉันด้วย ค่ำคืนแห่งอิสระภาพของฉันในอาทิตย์นี้  |แต่ถ้าคุณถามเกี่ยวกับการศึกษาของพวกเขาเค้าจะตอบมาเป็นฉากๆ เลยครับ เพราะว่าการศึกษาเป็นเรื่องที่คนยึดถืออย่างลึกซึ้ง จริงไหมครับ?เหมือนกับเรื่องของศาสนา ความร่ำรวย และอีกหลายๆ เรื่อง |ผมมีความสนใจอย่างมากในเรื่องของการศึกษา และผมคิดว่าทุกคนก็คงเหมือนกันพวกเราสนใจมันส่วนหนึ่งเป็นเพราะว่า การศึกษา คือสิ่งที่จะนำเราไปสู่อนาคตที่เราคาดไม่ถึงลองคิดดูซิครับ เด็กที่เริ่มเข้าโรงเรียนในปีนี้ จะเกษียณอายุในปี 2065 ไม่มีใครรู้เลยครับแม้แต่บรรดาผู้เชี่ยวชาญทั้งหลายที่มาร่วมในการสัมนาช่วง 4 วันที่ผ่านมา |ไม่รู้เลยครับว่าโลกจะเป็นอย่างไร |แม้แต่ในอีก 5 ปีข้างหน้า และพวกเรานั่นแหละที่จะต้องสอนเด็กๆ ให้รับมือกับสิ่งที่จะมาถึง ดังนั้น ผมคิดว่าความยากที่จะคาดเดานั้นมันยิ่งใหญ่เหลือเกิน |และแนวคิดสุดท้าย แนวคิดที่สามก็คือพวกเราทุกคนเห็นด้วย ใช่ไหมครับว่า |เด็กๆ มีความสามารถที่วิเศษความสามารถของพวกเขาในเรื่องของนวัตกรรม ดูจากเด็กหญิง Sirena เมื่อคืนนี้ซิครับ เธอเป็นสาวน้อยมหัศจรรย์จริงๆใช่มั๊ยครับ ในสิ่งที่เธอสามารถทำได้ |เธอทำได้เยี่ยมไปเลยครับ แต่ผมก็ยังคิดว่าเธอคงไม่ได้ |เก่งไปทั้งหมดในเรื่องของวัยเด็ก |แต่สิ่งที่พวกเราได้เห็นคือ คนที่มีความมุ่งมั่นเป็นเลิศคือคนที่หาความสามารถเฉพาะตัวของตนเองเจอ ข้อโต้แย้งของผมก็คือผมคิดว่า เด็กทุกคน มีความสามารถเฉพาะตัว |แต่พวกเรากลับทำลายมันอย่างน่าเสียดายดังนั้น วันนี้ ผมอยากจะพูดถึง การศึกษา และ |ความคิดสร้างสรรค์ ความคิดที่ผมต้องการนำเสนอคือความคิดสร้างสรรค์นั้นมีความสำคัญในด้านการศึกษาพอๆ กับการรู้หนังสือ |และเราควรที่จะให้ความสำคัญกับมันอย่างเท่าเทียมกัน ขอบคุณครับ อันที่จริงก็เท่านั้นล่ะครับ |ขอบคุณมากครับ  เอาล่ะ เหลืออีก 15 นาทีอืม ตอนที่ผมเกิด....ไ่ม่ล่ะ  |เมื่อไม่นานมานี้ผมได้ยินเรื่องๆ หนึ่ง ที่ผมชอบที่จะเล่าต่อให้กับคนอื่นๆ ฟังมันเป็นเรื่องเกี่ยวกับเด็กผู้หญิงอายุ 6 ขวบ คนหนึ่งในชั่วโมงศิลปะ |เธอนั่งวาดรูปอยู่หลังห้องคุณครูของเธอบอกว่า |เด็กผู้หญิงคนนี้ไม่เคยให้ความสนใจในสิ่งใดๆ เลย นอกจากในชั่วโมงศิลปะของวันนี้คุณครูรู้สึกประหลาดใจมาก จึงเดินเข้าไปหาเด็กน้อย |แล้วถามเธอว่า \"หนูกำลังวาดอะไรอยู่จ๊ะ\"เด็กน้อยตอบว่า \"หนูกำลังวาดรูปของพระเจ้าค่ะ\" |แล้วคุณครูก็ถามต่อว่า \"แต่ว่าไม่มีใครรู้นะจ๊ะว่าพระเจ้าหน้าตาเป็นยังไง\"เด็กผู้หญิงคนนั้นก็ตอบว่า \"อีกแป๊บนึงพวกเค้าก็จะรู้แล้วล่ะค่ะ\" |ตอนที่ลูกชายของผมอายุ 4 ขวบ ในอังกฤษอืม อันที่จริงแล้วเขาก็อายุ 4 ขวบ ไม่ว่าจะอยู่ที่ไหนแหละครับ ถ้าจะพูดให้ถูกต้องแล้ว ไม่ว่าเขาจะไปที่ไหนในปีนั้น เขาก็อายุ 4 ขวบเขาได้ร่วมแสดงในการแสดงเกี่ยวกับวันประสูติของพระเยซู |คุณจำเรื่องราวได้ไหมครับ มันเป็นเรื่องที่ยิ่งใหญ่มากนะครับเมล กิ๊บสัน ถึงขั้นทำภาคต่อเลยทีเดียวคุณคงเคยได้ชมแล้ว \"กำเนิดพระเยซู ภาค 2\" เจมส์ ลูกชายของผม ได้เล่นเป็น โจเซฟ |ซึ่งพวกเราตื่นเต้นกันมาก |เราถือว่านี่เขาเป็นหนึ่งในนักแสดงนำเลยทีเดียวตอนไปดูเรายกทีมกันใส่เสื้อยืดที่สกรีนว่า\"เจมส์ โรบินสัน เป็น โจเซฟ\" เขาไม่มีบทพูดเลยครับ แต่คุณก็คงรู้ว่าเค้าบทเป็นอย่างไรตอนที่กษัตริย์ 3 พระองค์ เดินทางมาถึง พวกเขานำของขวัญมาด้วยซึ่งได้แก่ ทอง ยางสนที่มีกลิ่นหอม และ น้ำมันหอมเรื่องนี้เกิดขึ้นจริงครับ พวกเรานั่งดูอยู่ที่นั่น |ผมคิดว่าเกิดการผิดคิวกันเกิดขึ้นเพราะว่าเราคุยกับเด็กผู้ชายคนหนึ่งหลังจากที่ตัวละครเดินเข้ามาบนเวที เราถามเขาว่า |\"หนูว่านี่โอเคมั๊ย\" เด็กน้อยตอบว่า \"ครับ ทำไมเหรอครับ?\" \"มีอะไรผิดปกติเหรอครับ\"พวกเขาแค่ยืนสลับที่กันอย่างไรก็ตาม เด็กชายสามคนเดินเข้ามาบนเวที |เด็กอายุ 4 ขวบ ที่มีผ้าเช็ดจานวางอยู่บนศีรษะ |แล้วพวกเขาก็วางกล่องของขวัญลงเด็กชายคนแรกพูดว่า \"ข้านำทองมาให้เจ้า\"เด็กชายคนที่สองพูดว่า \"ข้านำน้ำมันหอม มาให้เจ้า\" |แล้วเด็กชายคนสุดท้ายก็พูดว่า \"อันนี้แฟรงค์ส่งมา\"  |ทั้งสองเรื่องที่ผมเล่ามา มีสิ่งที่เหมือนกันคือ เด็กทุกคนกล้าที่จะลองถึงพวกเขาจะไม่รู้ พวกเขาก็จะลองดูจริงไหมครับ? เด็กไม่กลัวที่จะทำผิดพลาดเอาล่ะ แต่นี่ผมไม่ได้หมายความว่าการทำผิดพลาด เป็นสิ่งเดียวกันกับการมีความคิดสร้างสรรค์นะครับแต่เราทุกคนทราบว่า |ถ้าหากเราไม่พร้อมยอมรับกับการกระทำที่ผิดพลาด |เราจะไม่มีวันสร้างสรรค์สิ่งที่แปลกใหม่ขึ้นมาได้ถ้าเราไม่พร้อมยอมรับกับการทำผิดพลาด และรู้ไหมครับว่าเมื่อเวลาที่เด็กๆ โตเป็นผู้ใหญ่เด็กส่วนใหญ่สูญเสียความสามารถในการยอมรับความผิดพลาดพวกเขาจะกลายเป็นมีความเกรงกลัวต่อการทำผิดพลาด |คิดดูซิ พวกเราบริหารบริษัทแบบนี้ |แบบที่เราทำให้การทำผิดพลาดเป็นเรื่องคอขาดบาดตาย และตอนนี้เราก็บริหารระบบการศึกษาแบบที่ยอมรับความผิดพลาดไม่ได้ด้วยการทำผิด กลายเป็นเรื่องเลวร้ายที่สุด ที่คุณจะสามารถทำได้ดังนั้น ผลของมันก็คือ เรากำลังให้การศึกษาแก่คน เพื่อให้ละทิ้งความสามารถในด้านความคิดสร้างสรรค์ |ครั้งหนึ่ง ปิกัสโซ่  เคยกล่าวไว้ว่า เด็กทุกคนเกิดมาเป็นศิลปิน |ปัญหาก็คือ จะทำอย่างไรให้ความเป็นศิลปินนั้นยังคงอยู่เมื่อเราโตเป็นผู้ใหญ่ |ผมเชื่ีอเป็นอย่างยิ่งว่า พวกเราไม่ได้มีความคิดสร้างสรรค์มากขึ้นตามการเจริญเติบโต |แต่พวกเรากลับมีลดน้องถอยลง ตามอายุที่มากขึ้น หรืออาจจะพูดได้ว่า พวกเราได้รับการศึกษาให้มีความถดถอยด้านความคิดสร้างสรรค์มันเป็นอย่างนี้ไปได้อย่างไรล่ะ?ผมอาศัยอยู่ที่เมือง Stratford-on- Avon เมื่อ 5 ปีก่อน |หลังจากนั้น ครอบครัวเราก็ได้ย้ายย้ายจาก Stratford มาที่ Los Angeles |ลองจินตนาการดูซิครับว่า มันเป็นการเปลี่ยนแปลงจากหน้ามือเป็นหลังมือขนาดไหน | จริงๆ แล้ว |พวกเราอยู่ในเมืองที่เรียกว่า Snitterfield |ซึ่งอยู่ในรอบนอกของ Stratford มันเป็นสถานที่ที่เป็นบ้านเกิดของคุณพ่อของ Shakespeare คุณได้ยินอย่างนี้เกิดความคิดอย่างหนึ่งขึ้นรึเปล่า? ผมเป็นนะ |คุณไม่เคยคิดว่า Shakespeare มีพ่อใช่ไหมครับจริงไหม คุณคงไม่เคยคิดถึงว่า |Shakespeare ตอนเป็นเด็ก ใช่ไหมครับ? |Shakespeare อายุ 7 ขวบ เหรอ? ผมไม่เคยคิดถึงหรอก แต่จริงๆ แล้ว |ณ ช่วงเวลาหนึ่ง เขาเคยอายุ 7 ขวบเขาเคยเรียนอยู่ในวิชาภาษาอังกฤษของครูสักคนหนึ่ง ใชไหมครับ? มันจะน่ารำคาญสักแค่ไหนน๊า? | ครูของเขาคงจะเขียนรายงานผลการเรียนว่า\"ต้องพยายามมากกว่านี้\" หรืออย่างตอนที่พ่อของ Shakespeare ส่งเขาเข้านอน |\"ไปนอนได้แล้ว\"\"วางดินสอลง |แล้วก็หยุดพูดแบบนี้ซะที มันทำให้คนอื่นเค้าสับสนกันไปหมด\" | |เอาล่ะครับ กลับมาเข้าเรื่อง ก็คือครอบครัวของผมย้ายจากเมือง Stratford มาที่ Los Angelesที่ผมอยากจะเล่าเกี่ยวกับความเปลี่ยนแปลงครั้งนี้คือลูกชายของผมไม่อยากย้ายมาเลยผมมีลูกสองคนครับ ลูกชายตอนนี้อายุ 21 ส่วนลูกสาวอายุ 16 |เจ้าลูกชายผมเค้าไม่อยากย้ายไป Los Angeles จริงๆ เขาชอบเมืองนี้นะครับ |แต่ว่า ณ ตอนนั้น เขามีแฟนอยู่ในอังกฤษ ชื่อ ซาร่าห์ รักเดียวของเขาเลยล่ะครับเขารู้จักเธอมาได้ประมาณเดือนนึงแต่จะว่าไป อาจจะเรียกได้ว่าพวกเขาเหมือนแต่งงานกันมาแล้วครบ 4 ปีเพราะว่าการคบกับใครได้ 1 เดือนสำหรับเด็กอายุ 16 แล้ว มันเหมือนเป็นระยะเวลายาวนานดังนั้น ลูกชายผมจึงเสียใจมากตอนที่อยู่บนเครื่อง |เขาบอกว่า \"ผมคงไ่ม่มีทางเจอผู้หญิงอย่างซาร่าห์อีกแล้ว\" |จริงๆ แล้ว ผมกับภรรยา ดีใจครับที่เป็นแบบนั้นเพราะว่า ซาร่าห์ คือเหตุผลหลักที่เราตัดสินใจย้ายออกจากอังกฤษแต่การย้ายมาอเมริกาทำให้เราฉุกคิดครับเมื่อคุณได้ท่องเที่ยวมาแล้วทั่วโลกคุณจะพบว่า ระบบการศึกษา ทุกที่บนโลกนี้ มีืการจัดระดับของวิชาต่าง ๆ แบบเดียวกันทุกที่เลยครับ ไม่ว่าคุณจะไปที่ไหนคุณอาจคิดว่ามันน่าจะต่างกัน แต่มันไม่ใช่แบบนั้นเลยครับ |ระดับบนสุดก็คือ คณิตศาสตร์ และ ภาษาจากนั้ืนก็มนุษยศาสตร์ และล่างสุดคือศิลปะเป็นแบบนี้ทั้งโลกเลยครับและเป็นแบบนี้ในทุกระบบด้วยครับนอกจากนี้ข้างในสาขาศิลปะเองก็ยังแบ่งออกเป็นระดับต่างๆในสถานศึกษา จิตรกรรม และ ดนตรี จะมีสถานะที่สูงกว่าการแสดง และการเต้นรำ ไม่มีระบบการศึกษาใดเลยในโลกนี้ที่เราสอนให้เด็กๆ เต้นรำ ทุกวัน |เหมือนกับที่เราสอนคณิตศาสตร์ ทำไมล่ะครับ |ทำไมเราถึงไม่ทำอย่างนั้น ผมว่าเรื่องนี้สำคัญมากทีเดียว |ใช่ครับ ผมยอมรับว่าความรู้ด้านคณิตศาสตร์นั้นสำคัญ แต่ผมว่าการเต้นก็สำคัญเหมือนกัน |เด็กๆ เต้นตลอดเวลา ถ้าพวกเขาได้รับอนุญาต |พวกเราก็มีร่างกายด้วยกันทั้งนั้นใช่ไหมครับ ผมไม่ได้พลาดอะไรไปใช่ไหม | จริงๆ นะครับ สิ่งที่เกิดขึ้นก็คือ |เมื่อเด็กๆ โตขึ้นๆ พวกเราก็ค่อยๆ สอนเด็กเหล่านั้นให้ใช้ความสามารถตั้งแต่เอวขึ้นไป แล้วเราก็เน้นเฉพาะการใช้สมองและค่อนข้างจะไปทางซีกหนึ่งของสมองด้วย |ถ้าหากคุณเป็นมนุษย์ต่างด้าวแล้วได้เข้าไปเยี่ยมชมงานด้านการศึกษา |เพื่อตอบคำถามว่า \"การศึกษา มีไว้เพื่ออะไร?\"คุณคงจะได้ข้อสรุป จากการพิจารณาจากผลผลิตที่ออกมาจากคนที่ได้รับผลประโยชน์จากมันคนที่ทำในสิ่งที่คิดว่าสมควรทำ |คนที่ประสบความสำเร็จคุณน่าจะได้ข้อสรุปว่า วัตถุประสงค์ ของการศึกษาของทั้งโลกใบนี้ คือการผลิตอาจารย์มหาวิทยาลัย ว่ามั๊ยครับ |พวกเขาเหล่านั้น คือ คนที่อยู่อันดับต้นๆ ของการจัดอันดับครับ |ผมก็เคยอยู่ในคนกลุ่มนั้นครับ เป็นยังไงล่ะ  |ผมชอบอาจารย์มหาวิทยาลัยนะครับ แต่ผมว่า |เราไม่ควรยกย่องพวกเขาว่าเป็นบุคคลที่ยอดเยี่ยมที่สุด |พวกเขาก็แค่สิ่งมีชีวิตกลุ่มหนึ่งเท่านั้นครับ |ที่ค่อนข้างจะมีความช่างคิด ช่างสงสัยและผมพูดอย่างนี้โดยไม่คิดถึงความชื่นชมที่มีต่อพวกเขานะครับ |จากประสบการณ์ที่ผมมี มีบางอย่างน่าสนใจเกี่ยวกับบรรดาศาสตราจารย์เหล่านี้ครับไม่ใ่ช่ทุกคนนะครับ แค่บางคน ที่ีมีชีวิตอยู่แต่กับความคิดในหัวของตัวเองอยู่อย่างนั้นเลยครับ แล้วค่อนข้างไปทางสมองซีกหนึ่ง |พวกเขาไม่สนใจร่างกายของพวกเขาหรอกครับพวกเขามองว่าร่างกายนั้นก็เป็นเพียงแค่สิ่งที่ทำให้ศีรษะของพวกเขาเคลื่อนที่ไปยังสถานที่ต่างๆ ได้ | ร่างกายก็เป็นแค่สิ่งที่พาศีรษะของเขาไปประชุม |ถ้าคุณอยากเห็นหลักฐานเกี่ยวกับประสบการณ์การละทิ้งร่างกาย |ลองไปเข้าร่วมงานสัมนาของอาจารย์ประจำมหาวิทยาลัยซิครับบรรดาผู้มีคุณวุฒิทางการศึกษาไปงานเต้นรำในคืนสุดท้ายของการสัมนานะครับ ณ ที่นั่น คุณจะได้เห็น ชาย หญิง ที่โตแล้ว |ขยับแข้ง ขยับขา แบบไม่เข้าจังหวะเอาเสียเลยครับ |อยู่จนงานเลิก แล้วไปเขียนบนความเกี่ยวกับเรื่องนั้นนะครับ |ทีนี้ ระบบการศึกษาของเราเกิดจากความคิดเกี่ยวกับความสามารถทางวิชาการแ่ต่มันก็มีเหตุผลจากว่าระบบนี้ในทั่วโลก ถูกสร้างขึ้นในช่วงก่อนศตวรรษที่ 19 ซึ่งตอนนั้นยังไม่มีระบบการศึกษาสาธารณะเกิดขึ้นเลยครับมันถูกคิดค้นขึ้นมาเพื่อตอบสนองความต้องการในยุค การปฏิวัติอุตสาหกรรมดังนั้น อันดับ ความสำคัญของวิชาต่างๆ ถูกจัดโดยพิจารณาจาก 2 ปัจจัย ได้แก่ปัจจัยแรก วิชาที่มีประโยชน์กับลักษณะงานที่มีอยู่ในยุคนั้นมากที่สุดจะถูกจัดไว้สูงสุด ดังนั้น คุณจะได้รับการชี้นำให้ออกห่าง |จากสิ่งที่คุณชอบ ณ ตอนที่คุณเป็นเด็กด้วยเหตุผลที่ว่า |คุณไม่มีทางทำมาหากินได้จากวิชาความรู้ที่คุณชอบได้ จริงรึเปล่าครับ |ไม่ต้องเรียนดนตรีหรอก โตขึ้นจะเป็นนักดนตรีไม่ได้นะไม่ต้องเีรียนศิลปะหรอก โตขึ้นไม่ได้จะเป็นศิลปินเสียหน่อยคำแนะนำเหล่านี้ ณ ตอนนี้เราพลแล้วว่าเป็นความคิดที่ผิดโลกเราตอนนี้กำลังอยู่ในช่วงการปฏิวัติ |ถัดมาคือความสามารถในด้านวิชาการ ที่มีผลเป็นอย่างมาก |กับมุมมองของพวกเราในเรื่องของสติปัญญา |นั่นเป็นเพราะว่ามหาวิทยาลัยได้ออกแบบระบบการศึกษาจากภาพลักษณ์ของตัวมันเอง |ลองนึกดูซิครับว่าระบบการศึกษาสาธารณะทุกที่ในโลกนี้ ถูกสร้างขึ้นมาเพื่อเป็นส่วนหนึ่งของกระบวนการ |ในการเข้าสู่มหาวิทยาลัย |และผลก็คือ มีหลายคนที่้ มีพรสวรรค์ มีความสามารถเฉพาะตัว |เก่ง และมีความสร้างสรรค์ กลับคิดว่าพวกเขาไม่มีความสามารถอะไรเลย |เพียงเพราะว่า พวกเขาเรียนไม่เก่ง |ไม่มีใครมองเห็นคุณค่า แล้วกลับถูกมองว่าผิดปกติผมว่า เราไม่ควรปล่อยให้เป็นอย่างนี้ต่อไปนะครับด้วยข้อมูลจากองค์กรยูเนสโก้ ภายใน 30 ปี จากนี้ |ทั่วโลกจะมีคนจบการศึกษามากกว่าจำนวนคนทั้งหมด ณ จุดเริ่มต้นของประวัติศาสตร์จะมีคนจำนวนมากขึ้นแล้วก็มีสิ่งต่างๆ ที่เราได้พูดถึงก่อนหน้านี้ |ไม่ว่าจะเป็นเทคโนโลยี และการเปลี่ยนรูปร่างของมันที่มีผลต่อ งาน และลักษณะโครงสร้างของประชากรและจำนวนของประชากรที่จะเพิ่มขึ้นอย่างมหาศา่ล |ถึงตอนนั้น การมีปริญญาจะไ่ม่มีความหมายอีกต่อไป จริงไหมครับ |ตอนที่ผมเป็นนักศึกษา ตอนนั้นถ้าคุณมีปริญญา คุณก็จะมีงานทำแล้วถ้าหากคุณไม่มีงานทำ นั่นเป็นเพราะว่าคุณไม่ต้องการมัน |แล้วจริงๆ แล้วผมก็ไม่อยากได้มันหรอกครับ แต่คนรุ่นใหม่ที่ีมีปริญญาตอนนี้ |หลายคนกลับไปอยู่บ้าน แล้วยังคงเล่นวีดีโอเกมส์ |เพราะคุณต้องมีปริญญาโท เพื่อขยับจากงานเก่าที่ต้องการคนจบปริญญาตรีแล้วตอนนี้คุณก็ต้องมีปริญญาเอกเพื่ีอให้ได้อีกงานหนึ่ง |มันเป็นกระบวนการเฟ้อของการศึกษา |และมันชี้ให้เป็นว่าโครงสร้างของการศึกษา |ได้มีการเปลี่ยนแปลงแล้วในช่วงชีวิตของพวกเรา เราจึงจำเป็นต้องคิดใหม่ |เกี่ยวกับมุมมองของเราในเรื่องของสติปัญญาเรารู้อยู่ 3 อย่างเกี่ยวกับสติปัญญาสิ่งแรกคือมันหลากหลาย เรามองโลกในมุมมองที่หลากหลายจากสิ่งที่เราได้ประสบ เราคิดจากสิ่งที่เห็น |จากสิ่งที่ได้ยิน จากการลงมือทำเราคิดในแบบที่เป็นนามธรรม เราคิดในการเคลื่อนไหวสิ่งที่สองคือ สติปัญญานั้นมีการเปลี่ยนแปลงตลอดเวลาถ้าคุณมองการปฏิสัมพันธ์ในเซลล์ต่างๆ ของสมอง |จากที่เราได้ฟังจากหลายการนำเสนอเมื่อวานนี้ |สติปัญญาเป็นการปฏิสัมพันธ์ที่มหัศจรรย์สมองของเราไม่ได้ถูกแบ่งออกเป็นชิ้นส่วนต่างๆความคิดริเริ่มสร้างสรรค์ ที่ผมนิยามไว้ว่า เป็นกระบวนการ |ในการสร้างให้เกิดแนวความคิดที่เป็นต้นฉบับ ที่มีคุณค่าหลายครั้งมันไม่ได้มาจากการปฏิสัมพันธ์ของการมองสิ่งต่างๆ ในรูปแบบที่ต่างกันไป |สมองนั้นถูกออกแบบให้มีการประสานกันของเส้นประสาท ที่ได้หลอมรวมสมองทั้งสองส่วนเรียกว่า Corpus Collosum ซึ่งในผู้หญิงนั้นพบว่าจะมีความหนากว่าผู้ชายซึ่งก็เป็นไปตามที่ เฮเลน ได้พูดไว้เมื่อวานนี้ |ผมคิดว่า มันคือเหตุผลว่าทำไมผู้หญิงจึงสามารถทำงานหลายอย่างพร้อมๆ กันได้ดีกว่าผู้ชาย |เพราะว่าพวกคุณเก่งกว่าจริงๆ ใช่มั๊ยมีงานวิจัยสนับสนุนความคิดนี้มากมายเลยครับ แต่ผมรู้ได้จากชีวิตของผมเองถ้าหากภรรยาของผมทำอาหารที่บ้าน |โชคดีครับที่เธอไม่ได้ทำมันบ่อยนัก  |เธอทำอาหารบางจานอร่อยนะครับเอาเป็นว่า ถ้าภรรยาผมทำอาหารเธอสามารถคุยโทรศัพท์ |คุยกับลูกๆ พร้อมกับทาสีผนังไปด้วย |ให้ผ่าตัดหัวใจไปด้วยก็ยังได้แต่ถ้าตอนผมทำอาหาร ประตูครัวจะถูกปิด เด็กๆ จะต้องออกไปข้างนอก |หูโทรศัพท์ต้องยกออก ถ้าภรรยาผมเข้ามาในครัว ผมจะรำคาญมาก |ผมจะบอกว่า เทอรี่ ได้โปรดเถอะ ขอเวลาส่วนตัวหน่อยได้ไหม ผมกำลังทอดไข่ดาวอยู่นะ |คุณเคยได้ยินคำพูดนี้รึเปล่าถ้าต้นไม้ต้นหนึ่งในป่าล้มลง แล้วไม่มีใครได้ยินเรายังคิดว่ามันเกิดขึ้นจริงรึเปล่า จำเรื่องต้น Chestnut ต้นนั้นได้ไหมครับเมื่อเร็วๆ นี้ ผมเห็นเสื้อยืดตัวหนึ่งสกรีนคำว่า \"ถ้าชายคนหนึ่งบอกความในใจของเขาในป่าและไม่มีผู้หญิงคนไหนได้ยิน |เขาจะยังผิดรึเปล่า?\"  |เอาล่ะครับ มาถึงลักษณะที่ 3 ของความฉลาด ซึ่งก็คือ |มันมีความเป็นแตกต่างเป็นเอกลักษณ์เฉพาะ ตอนนี้ผมกำลังเขียนหนังสืออยู่เล่มหนึ่ง |ชื่อว่า Epiphany ซึ่งเนื้อหานำมาจาก |บทสัมภาษณ์บุคคลหลายๆ ท่าน เกี่ยวกับการค้นพบ |ความสามารถพิเศษของพวกเขา ผมหลงไหลกับวิธีการที่คนเหล่านั้นก้าวมาถึงจุดที่พวกเขายืนอยู่ |แนวคิดของหนังสือนี้ มาจากการที่ผมได้พูดคุย |กับผู้หญิงที่วิเศษคนหนึ่ง ซึ่งคนส่วนใหญ่ |อาจจะไม่รู้จัก เธอคนนั้นชื่อ จิลเลี่ยน ลินน์ ครับ |คุณเคยได้ยินชื่อเธอมาบ้างรึเปล่า? บางคน ณ ที่นี้รู้จักนะครับ เธอเป็นนักออกแบบท่าเต้นครับทุกคนจะต้องรู้จักผลงานของเธอเธอทำละครเวทีเรื่อง Catz และ Phantom of the Opera ครับ |เธอเยี่ยมมากเลย ผมเคยเป็นกรรมการบริหารของ Royal Ballet ในประเทศอังกฤษ |พอจะเดาออกไหมครับเอาล่ะ วันหนึ่งผมกับจิลเลี่ยนทานอาหารกลางวันด้วยกันผมถามเธอว่า \"จิลเลี่ยน คุณมาเป็นนักเต้นได้อย่างไร\"เธอตอบว่า ตอนที่เธอเป็นนักเรียน |การเรียนของเธอย่ำแย่มาก ตอนนั้นก็ยุค 30s ครับโรงเรียนของเธอส่งจดหมายถึงคุณพ่อคุณแม่ของเธอ ในนั้นเขียนว่า |\"เราคิดว่าจิลเลี่ยนมีปัญหาในการเรียนรู้\" เธอไม่สามารถมีสมาธิจดจ่อกับสิ่งใดได้ |ผมคิดว่าถ้าเป็นสมัยนี้ เราเรียกอาการนี้ว่าเธอเป็นโรคสมาธิสั้น ว่าไหมครับ แต่ในยุค 1930s |โรคสมาธิสั้นยังไม่ถูกค้นพบมันก็เลยไม่ได้เป็นอาการที่คนจะเลือกเป็นกันได้  |คนก็เลยไม่ทราบว่าพวกเขาอาจจะมีปัญหาเรื่องนี้ |จิลเลี่ยนก็ได้ไปพบผู้เชี่ยวชาญ |กับคุณแม่ของเธอเธอนั่งอยู่ที่เก้าอี้ที่อยู่ด้านหนึ่ง |เธอนั่งทับมือเธอไว้ 20 นาทีในระหว่างที่ผู้เชี่ยวชาญคนนี้คุยกับคุณแม่ของเธอเกี่ยวกับปัญหาของจิลเลี่ยนที่โรงเรียนว่าเธอรบกวนเด็กคนอื่นๆ |เธอส่งการบ้านสายเสมอเด็กอายุ 8 ขวบ เท่านั้นครับ ในตอนสุดท้าย คุณหมอท่านนี้ก็เดินมานั่งข้างๆ จิลเลี่ยนแล้วเขาก็บอกกับจิลเลี่ยนว่า |หมอได้ฟังเรื่องต่างๆ ของหนูจากคุณแม่แล้วนะจ๊ะหมอต้องขอคุยกับคุณแม่เป็นการส่วนตัวเสียหน่อยรอพวกเราอยู่ในห้องนี้สักพักนะจ๊ะ เราจะไปไม่นานหรอกแล้วคุณหมอ กับคุณแม่ของเธอก็เดินออกไปจากห้องก่อนที่คุณหมอจะออกไปจากห้อง เขาก็เปิดวิทยุที่อยู่บนโต๊ะทำงานของเขาเมื่อพวกเขาอยู่ข้างนอก คุณหมอก็พูดกับคุณแม่ของจิลเลี่ยนว่าคอยยืนดูจิลเลี่ยนอยู่ตรงนี้นะครับ และตั้งแต่เมื่อคุณหมอและคุณแม่ของเธอออกจากห้องไปจิลเลี่ยนบอกว่าเธอก็ลุกขึ้นยืน แล้วก็เต้นไปตามเสียงเพลงคุณหมอกับคุณแม่มองเธออยู่จากด้านนอกประมาณ 2-3 นาทีคุณหมอก็หันไปบอกกับคุณแม่ของเธอว่าคุณนายลินน์ครับ จิลเลี่ยนไม่ได้ป่วยหรอกครับ เธอเป็นนักเต้นต่างหากส่งเธอไป โรงเรียนสอนเต้นรำเถอะ |ผมถามจิลเลี่ยนว่า แล้วจากนั้นเกิดอะไรขึ้นจิลเลี่ยนบอกว่า แม่ส่งฉันไปค่ะ ฉันบรรยายไม่ถูกเลยว่ามันมหัศจรรย์ขนาดไหนเราเดินเข้าไปในห้องที่เต็มไปด้วย |คนที่เหมือนๆ กับฉัน คนที่อยู่เฉยๆ ไม่ได้ |คนที่ต้องขยับตัวตลอดเวลาเพื่อคิดที่นั่นสอนเต้นบัลเล่ต์ แท๊บ แจ๊ส |การเต้นสมัยใหม่ และแบบร่วมสมัย |เธอได้ไปคัดเลือกตัวที่ Royal Ballet School |แล้วเธอก็ได้เป็นนักเต้นเดี่ยว มีอาชีพวิเศษที่คณะ Royal Ballet แล้วเธอก็เรียนจบ |จาก The Royal Ballet School จากนั้น |เธอก็เปิดบริษัทสอนเต้นรำของตัวเอง ชื่อ The Gillian Lynne Dance Companyเธอได้เจอกับ แอนดรู ลอยด์ เว๊บเบอร์  เธอได้ร่วมงานกับเขา และมีส่วนร่วมกับละครเพลงที่ประสบความสำเร็จมากที่สุด |ในประประวัติศาสตร์ เธอได้ให้ความสุขกับคนนับล้าน |เธอกลายเป็นมหาเศรษฐีถ้าเธอไม่ได้เจอคุณหมอคนนั้น เธออาจได้รับยาแล้วก็บอกให้เํธออยู่นิ่งๆ สงบสติอารมณ์ |เอาล่ะ ทีนี้ผมคิดว่า  มาถึงเรื่องที่ |อัล กอร์ พูดเมื่อคืนก่อนเกี่ยวกับสิ่งแวดล้อม และที่ Rachel Carson กล่าวถึงเรื่องของวิวัฒนาการ |ผมเชื่อว่า สิ่งเดียวที่เราสามารถฝากอนาคตของเราไว้ได้คือ |แนวความคิดเกี่ยวกับสภาพแวดล้อมของมนุษย์เราจะต้องเริ่มต้นในการปรับเปลี่ยนวิธีการคิด |เกี่ยวกับสามารถอันมหาศาลของความสามารถของมนุษย์ระบบการศึกษาของเราได้ปลูกฝังความคิดของเราในรูปแบบที่ |เราใช้ทรัพยากรของเราเพื่อให้ได้มาเพียงผลผลิตบางอย่างที่ในอนาคตจะไม่สามารถตอบสนองความต้องการของเราได้เราจะต้องคิดใหม่ เกี่ยวกับโครงสร้างพื้นฐานหลักในการให้การศึกษาแก่ลูกหลานของเราผมขอยกคำพูดหนึ่งของ Jonas Salk ที่ว่าถ้าพวกแมลงทั้งหมดหายไปจากโลกนี้ |ภายใน 50 ปี ทุกชีวิตบนโลกก็จะสิ้นไป |แต่หากมนุษย์หายไปจากโลกนี้ภายใน 50 ปี สิ่งมีชีวิตทุกชนิดก็จะขยายเผ่าพันธุ์ได้สมบูรณ์ |เขาพูดถูกนะครับ |สิ่งที่ TED ส่งเสริม คือของขวัญจากจินตนาการของมนุษย์เราจะต้องระวังว่า เราได้ใช้ของขวัญนี้ |อย่างรู้ค่า และเราได้ป้องกันไม่ให้เกิดเรื่องราวอย่างที่เราได้พูดถึงกันในวันนี้ และมีเพียงวิธีการเดียว |ที่เราจะทำอย่างนั้นได้ คือ การที่เรามองความสามารถในการคิดริเริ่มสร้างสรรค์ว่ามันมีมากมายมหาศาลและมองลูกหลานของเราว่าพวกเขามีสิ่งเหล่านั้นและหน้าที่ของเราก็คือสอนพวกเขาเกี่ยวกับสิ่งต่าง ๆ เพื่อที่พวกเขาจะสามารถเผชิญกับอนาคตได้ |พวกเราอาจจะไม่มีโอกาสได้เห็นอนาคตนั้่นแต่ลูกหลานของเราจะได้เห็น ดังนั้น มันเป็นหน้าที่ของพวกเรา |ที่จะช่วยให้ลูกหลานของเราอยู่กับอนาคตนั้นได้ ขอบคุณมากครับ ',\n",
       "       'ถ้าวันนี้คุณอยู่ที่นี่--และดิฉันเองก็มีความสุขมากที่คุณมาอยู่ที่นี่คุณทุกคนคงเคยได้ยินมาแล้วเกี่ยวกับเรื่องของการพัฒนาอย่างยั่งยืนนั้นจะช่วยชีวิตเราจากตัวเราเอง อย่างไรก็ตาม เมื่อเราไม่ได้อยู่ที่ TEDมักจะมีคนมาบอกกับเราเสมอว่า แผนนโยบายที่ยั่งยืนอย่างแท้จริงนั้นเป็นไปไม่ได้ |โดยเฉพาะอย่างยิ่งในชุมชนเมืองขนาดใหญ่อย่างเมืองนิวยอร์กนั่นเป็นเพราะคนส่วนใหญ่ที่มีอำนาจในการตัดสินใจจากทั้งภาครัฐและภาคเอกชน |ต่างก็ไม่ได้รู้สึกจริงๆ ว่าตัวเองนั้นอยู่ในอันตรายเหตุผลที่ดิฉันมาที่นี่ในวันนี้ก็คือ ส่วนหนึ่ง มาจากสุนัขตัวหนึ่งลูกสุนัขซึ่งถูกทอดทิ้งที่ดิฉันเจอมันกลางสายฝนในปี 1998 |มันกลายมาเป็นสุนัขตัวใหญ่กว่าที่ดิฉันคาดเอาไว้อีกเมื่อมันเข้ามาในชีวิตของดิฉัน เราต่างช่วยกันต่อสู้กับโรงงานขยะขนาดมหึมาแห่งหนึ่ง |ซึ่งถูกวางแผนสำหรับริมฝั่งแม่น้ำอีสต์ริเวอร์ โดยไม่คำนึงถึงความจริงว่าพื้นที่เล็กๆ ในเมืองนิวยอร์กของเรานั้น |ได้รองรับสิ่งปฏิกูลเชิงพาณิชย์มากกว่า 40 เปอร์เซนต์ของทั้งเมืองอยู่แล้วมีโรงงานบำบัดน้ำเสีย โรงงานกากสิ่งปฏิกูล โรงไฟฟ้าสี่แห่งศูนย์กระจายอาหารขนาดใหญ่ที่สุดในโลกรวมทั้งอุตสาหกรรมอื่นๆ ที่นำรถบรรทุกดีเซลกว่า 60,000 เที่ยวเข้าไปในพื้นที่ในแต่ละสัปดาห์พื้นที่ยังมีอัตราส่วนสวนสาธารณะที่ต่ำที่สุดสำหรับผู้คนที่อาศัยอยู่ในเมืองและเมื่อดิฉันได้รับการติดต่อจากกรมการสวนสาธารณะเกียวกับเรื่องเงินทุนสนับสนุนจำนวน 10,000 เหรียญ เพื่อช่วยพัฒนาโครงการต่างๆ ในเขตริมฝั่งแม่น้ำตอนนั้นดิฉันคิดว่าพวกเขามีเจตนาดีจริงๆ แต่ค่อนข้างขาดประสบการณ์ |ดิฉันเคยอาศัยอยู่ในพื้นที่นี้มาตลอดชีวิต และคุณไม่สามารถไปถึงแม่น้ำได้เป็นเพราะ |โรงงานที่น่ารักทั้งหลายที่ดิฉันได้กล่าวถึงก่อนหน้านี้ต่อมา ขณะที่ดิฉันกำลังวิ่งจ๊อกกิ้งไปกับสุนัขของดิฉันมันดึงดิฉันเข้าไปที่ซึ่งดิฉันคิดว่าเป็นแค่ที่ทิ้งขยะผิดกฏหมายอีกที่หนึ่งเท่านั้น |ที่ตรงนั้นมีวัชพืชและกองขยะมากมาย และของอื่นๆ ที่ดิฉันจะไม่กล่าวถึง ณ ที่นี้แต่มันยังพยายามดึงดิฉันไปเรื่อยๆ--แล้วดูซิ ปลายทางของกองขยะก็คือแม่น้ำ |ดิฉันรู้ดีว่าที่ท้ายถนนเล็กๆ ที่ถูกลืมนี้ถูกทอดทิ้งเอาไว้เหมือนกับสุนัขตัวที่พาดิฉันไปที่นั่น คุ้มค่าต่อการรักษา |และดิฉันรู้ว่ามันจะเติบโตกลายเป็นจุดเริ่มต้นแห่งความภาคภูมิใจของการชุบชีวิตใหม่ที่นำโดยชุมชนของเซาท์บรองซ์แห่งใหม่นี้และเช่นเดียวกับสุนัขตัวใหม่ของดิฉัน มันเป็นแนวคิดที่เติบใหญ่เกินกว่าที่ดิฉันวาดภาพไว้ |เราได้สั่งสมความช่วยเหลือมามากตั้งแต่เริ่มจนบันนี้และแล้วสวนสาธารณะฮันซ์พอยต์ริเวอร์ไซด์ก็กลายเป็นสวนสาธารณะริมฝั่งแม่น้ำแห่งแรก |ที่เซาท์บรองค์ไม่เคยมีมาก่อนมากกว่า 60 ปีเราได้เพิ่มกำลังเงินทุนสนับสนุนจำนวน 10,000 เหรียญขึ้นมากกว่า 300 เท่าจนกลายเป็นสวนสาธารณะมูลค่า 3 ล้านเหรียญ |และในฤดูใบไม้ร่วง จริงๆ แล้วดิฉันจะ-- |ดิฉันจะแลกเปลี่ยนคำสาบานการแต่งงานกับสุดที่รักค่ะ ขอบคุณมากค่ะ เขานั่งอยู่นั่นไงคะ กำลังกดปุ่มให้ดิฉันอยู่ที่ด้านหลัง ซึ่งเขาทำแบบนี้ตลอด  |แต่พวกเราที่อาศัยอยู่ในชุมชนที่มีความยุติธรรมทางสิ่งแวดล้อมเป็นเหมือนนกขมิ้นในเหมืองถ่านหิน เรารู้สึกถึงปัญหาในขณะนี้และที่มีมาเป็นระยะเวลาหนึ่งแล้ว |ความยุติธรรมทางสิ่งแวดล้อม สำหรับพวกคุณที่ไม่คุ้นเคยกับคำศัพท์ คำนี้มีความหมายว่า |ไม่ควรมีชุมชนใดถูกบังคับให้รองรับภาระทางสิ่งแวดล้อมเพิ่มมากขึ้นและได้รับประโยชน์ทางสิ่งแวดล้อมน้อยกว่าที่อื่น |เป็นเรื่องน่าเสียดายที่เชื้อชาติและชนชั้นเป็นตัวบ่งบอกที่น่าเชื่อถืออย่างสูงขณะที่คนคนหนึ่งอาจพบของดี เช่น สวนสาธารณะและต้นไม้ |ในขณะที่อีกคนหนึ่งอาจพบสิ่งที่ไม่ดี เช่น โรงไฟฟ้าและโรงงานกำจัดสิ่งปฏิกูลในฐานะที่เป็นคนสีผิวในสหรัฐอเมริกา ดิฉันต้องเสี่ยงเป็นสองเท่าของคนผิวขาวในการอาศัยในพื้นที่ที่มลพิษทางอากาศก่อให้เกิดความเสี่ยงสูงสุดต่อสุขภาพของดิฉันดิฉันมีโอกาสเป็นห้าเท่าที่จะอาศัยอยู่ในระยะไม่ไกล |จากโรงไฟฟ้าหรือโรงงานสารเคมี--ซึ่งดิฉันอาศัยใรระแวกนั้นจริง |การตัดสินใจใช้พื้นที่เหล่านี้ได้สร้างปัจจัยที่เป็นผลร้ายที่นำไปสู่ปัญหาต่างๆ เช่น ปัญหาโรคอ้วน โรคเบาหวาน และโรคหอบหืดทำไมคนบางคนถึงออกจากบ้านเพื่อที่จะเดินออกกำลังกายเร็วๆ ในละแวกบ้านที่เป็นพิษด้วยอัตราคนเป็นโรคอ้วนร้อยละ 27 ของเรานั้นถือว่าสูง แม้คิดเฉพาะประเทศนี้ก็ตาม และโรคเบาหวานยังตามมากับโรคนี้ด้วย |เด็กหนึ่งในสี่คนของเซาท์บรองซ์จะเป็นโรคหอบหืดอัตราการเข้ารักษาโรคหอบหืดในโรงพยาบาลของเราคิดเป็น 7 เท่าสูงกว่าค่าเฉลี่ยของคนทั้งประเทศผลกระทบเหล่านี้กำลังคืบคลานเข้ามาหาทุกๆ คน |และเราทุกคนต้องจ่ายเงินมากมายเป็นค่าสิ่งปฏิกูลปัญหาสุขภาพที่เกี่ยวข้องกับมลพิษ และที่น่ารังเกียจมากกว่านั้นคือ |ค่าใช้จ่ายในการคุมขังเด็กหนุ่มผิวสีและชายเชื้อสายลาตินที่มีศักยภาพที่ยังไม่ได้นำมาใช้ให้เกิดประโยชน์มากมาย50 เปอร์เซนต์ของชาวบ้านมีชีวิตอยู่ที่ระดับยากจนหรือต่ำกว่า |25 เปอร์เซนต์ของพวกเราไม่มีงานทำ ประชาชนที่มีรายได้ต่ำมักจะใช้พบแพทย์ในห้องฉุกเฉินเป็นการดูแลสุขภาพหลัก |สิ่งนี้นำมาซึ่งค่าใช้จ่ายสูงลิ่วต่อผู้เสียภาษี และสร้างประโยชน์ที่ไม่เหมาะสมอีกด้วยคนจนไม่ใช่แค่ยังจนอยู่ แต่ยังมีสุขภาพที่ไม่ดีอีกด้วยโชคดีที่ยังมีคนอีกมากมายเหมือนอย่างดิฉันที่กำลังต่อสู้เพื่อหาทางแก้ปัญหา |ที่จะไม่เป็นอันตรายต่อชีวิตของผู้ที่อยู่ในชุมชนผิวสีรายได้ต่ำในระยะสั้น |และจะไม่ทำลายเราทั้งหมดในระยะยาวไม่มีใครต้องการสิ่งนั้น และเราทุกคนมีสิ่งนั้นเหมือนกัน แล้วมีอะไรอีกที่พวกเรามีเหมือนกัน |เอาล่ะ ก่อนอื่นต้องขอบอกว่าพวกเราทั้งหล่อทั้งสวยกันทุกคนค่ะ |--เรียนจบชั้นมัธยม วิทยาลัย ระดับปริญญาโทได้ท่องเที่ยวไปในที่ต่างๆ ที่น่าสนใจ ไม่มีลูกที่ต้องเลี้ยงดูในช่วงวัยรุ่นมีความมั่นคงทางการเงิน และไม่เคยจำคุกมาก่อน โอเคดีค่ะ  |นอกจากจะเป็นสตรีผิวสีแล้ว ดิฉันต่างจากพวกคุณส่วนใหญ่ในด้านอื่นๆ หลายด้านดิฉันเคยมองตึกรามบ้านช่องเกือบครึ่งในละแวกบ้านถูกไฟเผาทำลายไปต่อหน้าต่อตา |เลนนี่ พี่ชายคนโตของดิฉันเคยไปรบในเวียดนาม |ถูกยิงตายห่างจากบ้านของเราไปเพียงแค่ไม่กี่ช่วงตึก |พระเจ้า ดิฉันเติบโตมากับบ้านผุพังที่อยู่ฝั่งตรงข้ามถนน |ใช่ค่ะ ดิฉันเป็นเด็กผิวสีที่ยากจนมาจากสลัมสิ่งเหล่านี้ทำให้ดิฉันแตกต่างจากพวกคุณแต่สิ่งที่พวกเรามีเหมือนกันทำให้ดิฉันต่างจากคนส่วนใหญ่ในชุมชนของดิฉันและดิฉันยืนอยู่ระหว่างโลกทั้งสองนี้ |ด้วยหัวใจที่แกร่งพอที่จะต่อสู้เพื่อความยุติธรรมในอีกโลกหนึ่ง |แล้วสิ่งเหล่านี้แตกต่างสำหรับพวกเราได้อย่างไรในช่วงปลายยุค 40 พ่อของดิฉัน --ลูกทาส ทำงานเป็นคนเฝ้าประตูรถโดยสาร -- |ได้ซื้อบ้านหนึ่งหลังไว้ในเขตฮันซ์พอยท์ในเซาท์บรองซ์แห่งนี้และอีกไม่กี่ปีต่อมาพ่อแต่งงานกับแม่ของดิฉันในเวลานั้น คนในชุมชนส่วนใหญ่เป็นคนขาว เป็นถิ่นที่อยู่ของคนชนชั้นกลางแต่พ่อดิฉันไม่ได้อยู่เพียงลำพัง |และคนอื่นๆ ที่เหมือนพ่อที่ติดตามความฝันของคนอเมริกันในแบบฉบับของตนเอง |การอพยพออกของคนผิวขาวกลายเป็นเรื่องปกติในเซาท์บรองซ์และในอีกหลายเมืองทั่วประเทศการเลือกปฏิบัติที่ธนาคารนำมาใช้ในบางเขตของเมืองรวมถึงเขตของเราก็ถูกเข้าใจว่าเป็นเขตห้ามการลงทุนทุกชนิด |เจ้าของบ้านเช่าหลายคนเชื่อว่าการวางเพลิงเผาอาคารของตนเองจะทำกำไรได้มากกว่า |แล้วคอยรับเงินประกันแทนที่จะขายไปภายใต้สภาวการณ์เหล่านั้น--โดยไม่คำนึงถึงผู้เช่ารายเก่าที่ต้องเสียชีวิตหรือได้รับบาดเจ็บเลย |แต่ก่อนนี้ ฮันซ์พอยท์เคยเป็นชุมชนที่ผู้คนเดินไปทำงาน |แต่มาตอนนี้ผู้คนที่อาศัยอยู่ไม่มีแม้แต่งานหรือบ้านให้เดินกลับ |ความเจริญเติบโตของการก่อสร้างทางหลวงในประเทศถูกเพิ่มเข้ามาในปัญหาของเรา |ในรัฐนิวยอร์ก โรเบิร์ต โมส ได้เป็นหัวหอกในการรณรงค์เพื่อขยายทางหลวงอย่างแข็งขันดุดัน |หนึ่งในเป้าหมายหลักก็เพื่อสร้างความสะดวกให้แก่ผู้อาศัยในชุมชนที่ร่ำรวยในเขตเวสเชสเตอร์ที่ต้องการเดินทางไปยังแมนฮัตตันเขตเซาท์บรองซ์ซึ่งตั้งอยู่ระหว่างกลางไม่มีทางที่จะต่อกรได้เลยชาวบ้านมักจะได้รับการแจ้งล่วงหน้าไม่ถึงหนึ่งเดือนก่อนที่บ้านเรือนของพวกเขาจะถูกรื้อถอน |ชาวบ้าน 600,000 คนถูกขับไล่ความเข้าใจทั่วไปคือมีแค่แมงดา นักค้ายาเสพติด และโสเภณีเท่านั้นที่มาจากเซาท์บรองซ์และถ้ามีคนบอกคุณตั้งแต่ตอนเป็นเด็กว่าจะไม่มีสิ่งดีใดๆ เกิดขึ้นจากชุมชนของคุณ ซึ่งมันแย่และน่าเกลียด แล้วมันจะไม่มีอิทธิพลต่อคุณได้อย่างไร |ขณะนี้ อสังหาริมทรัพย์ของครอบครัวดิฉันไม่มีค่าอะไร แต่อย่างน้อยมันเคยเป็นบ้านของเราและเป็นสิ่งเดียวที่เรามี |และดิฉันโชคดีที่มีบ้านและความรักที่มีอยู่ในนั้น พร้อมได้รับความช่วยเหลือ |จากครูอาจารย์ ผู้ให้คำแนะนำ และเพื่อนๆ มาโดยตลอด ก็ถือว่าพอแล้วทำไมเรื่องนี้ถึงได้สำคัญเนื่องจากความเสื่อมถอยทางเศรษฐกิจและทัศนคติในการวางแผน |ก่อให้เกิดความเสื่อมถอยทางสิ่งแวดล้อม ซึ่งก่อให้เกิดความเสื่อมทางสังคมตามมาการถอนการลงทุนที่เริ่มต้นในทศวรรษที่ 1960 |ทำให้เกิดช่วงเวลาของความอยุติธรรมทางด้านสิ่งแวดล้อมที่จะมาถึงการจัดโซนนิ่งและกฏข้อบังคับการใช้ที่ดินที่ล้าสมัยยังคงถูกใช้อยู่จนถึงทุกวันนี้เพื่อจัดตั้งโรงงานที่สร้างมลพิษในละแวกบ้านของดิฉันต่อไป |เมื่อมีการกำหนดนโยบายการใช้ที่ดินขึ้นมา ปัจจัยเหล่านี้ถูกหยิบยกมาพิจารณาหรือไม่มีค่าใช้จ่ายอะไรบ้างที่เกี่ยวข้องกับการตัดสินใจเหล่านี้ และใครเป็นคนจ่าย |ใครได้ประโยชน์ มีอะไรมาแสดงให้เห็นว่าชุมชนในท้องถิ่นนี้ผ่านอะไรมาบ้าง |นี่คือ \\'การวางแผน\\'--ในเครื่องหมายคำพูด--ที่ไม่ได้ยึดเอาผลประโยชน์สูงสุดของเราเป็นหลักเมื่อเราตระหนักในเรื่องนี้ เราจึงตัดสินใจว่าถึงเวลาแล้วที่เราจะทำการวางแผนเอง |สวนสาธารณะเล็กๆ ที่ดิฉันบอกคุณเอาไว้ในตอนต้นคือขั้นแรกของการสร้างกระบวนการเส้นทางสีเขียวในเซาท์บรองซ์ |ดิฉันได้ให้เงินสนับสนุนระบบการขนส่งของรัฐบาลกลางจำนวน 1.25 ล้านเหรียญ |เพื่อออกแบบแผนผังสำหรับพื้นที่โล่งริมฝั่งน้ำที่มีเลนสำหรับรถจักรยานบนท้องถนนการปรับปรุงแก้ไขที่เป็นรูปธรรมจะช่วยแจ้งนโยบายสาธารณะเรื่องความปลอดภัยในการจราจร |สถานที่ตั้งโรงงานขยะและโรงงานอื่นๆ |ซึ่งหากได้ดำเนินการอย่างเหมาะสมแล้ว จะต้องไม่เป็นภัยต่อคุณภาพชีวิตของคนในชุมชนการปรับปรุงแก้ไขนั้นจะให้โอกาสในการดำเนินการอย่างเป็นรูปธรรมมากขึ้น |นอกจากนี้ยังเป็นการพัฒนาเศรษฐกิจในท้องถิ่นคิดถึงร้านจักรยานหรือแผงขายน้ำผลไม้เราได้รับเงิน 20 ล้านเหรียญเพื่อสร้างโครงการในระยะแรกนี่คือลาฟาเยตเอวินิว--ซึ่งถูกออกแบบใหม่โดยแมทธิว-นิลเซน สถาปนิกด้านภูมิทัศน์และเมื่อถนนเส้นนี้ถูกสร้างขึ้น มันจะเชื่อมต่อเซาท์บรองซ์กับสวนสาธารณะ Randall\\'s Island ที่มีพื้นที่มากกว่า 400 เอเคอร์ |ขณะนี้ เราถูกแบ่งออกด้วยพื้นที่น้ำประมาณ 25 ฟุต แต่ทางเชื่อมนี้จะเปลี่ยนแปลงสภาพนี้เมื่อเราดูแลรักษาสิ่งแวดล้อมทางธรรมชาติ ความอุดมสมบูรณ์ของมันจะให้กลับคืนแก่เรามากกว่าเดิมหลายเท่า |เราดำเนินโครงการที่เรียกว่า Bronx Ecological Stewardship Trainingซึ่งให้การฝึกอบรมงานในสาขาการฟื้นฟูทางระบบนิเวศน์เพื่อให้บุคลากรจากชุมชนของเรามีทักษะที่จะใช้แข่งขันเพื่อหางานที่มีรายได้ดีเหล่านั้นได้เรากำลังหว่านเมล็ดพันธุ์ลงในพื้นที่แห่งนี้ทีละเล็กละน้อยด้วยงานสีเขียว |แล้วผู้ที่มีส่วนได้เสียทั้งด้านการเงินและส่วนตัวในสิ่งแวดล้อมของตนเองทางด่วนเชอริแดนถือเป็นอนุสรณ์สถานของยุคโรเบิร์ด โมส ที่ไม่ได้ใช้ประโยชน์ |ถูกสร้างโดยไม่ได้คำนึงถึงพื้นที่อาศัยที่ถูกทางด่วนแบ่งแยกแม้ในชั่วโมงเร่งด่วน ทางด่วนก็ยังไม่ได้ถูกใช้งานเลย |ชุมชนได้สร้างแผนผังการคมนาคมทางเลือกที่อนุญาตสำหรับให้มีการยกเลิกทางหลวงตอนนี้เรามีโอกาสให้ผู้มีส่วนได้ส่วนเสียมาร่วมกันเพื่อคิดกันใหม่ว่าทำอย่างไรจึงจะใช้ประโยชน์จากพื้นที่ 28 เอเคอร์สำหรับพื้นที่สวนที่อยู่อาศัยราคาประหยัดและการพัฒนาเศรษฐกิจในท้องถิ่นเรายังสร้าง -- โครงการสาธิตหลังคาให้ความเย็นและมีสีเขียวแห่งแรกของเมืองนิวยอร์ก |ไว้ที่ชั้นบนสุดของสำนักงานของเรา |หลังคาให้ความเย็นจะมีพื้นผิวที่สะท้อนแสงสูงที่ไม่ดูดซับความร้อนจากแสงอาทิตย์และส่งผ่านไปยังอาคารหรือชั้นบรรยากาศ |หลังคาสีเขียวทำด้วยดินและต้นไม้ที่มีชีวิตซึ่งเราสามารถใช้แทนวัสดุการทำหลังคาจากปิโตรเลียมที่ดูดซับความร้อน มีส่วนทำให้เกิดผล \"เกาะร้อนระอุ\"ในเขตเมืองและเสื่อมสภาพภายใต้แสงอาทิตย์ |ซึ่งเรารับกลับคืนด้วยการสูดอากาศ หลังคาสีเขียวยังช่วยกักเก็บปริมาณน้ำฝนที่ตกลงมาได้ถึง 75 เปอร์เซนต์เพื่อให้ช่วยลดความต้องการของเมืองในการอัดฉีดเงินกับการแก้ปัญหาที่ปลายเหตุที่มีราคาแพงซึ่งมักจะอยู่ในชุมชนที่มีความยุติธรรมทางสิ่งแวดล้อมโดยบังเอิญเหมือนอย่างในชุมชนของดิฉัน |และมันยังช่วยให้ที่อยู่อาศัยแก่เพื่อนตัวน้อยๆ ของเราเลย----เยี่ยมจริงๆ! |อย่างไรก็ตาม โครงการสาธิตเป็นก้าวกระโดดสำหรับธุรกิจการติดตั้งหลังคาสีเขียวของเรา |นำมาซึ่งงานทำและกิจกรรมทางเศรษฐกิจที่ยั่งยืนสู่เซาท์บรองซ์ |  ดิฉันก็ชอบเหมือนกันแต่อย่างไร ดิฉันทราบว่าคริสได้บอกกับพวกเราว่าจะไม่ขายสินค้าที่นี่ |ทว่าตั้งแต่ดิฉันได้รับความสนใจจากพวกคุณ เราต้องการผู้ลงทุน ปิดการขายการขอให้ยกโทษน่าจะดีกว่าการขออนุญาต |ยังไงก็ตาม--  |โอเคค่ะ คาทริน่า ก่อนที่คาทริน่าจะมา เซาท์บรองซ์และเขต Ninth Ward ของนิวออร์ลีน |มีหลายสิ่งที่เหมือนกัน เมืองทั้งสองจะมีคนจนผิวสีอาศัยอยู่เป็นจำนวนมากและยังเป็นแหล่งเพาะนวัตกรรมทางวัฒนธรรม เช่น ฮิพฮอพและแจ๊สทั้งสองแห่งยังเป็นชุมชนเขตริมฝั่งน้ำที่เป็นเจ้าบ้านให้กับทั้งอุตสาหกรรมและผู้พักอาศัยได้อยู่อย่างใกล้ชิดซึ่งกันและกัน |ในยุคหลังอุทกภัยคาทริน่า เราก็ยังคงคล้ายกันมากขึ้นพวกเราถูกละเลยมากที่สุดและที่แย่จริงๆ พวกเราถูกใส่ร้ายและถูกข่มเหงโดยหน่วยงานออกกฎหมายของรัฐที่เพิกเฉย การจัดโซนนิ่งที่ร้ายกาจและความรับผิดชอบที่หย่อนยานของทางฝ่ายปกครอง |ความพินาศของ Ninth Ward และเซาท์บรองซ์เป็นสิ่งที่หลีกเลี่ยงไม่ได้แต่เราก้าวออกมาพร้อมกับบทเรียนที่ล้ำค่าเกี่ยวกับวิธีการเอาตัวของเราออกจากปัญหาเราเป็นมากกว่าสัญลักษณ์ความสว่างไสวในเมืองระดับชาติ |หรือปัญหาที่จะต้องได้รับการการแก้ไขโดยคำมั่นสัญญาลมๆ แล้งๆ ของบรรดาประธานาธิบดีที่มาแล้วก็จากไป |ตอนนี้พวกเราจะปล่อยให้กัลฟ์โคสท์เสื่อมโทรมไปเป็นเวลานับสิบหรือยี่สิบปีเหมือนอย่างที่เซาท์บรองซ์หรือ |หรือเราจะดำเนินการเชิงรุกและเรียนรู้จากทรัพยากรที่ถูกผลิตขึ้นเองของนักกิจกรรมระดับรากหญ้าที่เกิดมาพร้อมกับความสิ้นหวังในชุมชนอย่างเช่นดิฉันหรือคะฟังนะคะ ดิฉันไม่ได้คาดหวังว่าบุคคล |บริษัท หรือรัฐบาลที่จะทำให้โลกนี้ดีขึ้นเพราะเป็นเรื่องของสิทธิและศีลธรรมจรรยาการนำเสนอในวันนี้จะเสนอเฉพาะเรื่องบางเรื่องที่ดิฉันได้ผ่านมาแล้ว |เพียงเรื่องเล็กน้อย คุณจะไม่เข้าใจแต่ดิฉันจะบอกคุณทีหลังถ้าคุณต้องการจะรู้ |แต่--ดิฉันรู้ว่ามันเป็นผลท้ายสุดหรือเป็นความเข้าใจของคนบางคน |ที่ดลใจผู้คนในท้ายที่สุดดิฉันสนใจในสิ่งที่ดิฉันชอบเรียกว่า \"ผลสุดท้ายยกกำลังสาม\"ที่การพัฒนาอย่างยั่งยืนสามารถสร้างได้การพัฒนาต่างๆ ที่มีศักยภาพในการสร้างผลตอบแทนเชิงบวกให้กับความกังวลใจทั้งหมด |เช่น นักพัฒนา ภาครัฐ และชุมชนที่มีโครงการเหล่านี้ในปัจจุบัน สิ่งดังกล่าวไม่เกิดขึ้นในเมืองนิวยอร์กและเราดำเนินการโดยมีการขาดทุนในการวางแผนผังที่ครอบคลุมเงินสนับสนุนจำนวนมากจากภาครัฐกำลังเตรียมเสนอสร้างอาคารห้างร้านขนาดใหญ่ |และการพัฒนาสนามกีฬาในเซาท์บรองซ์แต่ยังขาดความร่วมมือกันระหว่างตัวแทนของเมืองในเรื่องการรับมือกับผลกระทบสะสมของปัญหาการจราจร มลพิษ ขยะที่ไม่ย่อยสลายและผลกระทบกับพื้นที่ว่าง อีกทั้งวิธีจัดการต่างๆ กับเศรษฐกิจในท้องถิ่นและการพัฒนางานก็เลื่อนลอย ไม่ใช่แม้แต่เป็นเรื่องตลกเพราะนอกจากนี้แล้ว ทีมกีฬาที่ร่ำรวยที่สุดในโลกต่างๆ กำลังเข้ามาแทนที่บ้านหลังที่รุทธ์สร้างด้วยการทำลายสวนสาธารณะอันเป็นที่รักของชุมชนถึงสองแห่ง |ตอนนี้ เราจะมีเหลือน้อยกว่านั้นอีก อย่างที่ดิฉันได้บอกไปก่อนหน้านี้และแม้ว่าผู้อาศัยในเซาท์บรองซ์จะเป็นเจ้าของรถยนต์น้อยกว่า 25 เปอร์เซนต์โครงการต่างๆ เหล่านี้กลับมีพื้นที่จอดรถใหม่หลายพันแห่ง |แต่เงียบกริบในเรื่องระบบขนส่งมวลชนตอนนี้สิ่งที่หายไปจากการอภิปรายครั้งใหญ่คือการวิเคราะห์ต้นทุน-กำไรที่ครอบคลุมระหว่างการไม่แก้ไข |ชุมชนอันอ่อนแอที่ได้ผลกระทบด้านสิ่งแวดล้อม กับการเปลี่ยนแปลง |ด้านโครงสร้างที่ยั่งยืนเอเจนซี่ของดิฉันทำงานกับมหาวิทยาลัยโคลัมเบียและที่อื่นๆ อย่างใกล้ชิดเพื่อหาความกระจ่างต่อปัญหาเหล่านี้ตอนนี้ขอให้เข้าใจด้วยว่า ดิฉันไม่ต่อต้านการพัฒนา |เมืองของเราเป็นเมือง ไม่ใช่พื้นที่ป่าสงวน และดิฉันได้ยอมรับนายทุนที่อยู่ในตัวของฉันเองและคุณทุกคนอาจจะมีด้วย และถ้าคุณไม่มี คุณจะต้องมีมันด้วย | ฉะนั้น ดิฉันไม่มีปัญหากับการที่นักพัฒนาทำเงินมีเรื่องราวที่เกิดมาก่อนให้ดูพอที่จะแสดงให้เห็นว่า |การพัฒนาที่ยั่งยืนและเป็นมิตรกับชุมชนยังสามารถสร้างความรุ่งเรืองได้เพื่อนดิฉัน เทดสเตอร์ บิล แมคโดนาฟ และ เอเมอรี่ เลอฟินส์ |ซึ่งทั้งคู่ก็เป็นฮี่โร่ในดวงใจของดิฉัน--ได้แสดงให้เห็นว่าคุณสามารถทำได้จริงๆ |ดิฉันมีปัญหากับการพัฒนาที่แสวงประโยชน์อย่างน่าเกลียดจากชุมชนที่เปราะบางต่อการเลือกปฏิบัติที่ยังคงเป็นสิ่งน่าอับอายสำหรับเราทั้งหมดต่อไป |เพราะเราทุกคนต้องรับผิดชอบต่ออนาคตที่เราสร้างขึ้นมา |แต่สิ่งหนึ่งที่ดิฉันทำเพื่อเตือนตัวเองถึงความเป็นไปได้ที่ยิ่งใหญ่กว่า คือการเรียนรู้จากผู้มีวิสัยทัศน์ในเมืองอื่นๆมันคือเรื่องราวของยุคโลกาภิวัฒน์ของดิฉัน |ดูที่โบโกต้า ชาวลาตินที่น่าสงสารที่ถูกแวดล้อมไปด้วยเด็กหนึออกจากบ้าน ปืน ความรุนแรงและการค้ายาเสพติด ชื่อเสียงที่ไม่แตกต่างไปจากของเซาท์บรองซ์แต่ถึงอย่างไร เมืองนี้ได้รับการคุ้มครองในช่วงปลายทศวรรษที่ 1990 |จากนายกเทศมนตรีที่มีอิทธิพลมากชื่อ เอนริเก้ เพนาโลซาเขาดูที่สถิติประชากรมีชาวโบกาต้าไม่กี่คนที่เป็นเจ้าของรถยนต์ แต่ทรัพยากรของเมืองส่วนมากได้ถูกนำไปใช้เพื่อรองรับคนเหล่านี้ถ้าคุณเป็นนายกเทศมนตรี คุณน่าจะทำอะไรสักอย่างกับเรื่องนี้ทีมบริหารของเขาได้บีบถนนนในเมืองสายสำคัญๆ ลงจากถนน 5 เลนเป็น 3 เลนการจอดรถบนถนนเหล่านั้นถือว่าผิดกฏหมาย ขยายทางเดินเท้าและเลนรถจักรยาน สร้างลานสาธารณะสร้างหนึ่งในระบบขนส่งมวลชนที่มีประสิทธิภาพมากที่สุดในโลกขึ้น |จากการดำเนินการที่ปราดเปรื่อง เขาเกือบถูกกล่าวโทษ |แต่เมื่อผู้คนเริ่มมองเห็นว่า พวกเขาถูกเหลียวแลเป็นอันดับแรกในปัญหาต่างๆ |สะท้อนชีวิตประจำวันของพวกเขา สิ่งเหลือเชื่อได้เกิดขึ้น |ผู้คนหยุดทิ้งขยะเกลื่อนกลาด อัตราอาชญากรรมลดลงเพราะบนถนนหนทางนั้นเต็มไปด้วยผู้คนทีมบริหารของเขาได้เข้าแก้ปัญหาทั่วไปในเขตเมืองหลายปัญหาในครั้งเดียว |และด้วยงบประมาณระดับโลกที่สามเราไม่มีข้อแก้ตัวใดๆ ในประเทศนี้ ดิฉันเสียใจด้วยค่ะ |แต่ผลสุดท้ายคือ จุดประสงค์ที่ให้ประชาชนมาก่อนไม่ได้หมายความว่าเพื่อลงโทษคนที่สามารถหาซื้อรถยนต์เองได้แต่เพื่อให้โอกาสแก่ชาวโบกาต้าทั้งหมดในการมีส่วนร่วม |ในการฟื้นคืนสภาพของเมือง นั่นคือการพัฒนาไม่ควรมาพร้อมกับค่าใช้จ่าย |ของประชากรส่วนใหญ่ที่ยังคงถูกมองว่าเป็นผู้มีแนวคิดรุนแรงในสหรัฐอเมริกา |แต่ตัวอย่างของโบโกต้ามีอำนาจที่จะเปลี่ยนแปลงเรื่องนั้นอย่างไรก็ตาม คุณได้รับพรด้วยของขวัญแห่งอิทธิพลเหตุนี้ คุณถึงอยู่ที่นี่และให้ความสำคัญกับข้อมูลที่เราแลกเปลี่ยนกันใช้แรงจูงใจของคุณเองในการสนับสนุนการเปลี่ยนแปลงอย่างยั่งยืนทุกหนทุกแห่งอย่าเพียงแค่พูดถึงเรื่องนี้ที่ TED นี่คือแผนนโยบายทั่วประเทศที่ดิฉันพยายามจะสร้าง |และดังที่คุณทั้งหมดทราบว่า การเมืองเป็นเรื่องส่วนบุคคลมาช่วยดิฉันทำให้คนผิวดำรุ่นใหม่ให้มีสีเขียว ช่วยดิฉันทำให้ความยั่งยืนเซ็กซี่ |ทำให้มันเป็นส่วนหนึ่งของการสนทนาช่วงอาหาเย็นและงานเลี้ยงค๊อกเทลมาร่วมกับดิฉันต่อสู้เพื่อความยุติธรรมทางสิ่งแวดล้อมและเศรษฐกิจสนับสนุนการลงทุนด้วยผลตอบแทนสุดท้ายยกกำลังสาม |ช่วยดิฉันสร้างประชาธิปไตยให้แก่ความยั่นยืนด้วยการนำทุกคนมาร่วมนั่งโต๊ะ |และยืนยันว่าการวางแผนผังที่ครอบคลุมจะสามารถกล่าวถึงได้ทุกหนทุกแห่งดีจังค่ะ ดีจังที่ยังพอมีเวลาเหลือนิดหน่อย!ฟังนะคะ--เมื่อดิฉันพูดกับคุณกอร์หลังอาหารเช้าของวันก่อน |ดิฉันถามว่า นักกิจกรรมเพื่อความเป็นธรรมทางสิ่งแวดล้อมจะถูกรวมไว้ในแผนกลยุทธ์ทางการตลาดแบบใหม่อย่างไรคำตอบของเขาคือแผนการให้เงินทุนสนับสนุนดิฉันไม่คิดว่าเขาเข้าใจ ดิฉันไม่ได้ขอเงินทุน |ดิฉันเสนอเงินทุนให้เขาต่างหาก สิ่งที่กวนใจดิฉันคือวิธีดำเนินการจากบนลงล่างยังคงมีอยู่ |ตอนนี้ อย่าเข้าใจดิฉันผิดนะคะ เราต้องการเงิน  |แต่เราต้องการให้มีกลุ่มคนรากหญ้าที่โต๊ะในช่วงของกระบวนการตัดสินใจ |90 เปอร์เซนต์ของพลังงานที่คุณกอร์ได้เตือนพวกเราไว้ว่าเราเสียไปทุกๆ วัน |อย่าเพิ่มการสูญเสียพลังงาน ความชาญฉลาดประสบการณ์ที่ได้มาด้วยความยากลำบากเข้าไปด้วย ดิฉันได้เดินทางมาไกลเพื่อพบปะกับคุณแบบนี้ |โปรดอย่าให้ดิฉันต้องสูญเปล่า ด้วยการร่วมมือกันเราสามารถกลายเป็นหนึ่งในกลุ่มคนเล็กๆ ที่เติบโตอย่างรวดเร็ว |ซึ่งมีความเด็ดเดี่ยวและกล้าหาญอย่างแท้จริงที่เขื่อว่าเราสามารถเปลี่ยนโลกนี้ได้จริงพวกเราอาจมาร่วมการสัมนานี้จากสถานที่ที่ต่างกันอย่างมากในชีวิต |แต่เชื่อดิฉันเถอะ เราทั้งหมดแบ่งปันสิ่งหนึ่งที่ทรงพลังเหลือเชื่อเราไม่มีอะไรจะเสียและมีทุกสิ่งอย่างที่จะได้รับ |สวัสดีค่ะ ลาก่อน '],\n",
       "      dtype='<U28162')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "liUDUQ9tugag"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['การเขียนไหลเวียนได้ดีตลอดทั้งเล่ม |อย่างไรก็ตามมีบางส่วนที่รู้สึกไม่สมจริง ',\n",
       "       'รายการนี้ยอดเยี่ยมมาก |มันทำให้เสื้อสุนัขแห้ง |แต่มันก็รั่วไหล ',\n",
       "       'ฉันไม่รู้ว่ามันเป็นชุดของเรื่องสั้น |สองคนแรกนั้นดีมาก แต่มันก็จบลงอย่างกะทันหัน ',\n",
       "       'ฉันใช้ Windows 8 และจะไม่เชื่อมต่อกับโทรศัพท์ของฉัน |เสียเวลากับมัน ... คุณสามารถพูดอะไรได้อีก! ',\n",
       "       'มันเยี่ยมมาก |รักมัน |ความคุ้มครองประเภทนี้ควรใช้งานได้ดีสำหรับคุณ |ขอบคุณมาก. ',\n",
       "       'ไม่ทำงาน. |ไม่คุ้มที่จะลองใช้ |โฆษณาที่ทำให้เข้าใจผิดมาก |พวกเขาต้องการการติดฉลากสินค้าจากผู้ขายรายอื่นให้ดีขึ้น ',\n",
       "       'ฉันสนุกกับการดูหนังเรื่องนี้ก่อนที่จะได้เห็นงานของ David Lynch ทั้งหมด |ซาวด์แทร็กเพลงที่สร้างขึ้นโดย John Williams ในช่วงเวลานี้เป็นเพลงโปรดของฉันเสมอ ',\n",
       "       'ฉันรักรสชาติของกาแฟนี้ |อย่างไรก็ตามคุณไม่สามารถรับได้ในร้านค้าในพื้นที่ของฉัน |แย่มากเพราะฉันต้องเปลี่ยนยี่ห้อ ',\n",
       "       'นี่คือการซื้อเป็นของขวัญดังนั้นหลังจากรับด้วยไม่มีปัญหา |จากนั้นรับอีกอันหนึ่ง |เสียงที่ยอดเยี่ยมอีกครั้ง! |ลูกสาวของฉันต้องการเธอ ',\n",
       "       'สนุกและสนุกมาก |อ่านอย่างรวดเร็วฉันไม่สามารถวางมันลง |เป็นนิยายรักที่น่ารักจริงๆ |แนะนำอย่างแน่นอน :) '],\n",
       "      dtype='<U582')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_review_all_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mhtwlRKOj7xF"
   },
   "outputs": [],
   "source": [
    "# Sample from 3 datasets\n",
    "np.random.seed(42)\n",
    "ratio = .25 # sample ratio\n",
    "ted_sample = np.random.choice(ted_all_sentences, int(len(ted_all_sentences) * ratio))\n",
    "orchid_sample = orchid.iloc[:int(len(orchid) * ratio)]\n",
    "# fake_review_sample = np.random.choice(fake_review_all_sentences, int(len(fake_review_all_sentences) * ratio))\n",
    "fake_review_train, fake_review_test = fake_review_all_sentences[:-39632], fake_review_all_sentences[-39632:]\n",
    "fake_review_sample = np.random.choice(fake_review_train, int(len(fake_review_all_sentences) * ratio))\n",
    "fake_review_test_sample = np.random.choice(fake_review_test, int(len(fake_review_test) * ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tcWA1ELDkA0V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of TED talk (talk): 385\n",
      "Length of orchid (word): 91453\n",
      "Length of fake review train (review): 49540\n",
      "Length of fake review test (review): 9908\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of TED talk (talk): {len(ted_sample)}\")\n",
    "print(f\"Length of orchid (word): {len(orchid_sample)}\")\n",
    "print(f\"Length of fake review train (review): {len(fake_review_sample)}\")\n",
    "print(f\"Length of fake review test (review): {len(fake_review_test_sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xhbX0s8UkCZA"
   },
   "outputs": [],
   "source": [
    "def assign_word_lab(all_sentences):\n",
    "    all_tuples = []\n",
    "    for i in tqdm(range(len(all_sentences)), total=len(all_sentences)):\n",
    "        tuples = []\n",
    "        for s in all_sentences[i].split('|'):\n",
    "            s_lst = word_tokenize(s)\n",
    "            for j in range(len(s_lst)):\n",
    "                lab = 'E' if j==len(s_lst)-1 else 'I'\n",
    "                tuples.append((s_lst[j],lab))\n",
    "        all_tuples.append(tuples)\n",
    "    return all_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RwmpTnUwkITC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:18<00:00, 20.59it/s]\n",
      "100%|██████████| 49540/49540 [01:24<00:00, 584.57it/s]\n",
      "100%|██████████| 9908/9908 [00:14<00:00, 706.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 11s, sys: 2.46 s, total: 2min 14s\n",
      "Wall time: 2min 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ted_all_tuples = assign_word_lab(ted_sample)\n",
    "orchid_all_tuples = [(row['word'],row['lab']) for i,row in orchid_sample.iterrows()]\n",
    "# fake_review_all_tuples = assign_word_lab(fake_review_sample)\n",
    "fake_review_all_tuples = assign_word_lab(fake_review_sample)\n",
    "fake_review_test_tuples = assign_word_lab(fake_review_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BsY0JGUYkJZk"
   },
   "outputs": [],
   "source": [
    "enders = [\"ครับ\",\"ค่ะ\",\"คะ\",\"นะคะ\",\"นะ\",\"จ้ะ\",\"จ้า\",\"จ๋า\",\"ฮะ\", #ending honorifics\n",
    "          #enders\n",
    "          \"ๆ\",\"ได้\",\"แล้ว\",\"ด้วย\",\"เลย\",\"มาก\",\"น้อย\",\"กัน\",\"เช่นกัน\",\"เท่านั้น\",\n",
    "          \"อยู่\",\"ลง\",\"ขึ้น\",\"มา\",\"ไป\",\"ไว้\",\"เอง\",\"อีก\",\"ใหม่\",\"จริงๆ\",\n",
    "          \"บ้าง\",\"หมด\",\"ทีเดียว\",\"เดียว\",\n",
    "          #demonstratives\n",
    "          \"นั้น\",\"นี้\",\"เหล่านี้\",\"เหล่านั้น\",\n",
    "          #questions\n",
    "          \"อย่างไร\",\"ยังไง\",\"หรือไม่\",\"มั้ย\",\"ไหน\",\"อะไร\",\"ทำไม\",\"เมื่อไหร่\"]\n",
    "starters = [\"ผม\",\"ฉัน\",\"ดิฉัน\",\"ชั้น\",\"คุณ\",\"มัน\",\"เขา\",\"เค้า\",\n",
    "            \"เธอ\",\"เรา\",\"พวกเรา\",\"พวกเขา\", #pronouns\n",
    "            #connectors\n",
    "            \"และ\",\"หรือ\",\"แต่\",\"เมื่อ\",\"ถ้า\",\"ใน\",\n",
    "            \"ด้วย\",\"เพราะ\",\"เนื่องจาก\",\"ซึ่ง\",\"ไม่\",\n",
    "            \"ตอนนี้\",\"ทีนี้\",\"ดังนั้น\",\"เพราะฉะนั้น\",\"ฉะนั้น\",\n",
    "            \"ตั้งแต่\",\"ในที่สุด\",\n",
    "            #demonstratives\n",
    "            \"นั้น\",\"นี้\",\"เหล่านี้\",\"เหล่านั้น\"]\n",
    "\n",
    "def extract_features(doc, window=2, max_n_gram=3):\n",
    "    doc_features = []\n",
    "    #paddings for word and POS\n",
    "    doc = ['xxpad' for i in range(window)] + doc + ['xxpad' for i in range(window)]\n",
    "    doc_ender = []\n",
    "    doc_starter = []\n",
    "    #add enders\n",
    "    for i in range(len(doc)):\n",
    "        if doc[i] in enders:\n",
    "            doc_ender.append('ender')\n",
    "        else:\n",
    "            doc_ender.append('normal')\n",
    "    #add starters\n",
    "    for i in range(len(doc)):\n",
    "        if doc[i] in starters:\n",
    "            doc_starter.append('starter')\n",
    "        else:\n",
    "            doc_starter.append('normal')\n",
    "    #for each word\n",
    "    for i in range(window, len(doc)-window):\n",
    "        #bias term\n",
    "        word_features = ['bias'] \n",
    "        \n",
    "        #ngram features\n",
    "        for n_gram in range(1, min(max_n_gram+1,2+window*2)):\n",
    "            for j in range(i-window,i+window+2-n_gram):\n",
    "                feature_position = f'{n_gram}_{j-i}_{j-i+n_gram}'\n",
    "                word_ = f'{\"|\".join(doc[j:(j+n_gram)])}'\n",
    "                word_features += [f'word_{feature_position}={word_}']\n",
    "                ender_ =  f'{\"|\".join(doc_ender[j:(j+n_gram)])}'\n",
    "                word_features += [f'ender_{feature_position}={ender_}']\n",
    "                starter_ =  f'{\"|\".join(doc_starter[j:(j+n_gram)])}'\n",
    "                word_features += [f'starter_{feature_position}={starter_}']\n",
    "        \n",
    "        #append to feature per word\n",
    "        doc_features.append(word_features)\n",
    "    return doc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "t2hUmMtdkLzi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:00<00:00, 1485.29it/s]\n",
      "100%|██████████| 385/385 [00:00<00:00, 1581.82it/s]\n",
      "100%|██████████| 385/385 [00:46<00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.1 s, sys: 3.53 s, total: 46.6 s\n",
      "Wall time: 46.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ted\n",
    "# target\n",
    "ted_y = []\n",
    "for t in tqdm(ted_all_tuples, total=len(ted_all_tuples)):\n",
    "    temp = []\n",
    "    for (w, l) in t:\n",
    "        temp.append(l)\n",
    "    ted_y.append(temp)\n",
    "\n",
    "# features\n",
    "ted_x_pre = []\n",
    "for t in tqdm(ted_all_tuples, total=len(ted_all_tuples)):\n",
    "    temp = []\n",
    "    for (w, l) in t:\n",
    "        temp.append(w)\n",
    "    ted_x_pre.append(temp)\n",
    "ted_x = []\n",
    "for x_ in tqdm(ted_x_pre, total=len(ted_x_pre)):\n",
    "    ted_x.append(extract_features(x_, window=2, max_n_gram = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2JmEClQtkQGg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91453/91453 [00:00<00:00, 928733.23it/s]\n",
      "100%|██████████| 91453/91453 [00:00<00:00, 979189.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.19 s, sys: 248 ms, total: 4.43 s\n",
      "Wall time: 4.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# orchid\n",
    "# target\n",
    "orchid_y = []\n",
    "for (w, l) in tqdm(orchid_all_tuples, total=len(orchid_all_tuples)):\n",
    "    orchid_y.append(l)\n",
    "# features\n",
    "orchid_x_pre = []\n",
    "for (w, l) in tqdm(orchid_all_tuples, total=len(orchid_all_tuples)):\n",
    "    orchid_x_pre.append(w)\n",
    "orchid_x = extract_features(orchid_x_pre, window=2, max_n_gram = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A8ZCmpN1kSnK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9908/9908 [00:00<00:00, 41833.14it/s]\n",
      "100%|██████████| 9908/9908 [00:00<00:00, 45552.58it/s]\n",
      "100%|██████████| 9908/9908 [00:40<00:00, 244.66it/s]\n",
      "100%|██████████| 49540/49540 [00:01<00:00, 25354.64it/s]\n",
      "100%|██████████| 49540/49540 [00:01<00:00, 25599.33it/s]\n",
      "100%|██████████| 49540/49540 [03:53<00:00, 212.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# # fake review\n",
    "# # target\n",
    "# fake_review_y = []\n",
    "# for t in tqdm(fake_review_all_tuples, total=len(fake_review_all_tuples)):\n",
    "#     temp = []\n",
    "#     for (w, l) in t:\n",
    "#         temp.append(l)\n",
    "#     fake_review_y.append(temp)\n",
    "\n",
    "# # features\n",
    "# fake_review_x_pre = []\n",
    "# for t in tqdm(fake_review_all_tuples, total=len(fake_review_all_tuples)):\n",
    "#     temp = []\n",
    "#     for (w, l) in t:\n",
    "#         temp.append(w)\n",
    "#     fake_review_x_pre.append(temp)\n",
    "# fake_review_x = []\n",
    "# for x_ in tqdm(fake_review_x_pre, total=len(fake_review_x_pre)):\n",
    "#     fake_review_x.append(extract_features(x_, window=2, max_n_gram = 3))\n",
    "\n",
    "# fake review\n",
    "# Test\n",
    "# target\n",
    "fake_review_test_y = []\n",
    "for t in tqdm(fake_review_test_tuples, total=len(fake_review_test_tuples)):\n",
    "    temp = []\n",
    "    for (w, l) in t:\n",
    "        temp.append(l)\n",
    "    fake_review_test_y.append(temp)\n",
    "\n",
    "# features\n",
    "fake_review_test_x_pre = []\n",
    "for t in tqdm(fake_review_test_tuples, total=len(fake_review_test_tuples)):\n",
    "    temp = []\n",
    "    for (w, l) in t:\n",
    "        temp.append(w)\n",
    "    fake_review_test_x_pre.append(temp)\n",
    "fake_review_test_x = []\n",
    "for x_ in tqdm(fake_review_test_x_pre, total=len(fake_review_test_x_pre)):\n",
    "    fake_review_test_x.append(extract_features(x_, window=2, max_n_gram = 3))\n",
    "    \n",
    "# Train\n",
    "# target\n",
    "fake_review_y = []\n",
    "for t in tqdm(fake_review_all_tuples, total=len(fake_review_all_tuples)):\n",
    "    temp = []\n",
    "    for (w, l) in t:\n",
    "        temp.append(l)\n",
    "    fake_review_y.append(temp)\n",
    "\n",
    "# features\n",
    "fake_review_x_pre = []\n",
    "for t in tqdm(fake_review_all_tuples, total=len(fake_review_all_tuples)):\n",
    "    temp = []\n",
    "    for (w, l) in t:\n",
    "        temp.append(w)\n",
    "    fake_review_x_pre.append(temp)\n",
    "fake_review_x = []\n",
    "for x_ in tqdm(fake_review_x_pre, total=len(fake_review_x_pre)):\n",
    "    fake_review_x.append(extract_features(x_, window=2, max_n_gram = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gCdvNK7ykVXs"
   },
   "outputs": [],
   "source": [
    "# Split train and test set at 80/20 proportion\n",
    "ted_x_train, ted_x_test, ted_y_train, ted_y_test = train_test_split(ted_x, ted_y, test_size=0.2, random_state=1412)\n",
    "idx = int(len(orchid_x)*0.8)\n",
    "orchid_x_train, orchid_x_test = orchid_x[:idx], orchid_x[idx:]\n",
    "orchid_y_train, orchid_y_test = orchid_y[:idx], orchid_y[idx:]\n",
    "# fake_review_x_train, fake_review_x_test, fake_review_y_train, fake_review_y_test \\\n",
    "#     = train_test_split(fake_review_x, fake_review_y, test_size=0.2, random_state=1412)\n",
    "fake_review_x_train, fake_review_x_test = fake_review_x, fake_review_test_x\n",
    "fake_review_y_train, fake_review_y_test = fake_review_y, fake_review_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PKJK7K2AkfSa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:52<00:00,  5.91it/s]\n",
      "100%|██████████| 49540/49540 [04:17<00:00, 192.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 6870888\n",
      "Seconds required: 61.107\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 1.000000\n",
      "c2: 0.000000\n",
      "num_memories: 6\n",
      "max_iterations: 1000\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "***** Iteration #1 *****\n",
      "Loss: 1717751.157588\n",
      "Feature norm: 1.000000\n",
      "Error norm: 1747502.947940\n",
      "Active features: 1341844\n",
      "Line search trials: 1\n",
      "Line search step: 0.000000\n",
      "Seconds required for this iteration: 39.806\n",
      "\n",
      "***** Iteration #2 *****\n",
      "Loss: 1500762.871080\n",
      "Feature norm: 0.875255\n",
      "Error norm: 1676350.089757\n",
      "Active features: 1020801\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.958\n",
      "\n",
      "***** Iteration #3 *****\n",
      "Loss: 1395806.804113\n",
      "Feature norm: 0.393197\n",
      "Error norm: 4720174.754368\n",
      "Active features: 394478\n",
      "Line search trials: 3\n",
      "Line search step: 0.250000\n",
      "Seconds required for this iteration: 54.610\n",
      "\n",
      "***** Iteration #4 *****\n",
      "Loss: 1132097.827070\n",
      "Feature norm: 0.747049\n",
      "Error norm: 1429504.758733\n",
      "Active features: 905316\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.610\n",
      "\n",
      "***** Iteration #5 *****\n",
      "Loss: 963305.087155\n",
      "Feature norm: 0.688933\n",
      "Error norm: 1074245.821822\n",
      "Active features: 905293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.244\n",
      "\n",
      "***** Iteration #6 *****\n",
      "Loss: 819398.050744\n",
      "Feature norm: 0.728087\n",
      "Error norm: 798269.602530\n",
      "Active features: 541100\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 41.901\n",
      "\n",
      "***** Iteration #7 *****\n",
      "Loss: 775750.675470\n",
      "Feature norm: 0.809610\n",
      "Error norm: 418095.934638\n",
      "Active features: 510299\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.075\n",
      "\n",
      "***** Iteration #8 *****\n",
      "Loss: 638021.293198\n",
      "Feature norm: 1.317060\n",
      "Error norm: 599086.954595\n",
      "Active features: 445708\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.375\n",
      "\n",
      "***** Iteration #9 *****\n",
      "Loss: 478515.203598\n",
      "Feature norm: 2.060337\n",
      "Error norm: 545451.018223\n",
      "Active features: 424054\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.409\n",
      "\n",
      "***** Iteration #10 *****\n",
      "Loss: 383160.606134\n",
      "Feature norm: 2.876703\n",
      "Error norm: 340664.066817\n",
      "Active features: 428675\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.975\n",
      "\n",
      "***** Iteration #11 *****\n",
      "Loss: 323931.715994\n",
      "Feature norm: 3.649070\n",
      "Error norm: 172965.222211\n",
      "Active features: 383155\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.156\n",
      "\n",
      "***** Iteration #12 *****\n",
      "Loss: 279818.520272\n",
      "Feature norm: 4.577767\n",
      "Error norm: 112237.978679\n",
      "Active features: 342900\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.504\n",
      "\n",
      "***** Iteration #13 *****\n",
      "Loss: 276574.101854\n",
      "Feature norm: 4.830324\n",
      "Error norm: 374448.035010\n",
      "Active features: 312439\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 41.668\n",
      "\n",
      "***** Iteration #14 *****\n",
      "Loss: 262957.875760\n",
      "Feature norm: 5.948063\n",
      "Error norm: 483825.513302\n",
      "Active features: 309405\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.041\n",
      "\n",
      "***** Iteration #15 *****\n",
      "Loss: 234060.032395\n",
      "Feature norm: 6.276395\n",
      "Error norm: 251779.197010\n",
      "Active features: 304193\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.587\n",
      "\n",
      "***** Iteration #16 *****\n",
      "Loss: 226184.156043\n",
      "Feature norm: 7.029834\n",
      "Error norm: 280178.686911\n",
      "Active features: 298319\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.769\n",
      "\n",
      "***** Iteration #17 *****\n",
      "Loss: 214409.334276\n",
      "Feature norm: 7.239402\n",
      "Error norm: 144490.867554\n",
      "Active features: 298634\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.819\n",
      "\n",
      "***** Iteration #18 *****\n",
      "Loss: 210642.641000\n",
      "Feature norm: 7.763184\n",
      "Error norm: 167474.887286\n",
      "Active features: 293678\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.110\n",
      "\n",
      "***** Iteration #19 *****\n",
      "Loss: 205065.382955\n",
      "Feature norm: 7.922454\n",
      "Error norm: 63344.803072\n",
      "Active features: 292387\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.091\n",
      "\n",
      "***** Iteration #20 *****\n",
      "Loss: 203357.442739\n",
      "Feature norm: 8.294459\n",
      "Error norm: 103144.066015\n",
      "Active features: 288303\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.920\n",
      "\n",
      "***** Iteration #21 *****\n",
      "Loss: 200658.235696\n",
      "Feature norm: 8.466313\n",
      "Error norm: 53215.117857\n",
      "Active features: 285127\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.208\n",
      "\n",
      "***** Iteration #22 *****\n",
      "Loss: 199445.134721\n",
      "Feature norm: 8.781111\n",
      "Error norm: 90824.402994\n",
      "Active features: 279147\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.693\n",
      "\n",
      "***** Iteration #23 *****\n",
      "Loss: 197311.765247\n",
      "Feature norm: 9.007131\n",
      "Error norm: 47375.504478\n",
      "Active features: 274384\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.176\n",
      "\n",
      "***** Iteration #24 *****\n",
      "Loss: 195693.435397\n",
      "Feature norm: 9.318251\n",
      "Error norm: 79105.157192\n",
      "Active features: 269227\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.152\n",
      "\n",
      "***** Iteration #25 *****\n",
      "Loss: 192153.905043\n",
      "Feature norm: 9.584658\n",
      "Error norm: 31855.928817\n",
      "Active features: 264767\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.071\n",
      "\n",
      "***** Iteration #26 *****\n",
      "Loss: 188230.971228\n",
      "Feature norm: 10.497081\n",
      "Error norm: 124458.794314\n",
      "Active features: 256133\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.200\n",
      "\n",
      "***** Iteration #27 *****\n",
      "Loss: 180429.244516\n",
      "Feature norm: 11.349159\n",
      "Error norm: 116716.290481\n",
      "Active features: 249775\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.100\n",
      "\n",
      "***** Iteration #28 *****\n",
      "Loss: 173034.904885\n",
      "Feature norm: 12.731908\n",
      "Error norm: 98881.378348\n",
      "Active features: 243240\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.959\n",
      "\n",
      "***** Iteration #29 *****\n",
      "Loss: 166513.446461\n",
      "Feature norm: 13.751399\n",
      "Error norm: 58748.403291\n",
      "Active features: 237167\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.688\n",
      "\n",
      "***** Iteration #30 *****\n",
      "Loss: 161999.649267\n",
      "Feature norm: 15.279522\n",
      "Error norm: 74235.694474\n",
      "Active features: 228332\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.497\n",
      "\n",
      "***** Iteration #31 *****\n",
      "Loss: 156284.254215\n",
      "Feature norm: 17.144735\n",
      "Error norm: 60590.234789\n",
      "Active features: 220821\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.134\n",
      "\n",
      "***** Iteration #32 *****\n",
      "Loss: 151218.785728\n",
      "Feature norm: 19.771378\n",
      "Error norm: 61675.756552\n",
      "Active features: 213114\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.844\n",
      "\n",
      "***** Iteration #33 *****\n",
      "Loss: 146111.599486\n",
      "Feature norm: 20.847650\n",
      "Error norm: 41781.857666\n",
      "Active features: 204976\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.384\n",
      "\n",
      "***** Iteration #34 *****\n",
      "Loss: 141519.095549\n",
      "Feature norm: 22.223209\n",
      "Error norm: 34377.963117\n",
      "Active features: 198706\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.417\n",
      "\n",
      "***** Iteration #35 *****\n",
      "Loss: 136793.874567\n",
      "Feature norm: 23.723892\n",
      "Error norm: 19040.730561\n",
      "Active features: 191175\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.733\n",
      "\n",
      "***** Iteration #36 *****\n",
      "Loss: 132515.027320\n",
      "Feature norm: 25.583901\n",
      "Error norm: 25699.286272\n",
      "Active features: 181836\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.956\n",
      "\n",
      "***** Iteration #37 *****\n",
      "Loss: 129317.634266\n",
      "Feature norm: 26.769603\n",
      "Error norm: 12177.467491\n",
      "Active features: 175529\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.915\n",
      "\n",
      "***** Iteration #38 *****\n",
      "Loss: 125873.656755\n",
      "Feature norm: 28.727034\n",
      "Error norm: 18659.756887\n",
      "Active features: 167536\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.162\n",
      "\n",
      "***** Iteration #39 *****\n",
      "Loss: 123126.809687\n",
      "Feature norm: 30.675864\n",
      "Error norm: 17968.918601\n",
      "Active features: 158021\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.757\n",
      "\n",
      "***** Iteration #40 *****\n",
      "Loss: 120068.164094\n",
      "Feature norm: 33.264722\n",
      "Error norm: 5868.079017\n",
      "Active features: 144968\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.031\n",
      "\n",
      "***** Iteration #41 *****\n",
      "Loss: 116735.946998\n",
      "Feature norm: 36.963272\n",
      "Error norm: 6749.482631\n",
      "Active features: 132826\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.369\n",
      "\n",
      "***** Iteration #42 *****\n",
      "Loss: 114316.709233\n",
      "Feature norm: 40.638887\n",
      "Error norm: 33449.475776\n",
      "Active features: 124681\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.875\n",
      "\n",
      "***** Iteration #43 *****\n",
      "Loss: 112212.293302\n",
      "Feature norm: 43.087061\n",
      "Error norm: 6376.379858\n",
      "Active features: 123904\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.755\n",
      "\n",
      "***** Iteration #44 *****\n",
      "Loss: 109718.705045\n",
      "Feature norm: 47.392915\n",
      "Error norm: 12318.928152\n",
      "Active features: 120534\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.836\n",
      "\n",
      "***** Iteration #45 *****\n",
      "Loss: 108384.079904\n",
      "Feature norm: 50.051133\n",
      "Error norm: 5006.672160\n",
      "Active features: 118761\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.186\n",
      "\n",
      "***** Iteration #46 *****\n",
      "Loss: 107647.219873\n",
      "Feature norm: 50.566038\n",
      "Error norm: 2388.788082\n",
      "Active features: 117047\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.503\n",
      "\n",
      "***** Iteration #47 *****\n",
      "Loss: 106182.641645\n",
      "Feature norm: 53.707125\n",
      "Error norm: 9043.870920\n",
      "Active features: 112891\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.118\n",
      "\n",
      "***** Iteration #48 *****\n",
      "Loss: 105603.891159\n",
      "Feature norm: 56.887313\n",
      "Error norm: 33158.438578\n",
      "Active features: 109406\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.101\n",
      "\n",
      "***** Iteration #49 *****\n",
      "Loss: 104828.929569\n",
      "Feature norm: 58.643313\n",
      "Error norm: 9800.579564\n",
      "Active features: 110129\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.958\n",
      "\n",
      "***** Iteration #50 *****\n",
      "Loss: 103973.109244\n",
      "Feature norm: 61.718094\n",
      "Error norm: 5675.672932\n",
      "Active features: 108283\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.164\n",
      "\n",
      "***** Iteration #51 *****\n",
      "Loss: 103086.337816\n",
      "Feature norm: 64.572576\n",
      "Error norm: 4325.690102\n",
      "Active features: 103688\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.929\n",
      "\n",
      "***** Iteration #52 *****\n",
      "Loss: 102140.395978\n",
      "Feature norm: 67.918754\n",
      "Error norm: 2664.578784\n",
      "Active features: 100339\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.061\n",
      "\n",
      "***** Iteration #53 *****\n",
      "Loss: 101462.560665\n",
      "Feature norm: 70.456722\n",
      "Error norm: 7938.904856\n",
      "Active features: 94501\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.399\n",
      "\n",
      "***** Iteration #54 *****\n",
      "Loss: 100725.776649\n",
      "Feature norm: 73.816915\n",
      "Error norm: 2627.153662\n",
      "Active features: 93231\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.691\n",
      "\n",
      "***** Iteration #55 *****\n",
      "Loss: 100163.985973\n",
      "Feature norm: 76.326289\n",
      "Error norm: 3847.392976\n",
      "Active features: 92574\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.981\n",
      "\n",
      "***** Iteration #56 *****\n",
      "Loss: 99677.292421\n",
      "Feature norm: 78.218713\n",
      "Error norm: 12392.957428\n",
      "Active features: 91401\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.320\n",
      "\n",
      "***** Iteration #57 *****\n",
      "Loss: 99219.498275\n",
      "Feature norm: 80.177848\n",
      "Error norm: 1387.691812\n",
      "Active features: 91174\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.789\n",
      "\n",
      "***** Iteration #58 *****\n",
      "Loss: 98775.409005\n",
      "Feature norm: 82.728023\n",
      "Error norm: 1909.892485\n",
      "Active features: 88275\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.762\n",
      "\n",
      "***** Iteration #59 *****\n",
      "Loss: 98462.555122\n",
      "Feature norm: 86.295679\n",
      "Error norm: 18004.887486\n",
      "Active features: 86491\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.608\n",
      "\n",
      "***** Iteration #60 *****\n",
      "Loss: 98144.599995\n",
      "Feature norm: 87.604547\n",
      "Error norm: 2229.759686\n",
      "Active features: 85234\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.241\n",
      "\n",
      "***** Iteration #61 *****\n",
      "Loss: 97935.501223\n",
      "Feature norm: 89.128092\n",
      "Error norm: 1399.277622\n",
      "Active features: 84620\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.691\n",
      "\n",
      "***** Iteration #62 *****\n",
      "Loss: 97372.287800\n",
      "Feature norm: 94.109191\n",
      "Error norm: 776.094322\n",
      "Active features: 81696\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.793\n",
      "\n",
      "***** Iteration #63 *****\n",
      "Loss: 97336.822544\n",
      "Feature norm: 93.699796\n",
      "Error norm: 4027.017223\n",
      "Active features: 82193\n",
      "Line search trials: 5\n",
      "Line search step: 0.062500\n",
      "Seconds required for this iteration: 95.824\n",
      "\n",
      "***** Iteration #64 *****\n",
      "Loss: 97154.063449\n",
      "Feature norm: 94.976681\n",
      "Error norm: 1114.591642\n",
      "Active features: 81554\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.862\n",
      "\n",
      "***** Iteration #65 *****\n",
      "Loss: 96813.505314\n",
      "Feature norm: 97.643509\n",
      "Error norm: 2730.730771\n",
      "Active features: 79798\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.530\n",
      "\n",
      "***** Iteration #66 *****\n",
      "Loss: 96649.835830\n",
      "Feature norm: 98.825765\n",
      "Error norm: 10040.550656\n",
      "Active features: 79066\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.361\n",
      "\n",
      "***** Iteration #67 *****\n",
      "Loss: 96443.297936\n",
      "Feature norm: 100.397749\n",
      "Error norm: 783.721424\n",
      "Active features: 78979\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.736\n",
      "\n",
      "***** Iteration #68 *****\n",
      "Loss: 96232.792125\n",
      "Feature norm: 102.030365\n",
      "Error norm: 3590.329967\n",
      "Active features: 78226\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 22.648\n",
      "\n",
      "***** Iteration #69 *****\n",
      "Loss: 96055.913718\n",
      "Feature norm: 103.760637\n",
      "Error norm: 2326.069307\n",
      "Active features: 76383\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.824\n",
      "\n",
      "***** Iteration #70 *****\n",
      "Loss: 95968.916443\n",
      "Feature norm: 104.422071\n",
      "Error norm: 829.144041\n",
      "Active features: 75986\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.051\n",
      "\n",
      "***** Iteration #71 *****\n",
      "Loss: 95785.530809\n",
      "Feature norm: 106.979640\n",
      "Error norm: 3404.193941\n",
      "Active features: 74971\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.611\n",
      "\n",
      "***** Iteration #72 *****\n",
      "Loss: 95688.784108\n",
      "Feature norm: 107.914407\n",
      "Error norm: 5402.373504\n",
      "Active features: 74469\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.610\n",
      "\n",
      "***** Iteration #73 *****\n",
      "Loss: 95587.001937\n",
      "Feature norm: 108.903661\n",
      "Error norm: 652.346850\n",
      "Active features: 73850\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.380\n",
      "\n",
      "***** Iteration #74 *****\n",
      "Loss: 95469.445735\n",
      "Feature norm: 110.359672\n",
      "Error norm: 1769.340830\n",
      "Active features: 72656\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.001\n",
      "\n",
      "***** Iteration #75 *****\n",
      "Loss: 95417.777715\n",
      "Feature norm: 111.954516\n",
      "Error norm: 8599.092649\n",
      "Active features: 71955\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 22.472\n",
      "\n",
      "***** Iteration #76 *****\n",
      "Loss: 95358.509862\n",
      "Feature norm: 112.210027\n",
      "Error norm: 1853.832958\n",
      "Active features: 72148\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.862\n",
      "\n",
      "***** Iteration #77 *****\n",
      "Loss: 95311.215842\n",
      "Feature norm: 112.820065\n",
      "Error norm: 3057.185301\n",
      "Active features: 71813\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.041\n",
      "\n",
      "***** Iteration #78 *****\n",
      "Loss: 95257.009885\n",
      "Feature norm: 113.419877\n",
      "Error norm: 595.099731\n",
      "Active features: 71395\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.838\n",
      "\n",
      "***** Iteration #79 *****\n",
      "Loss: 95190.835922\n",
      "Feature norm: 114.118382\n",
      "Error norm: 1732.352600\n",
      "Active features: 70898\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.859\n",
      "\n",
      "***** Iteration #80 *****\n",
      "Loss: 95153.446493\n",
      "Feature norm: 114.267202\n",
      "Error norm: 2829.233519\n",
      "Active features: 70681\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.077\n",
      "\n",
      "***** Iteration #81 *****\n",
      "Loss: 95110.260951\n",
      "Feature norm: 114.865767\n",
      "Error norm: 1298.074462\n",
      "Active features: 70499\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.366\n",
      "\n",
      "***** Iteration #82 *****\n",
      "Loss: 95067.871170\n",
      "Feature norm: 115.415109\n",
      "Error norm: 1736.086032\n",
      "Active features: 70235\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.186\n",
      "\n",
      "***** Iteration #83 *****\n",
      "Loss: 95031.100410\n",
      "Feature norm: 116.093498\n",
      "Error norm: 1777.653225\n",
      "Active features: 69887\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.053\n",
      "\n",
      "***** Iteration #84 *****\n",
      "Loss: 95002.816645\n",
      "Feature norm: 116.497955\n",
      "Error norm: 916.340203\n",
      "Active features: 69701\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.667\n",
      "\n",
      "***** Iteration #85 *****\n",
      "Loss: 94971.831327\n",
      "Feature norm: 116.965881\n",
      "Error norm: 1333.209703\n",
      "Active features: 69006\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.407\n",
      "\n",
      "***** Iteration #86 *****\n",
      "Loss: 94946.447682\n",
      "Feature norm: 117.425826\n",
      "Error norm: 1303.607373\n",
      "Active features: 68650\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.535\n",
      "\n",
      "***** Iteration #87 *****\n",
      "Loss: 94920.573563\n",
      "Feature norm: 117.741689\n",
      "Error norm: 1390.819589\n",
      "Active features: 68413\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.707\n",
      "\n",
      "***** Iteration #88 *****\n",
      "Loss: 94895.955847\n",
      "Feature norm: 118.086636\n",
      "Error norm: 2025.800771\n",
      "Active features: 68086\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.442\n",
      "\n",
      "***** Iteration #89 *****\n",
      "Loss: 94874.959927\n",
      "Feature norm: 118.339780\n",
      "Error norm: 1162.596393\n",
      "Active features: 67715\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.867\n",
      "\n",
      "***** Iteration #90 *****\n",
      "Loss: 94854.605113\n",
      "Feature norm: 118.577762\n",
      "Error norm: 1334.279203\n",
      "Active features: 67376\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.148\n",
      "\n",
      "***** Iteration #91 *****\n",
      "Loss: 94831.698261\n",
      "Feature norm: 118.781674\n",
      "Error norm: 1060.489308\n",
      "Active features: 66868\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.528\n",
      "\n",
      "***** Iteration #92 *****\n",
      "Loss: 94811.561547\n",
      "Feature norm: 118.987703\n",
      "Error norm: 1289.468009\n",
      "Active features: 66457\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.723\n",
      "\n",
      "***** Iteration #93 *****\n",
      "Loss: 94797.350547\n",
      "Feature norm: 119.138290\n",
      "Error norm: 1857.972589\n",
      "Active features: 66242\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.420\n",
      "\n",
      "***** Iteration #94 *****\n",
      "Loss: 94781.402469\n",
      "Feature norm: 119.252367\n",
      "Error norm: 1651.528952\n",
      "Active features: 66066\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.247\n",
      "\n",
      "***** Iteration #95 *****\n",
      "Loss: 94769.245468\n",
      "Feature norm: 119.387635\n",
      "Error norm: 1046.043780\n",
      "Active features: 65898\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.481\n",
      "\n",
      "***** Iteration #96 *****\n",
      "Loss: 94761.909357\n",
      "Feature norm: 119.466988\n",
      "Error norm: 960.727726\n",
      "Active features: 65880\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 37.397\n",
      "\n",
      "***** Iteration #97 *****\n",
      "Loss: 94752.938004\n",
      "Feature norm: 119.583612\n",
      "Error norm: 1884.122180\n",
      "Active features: 65676\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.110\n",
      "\n",
      "***** Iteration #98 *****\n",
      "Loss: 94745.166099\n",
      "Feature norm: 119.666917\n",
      "Error norm: 3509.129243\n",
      "Active features: 65608\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.589\n",
      "\n",
      "***** Iteration #99 *****\n",
      "Loss: 94729.623928\n",
      "Feature norm: 119.752931\n",
      "Error norm: 553.855513\n",
      "Active features: 65528\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 22.110\n",
      "\n",
      "***** Iteration #100 *****\n",
      "Loss: 94723.063333\n",
      "Feature norm: 119.821348\n",
      "Error norm: 1020.489954\n",
      "Active features: 65391\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.989\n",
      "\n",
      "***** Iteration #101 *****\n",
      "Loss: 94715.222228\n",
      "Feature norm: 119.867228\n",
      "Error norm: 389.986562\n",
      "Active features: 65342\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 37.380\n",
      "\n",
      "***** Iteration #102 *****\n",
      "Loss: 94712.835306\n",
      "Feature norm: 119.946418\n",
      "Error norm: 1307.941161\n",
      "Active features: 65210\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.784\n",
      "\n",
      "***** Iteration #103 *****\n",
      "Loss: 94704.609350\n",
      "Feature norm: 120.013232\n",
      "Error norm: 733.356146\n",
      "Active features: 65109\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.211\n",
      "\n",
      "***** Iteration #104 *****\n",
      "Loss: 94699.968323\n",
      "Feature norm: 120.077686\n",
      "Error norm: 717.858893\n",
      "Active features: 65048\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.955\n",
      "\n",
      "***** Iteration #105 *****\n",
      "Loss: 94698.174749\n",
      "Feature norm: 120.152061\n",
      "Error norm: 782.456154\n",
      "Active features: 64987\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.415\n",
      "\n",
      "***** Iteration #106 *****\n",
      "Loss: 94690.391943\n",
      "Feature norm: 120.200978\n",
      "Error norm: 267.874699\n",
      "Active features: 64905\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.174\n",
      "\n",
      "***** Iteration #107 *****\n",
      "Loss: 94688.866504\n",
      "Feature norm: 120.261947\n",
      "Error norm: 693.558562\n",
      "Active features: 64855\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.434\n",
      "\n",
      "***** Iteration #108 *****\n",
      "Loss: 94683.825330\n",
      "Feature norm: 120.305560\n",
      "Error norm: 1929.638107\n",
      "Active features: 64803\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.136\n",
      "\n",
      "***** Iteration #109 *****\n",
      "Loss: 94683.611619\n",
      "Feature norm: 120.352521\n",
      "Error norm: 3293.184842\n",
      "Active features: 64859\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.056\n",
      "\n",
      "***** Iteration #110 *****\n",
      "Loss: 94678.091265\n",
      "Feature norm: 120.387259\n",
      "Error norm: 462.177468\n",
      "Active features: 64789\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.652\n",
      "\n",
      "***** Iteration #111 *****\n",
      "Loss: 94675.460754\n",
      "Feature norm: 120.424502\n",
      "Error norm: 770.056578\n",
      "Active features: 64736\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.683\n",
      "\n",
      "***** Iteration #112 *****\n",
      "Loss: 94672.608494\n",
      "Feature norm: 120.459082\n",
      "Error norm: 144.103684\n",
      "Active features: 64679\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.729\n",
      "\n",
      "***** Iteration #113 *****\n",
      "Loss: 94670.484039\n",
      "Feature norm: 120.503623\n",
      "Error norm: 697.381850\n",
      "Active features: 64621\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.473\n",
      "\n",
      "***** Iteration #114 *****\n",
      "Loss: 94666.110528\n",
      "Feature norm: 120.552568\n",
      "Error norm: 733.120922\n",
      "Active features: 64544\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.977\n",
      "\n",
      "***** Iteration #115 *****\n",
      "Loss: 94663.502594\n",
      "Feature norm: 120.617614\n",
      "Error norm: 820.179693\n",
      "Active features: 64484\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.552\n",
      "\n",
      "***** Iteration #116 *****\n",
      "Loss: 94660.956224\n",
      "Feature norm: 120.669589\n",
      "Error norm: 543.357419\n",
      "Active features: 64402\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.351\n",
      "\n",
      "***** Iteration #117 *****\n",
      "Loss: 94655.517800\n",
      "Feature norm: 120.706239\n",
      "Error norm: 1296.929915\n",
      "Active features: 64351\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.160\n",
      "\n",
      "***** Iteration #118 *****\n",
      "Loss: 94653.310188\n",
      "Feature norm: 120.722788\n",
      "Error norm: 2087.491470\n",
      "Active features: 64385\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 38.288\n",
      "\n",
      "***** Iteration #119 *****\n",
      "Loss: 94650.896782\n",
      "Feature norm: 120.758814\n",
      "Error norm: 319.692606\n",
      "Active features: 64480\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.293\n",
      "\n",
      "***** Iteration #120 *****\n",
      "Loss: 94646.592518\n",
      "Feature norm: 120.787091\n",
      "Error norm: 681.436156\n",
      "Active features: 64268\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.920\n",
      "\n",
      "***** Iteration #121 *****\n",
      "Loss: 94644.060552\n",
      "Feature norm: 120.810688\n",
      "Error norm: 732.852863\n",
      "Active features: 64205\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 39.765\n",
      "\n",
      "***** Iteration #122 *****\n",
      "Loss: 94643.125581\n",
      "Feature norm: 120.862209\n",
      "Error norm: 1119.358716\n",
      "Active features: 64128\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.150\n",
      "\n",
      "***** Iteration #123 *****\n",
      "Loss: 94637.927113\n",
      "Feature norm: 120.899324\n",
      "Error norm: 1423.720975\n",
      "Active features: 64088\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.568\n",
      "\n",
      "***** Iteration #124 *****\n",
      "Loss: 94634.886080\n",
      "Feature norm: 120.940716\n",
      "Error norm: 1022.108157\n",
      "Active features: 64019\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.045\n",
      "\n",
      "***** Iteration #125 *****\n",
      "Loss: 94631.925635\n",
      "Feature norm: 120.973228\n",
      "Error norm: 858.740071\n",
      "Active features: 63983\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.332\n",
      "\n",
      "***** Iteration #126 *****\n",
      "Loss: 94629.600550\n",
      "Feature norm: 120.998856\n",
      "Error norm: 1038.117191\n",
      "Active features: 63956\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.053\n",
      "\n",
      "***** Iteration #127 *****\n",
      "Loss: 94627.769201\n",
      "Feature norm: 121.033636\n",
      "Error norm: 905.909626\n",
      "Active features: 63901\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.523\n",
      "\n",
      "***** Iteration #128 *****\n",
      "Loss: 94625.852186\n",
      "Feature norm: 121.062771\n",
      "Error norm: 1087.584738\n",
      "Active features: 63869\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.778\n",
      "\n",
      "***** Iteration #129 *****\n",
      "Loss: 94623.354634\n",
      "Feature norm: 121.087181\n",
      "Error norm: 760.655466\n",
      "Active features: 63833\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.844\n",
      "\n",
      "***** Iteration #130 *****\n",
      "Loss: 94622.012541\n",
      "Feature norm: 121.112720\n",
      "Error norm: 865.847344\n",
      "Active features: 63827\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.207\n",
      "\n",
      "***** Iteration #131 *****\n",
      "Loss: 94620.048584\n",
      "Feature norm: 121.137397\n",
      "Error norm: 714.205196\n",
      "Active features: 63810\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.358\n",
      "\n",
      "***** Iteration #132 *****\n",
      "Loss: 94618.792335\n",
      "Feature norm: 121.168297\n",
      "Error norm: 1129.229039\n",
      "Active features: 63769\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.794\n",
      "\n",
      "***** Iteration #133 *****\n",
      "Loss: 94616.471494\n",
      "Feature norm: 121.190880\n",
      "Error norm: 765.361949\n",
      "Active features: 63751\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.383\n",
      "\n",
      "***** Iteration #134 *****\n",
      "Loss: 94615.220936\n",
      "Feature norm: 121.214441\n",
      "Error norm: 809.497673\n",
      "Active features: 63746\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.914\n",
      "\n",
      "***** Iteration #135 *****\n",
      "Loss: 94613.540201\n",
      "Feature norm: 121.236385\n",
      "Error norm: 520.743908\n",
      "Active features: 63706\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.501\n",
      "\n",
      "***** Iteration #136 *****\n",
      "Loss: 94612.599912\n",
      "Feature norm: 121.256875\n",
      "Error norm: 1097.075972\n",
      "Active features: 63658\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.595\n",
      "\n",
      "***** Iteration #137 *****\n",
      "Loss: 94610.610533\n",
      "Feature norm: 121.274856\n",
      "Error norm: 947.545726\n",
      "Active features: 63647\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.331\n",
      "\n",
      "***** Iteration #138 *****\n",
      "Loss: 94609.694660\n",
      "Feature norm: 121.296047\n",
      "Error norm: 614.601747\n",
      "Active features: 63640\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.365\n",
      "\n",
      "***** Iteration #139 *****\n",
      "Loss: 94608.310048\n",
      "Feature norm: 121.316582\n",
      "Error norm: 546.650296\n",
      "Active features: 63609\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.265\n",
      "\n",
      "***** Iteration #140 *****\n",
      "Loss: 94607.067943\n",
      "Feature norm: 121.342117\n",
      "Error norm: 1147.211991\n",
      "Active features: 63565\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.690\n",
      "\n",
      "***** Iteration #141 *****\n",
      "Loss: 94605.498060\n",
      "Feature norm: 121.352885\n",
      "Error norm: 1183.233692\n",
      "Active features: 63568\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.764\n",
      "\n",
      "***** Iteration #142 *****\n",
      "Loss: 94604.525245\n",
      "Feature norm: 121.373048\n",
      "Error norm: 355.046654\n",
      "Active features: 63572\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.290\n",
      "\n",
      "***** Iteration #143 *****\n",
      "Loss: 94603.248806\n",
      "Feature norm: 121.387700\n",
      "Error norm: 663.133919\n",
      "Active features: 63530\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.240\n",
      "\n",
      "***** Iteration #144 *****\n",
      "Loss: 94601.720353\n",
      "Feature norm: 121.405713\n",
      "Error norm: 845.192162\n",
      "Active features: 63496\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.810\n",
      "\n",
      "***** Iteration #145 *****\n",
      "Loss: 94601.011724\n",
      "Feature norm: 121.417767\n",
      "Error norm: 1099.836630\n",
      "Active features: 63488\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.091\n",
      "\n",
      "***** Iteration #146 *****\n",
      "Loss: 94599.498757\n",
      "Feature norm: 121.438533\n",
      "Error norm: 607.445191\n",
      "Active features: 63439\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.833\n",
      "\n",
      "***** Iteration #147 *****\n",
      "Loss: 94598.410505\n",
      "Feature norm: 121.450892\n",
      "Error norm: 762.509064\n",
      "Active features: 63412\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.273\n",
      "\n",
      "***** Iteration #148 *****\n",
      "Loss: 94597.136268\n",
      "Feature norm: 121.469606\n",
      "Error norm: 892.647889\n",
      "Active features: 63393\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.813\n",
      "\n",
      "***** Iteration #149 *****\n",
      "Loss: 94595.916977\n",
      "Feature norm: 121.478939\n",
      "Error norm: 886.929299\n",
      "Active features: 63391\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.214\n",
      "\n",
      "***** Iteration #150 *****\n",
      "Loss: 94594.952397\n",
      "Feature norm: 121.495369\n",
      "Error norm: 608.445217\n",
      "Active features: 63396\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.655\n",
      "\n",
      "***** Iteration #151 *****\n",
      "Loss: 94593.993914\n",
      "Feature norm: 121.507709\n",
      "Error norm: 583.796707\n",
      "Active features: 63349\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.308\n",
      "\n",
      "***** Iteration #152 *****\n",
      "Loss: 94593.104830\n",
      "Feature norm: 121.524053\n",
      "Error norm: 943.272727\n",
      "Active features: 63336\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.436\n",
      "\n",
      "***** Iteration #153 *****\n",
      "Loss: 94592.017678\n",
      "Feature norm: 121.532870\n",
      "Error norm: 789.357365\n",
      "Active features: 63324\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.246\n",
      "\n",
      "***** Iteration #154 *****\n",
      "Loss: 94591.287997\n",
      "Feature norm: 121.542932\n",
      "Error norm: 529.969285\n",
      "Active features: 63321\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.500\n",
      "\n",
      "***** Iteration #155 *****\n",
      "Loss: 94590.366156\n",
      "Feature norm: 121.552802\n",
      "Error norm: 438.652468\n",
      "Active features: 63287\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.322\n",
      "\n",
      "***** Iteration #156 *****\n",
      "Loss: 94589.700970\n",
      "Feature norm: 121.563909\n",
      "Error norm: 889.624849\n",
      "Active features: 63234\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.062\n",
      "\n",
      "***** Iteration #157 *****\n",
      "Loss: 94588.686684\n",
      "Feature norm: 121.573198\n",
      "Error norm: 852.538959\n",
      "Active features: 63202\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.999\n",
      "\n",
      "***** Iteration #158 *****\n",
      "Loss: 94587.755788\n",
      "Feature norm: 121.583949\n",
      "Error norm: 589.970092\n",
      "Active features: 63189\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.867\n",
      "\n",
      "***** Iteration #159 *****\n",
      "Loss: 94586.868447\n",
      "Feature norm: 121.594399\n",
      "Error norm: 671.330033\n",
      "Active features: 63160\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.688\n",
      "\n",
      "***** Iteration #160 *****\n",
      "Loss: 94586.007823\n",
      "Feature norm: 121.604736\n",
      "Error norm: 974.236951\n",
      "Active features: 63130\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.156\n",
      "\n",
      "***** Iteration #161 *****\n",
      "Loss: 94584.898269\n",
      "Feature norm: 121.612093\n",
      "Error norm: 689.036530\n",
      "Active features: 63131\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.115\n",
      "\n",
      "***** Iteration #162 *****\n",
      "Loss: 94583.986170\n",
      "Feature norm: 121.619408\n",
      "Error norm: 545.733106\n",
      "Active features: 63128\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.918\n",
      "\n",
      "***** Iteration #163 *****\n",
      "Loss: 94583.144084\n",
      "Feature norm: 121.628572\n",
      "Error norm: 623.839014\n",
      "Active features: 63107\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.225\n",
      "\n",
      "***** Iteration #164 *****\n",
      "Loss: 94582.260364\n",
      "Feature norm: 121.638491\n",
      "Error norm: 870.156644\n",
      "Active features: 63087\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.136\n",
      "\n",
      "***** Iteration #165 *****\n",
      "Loss: 94581.113148\n",
      "Feature norm: 121.647284\n",
      "Error norm: 710.216497\n",
      "Active features: 63088\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.036\n",
      "\n",
      "***** Iteration #166 *****\n",
      "Loss: 94580.439371\n",
      "Feature norm: 121.657718\n",
      "Error norm: 706.493135\n",
      "Active features: 63083\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.454\n",
      "\n",
      "***** Iteration #167 *****\n",
      "Loss: 94579.390788\n",
      "Feature norm: 121.664121\n",
      "Error norm: 302.338305\n",
      "Active features: 63058\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.004\n",
      "\n",
      "***** Iteration #168 *****\n",
      "Loss: 94578.304274\n",
      "Feature norm: 121.673047\n",
      "Error norm: 401.508120\n",
      "Active features: 63035\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.869\n",
      "\n",
      "***** Iteration #169 *****\n",
      "Loss: 94577.344467\n",
      "Feature norm: 121.686639\n",
      "Error norm: 1594.030343\n",
      "Active features: 62995\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.926\n",
      "\n",
      "***** Iteration #170 *****\n",
      "Loss: 94575.331641\n",
      "Feature norm: 121.699906\n",
      "Error norm: 90.529832\n",
      "Active features: 63022\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.308\n",
      "\n",
      "***** Iteration #171 *****\n",
      "Loss: 94573.690212\n",
      "Feature norm: 121.716526\n",
      "Error norm: 77.298693\n",
      "Active features: 62984\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.349\n",
      "\n",
      "***** Iteration #172 *****\n",
      "Loss: 94573.027549\n",
      "Feature norm: 121.732588\n",
      "Error norm: 1270.462468\n",
      "Active features: 62904\n",
      "Line search trials: 6\n",
      "Line search step: 0.031250\n",
      "Seconds required for this iteration: 108.983\n",
      "\n",
      "***** Iteration #173 *****\n",
      "Loss: 94571.798540\n",
      "Feature norm: 121.752328\n",
      "Error norm: 1487.519072\n",
      "Active features: 62887\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.404\n",
      "\n",
      "***** Iteration #174 *****\n",
      "Loss: 94570.783750\n",
      "Feature norm: 121.768613\n",
      "Error norm: 1857.419560\n",
      "Active features: 62911\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.265\n",
      "\n",
      "***** Iteration #175 *****\n",
      "Loss: 94568.766577\n",
      "Feature norm: 121.778888\n",
      "Error norm: 658.471168\n",
      "Active features: 62893\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.718\n",
      "\n",
      "***** Iteration #176 *****\n",
      "Loss: 94568.405377\n",
      "Feature norm: 121.787338\n",
      "Error norm: 1425.303475\n",
      "Active features: 62892\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.736\n",
      "\n",
      "***** Iteration #177 *****\n",
      "Loss: 94567.168999\n",
      "Feature norm: 121.794384\n",
      "Error norm: 893.829033\n",
      "Active features: 62879\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.670\n",
      "\n",
      "***** Iteration #178 *****\n",
      "Loss: 94566.763759\n",
      "Feature norm: 121.804653\n",
      "Error norm: 1426.395138\n",
      "Active features: 62888\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.911\n",
      "\n",
      "***** Iteration #179 *****\n",
      "Loss: 94565.244799\n",
      "Feature norm: 121.815639\n",
      "Error norm: 771.504335\n",
      "Active features: 62873\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.788\n",
      "\n",
      "***** Iteration #180 *****\n",
      "Loss: 94564.447467\n",
      "Feature norm: 121.825081\n",
      "Error norm: 1371.908705\n",
      "Active features: 62854\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.509\n",
      "\n",
      "***** Iteration #181 *****\n",
      "Loss: 94563.522651\n",
      "Feature norm: 121.840593\n",
      "Error norm: 1172.395262\n",
      "Active features: 62835\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.470\n",
      "\n",
      "***** Iteration #182 *****\n",
      "Loss: 94562.958881\n",
      "Feature norm: 121.852489\n",
      "Error norm: 1942.236957\n",
      "Active features: 62790\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.720\n",
      "\n",
      "***** Iteration #183 *****\n",
      "Loss: 94560.933177\n",
      "Feature norm: 121.860582\n",
      "Error norm: 776.249363\n",
      "Active features: 62762\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.477\n",
      "\n",
      "***** Iteration #184 *****\n",
      "Loss: 94560.854217\n",
      "Feature norm: 121.866972\n",
      "Error norm: 2065.638832\n",
      "Active features: 62741\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.286\n",
      "\n",
      "***** Iteration #185 *****\n",
      "Loss: 94558.714847\n",
      "Feature norm: 121.876312\n",
      "Error norm: 430.359640\n",
      "Active features: 62734\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.898\n",
      "\n",
      "***** Iteration #186 *****\n",
      "Loss: 94558.014160\n",
      "Feature norm: 121.879452\n",
      "Error norm: 860.439726\n",
      "Active features: 62732\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 37.105\n",
      "\n",
      "***** Iteration #187 *****\n",
      "Loss: 94557.769641\n",
      "Feature norm: 121.887267\n",
      "Error norm: 1260.993406\n",
      "Active features: 62711\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.922\n",
      "\n",
      "***** Iteration #188 *****\n",
      "Loss: 94556.710215\n",
      "Feature norm: 121.895399\n",
      "Error norm: 1660.879184\n",
      "Active features: 62697\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.491\n",
      "\n",
      "***** Iteration #189 *****\n",
      "Loss: 94555.278381\n",
      "Feature norm: 121.900513\n",
      "Error norm: 684.923112\n",
      "Active features: 62667\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.820\n",
      "\n",
      "***** Iteration #190 *****\n",
      "Loss: 94555.014292\n",
      "Feature norm: 121.904296\n",
      "Error norm: 1682.820304\n",
      "Active features: 62655\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.479\n",
      "\n",
      "***** Iteration #191 *****\n",
      "Loss: 94553.527730\n",
      "Feature norm: 121.907868\n",
      "Error norm: 690.353429\n",
      "Active features: 62637\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.557\n",
      "\n",
      "***** Iteration #192 *****\n",
      "Loss: 94553.504766\n",
      "Feature norm: 121.912661\n",
      "Error norm: 1815.657798\n",
      "Active features: 62616\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.877\n",
      "\n",
      "***** Iteration #193 *****\n",
      "Loss: 94551.660448\n",
      "Feature norm: 121.916824\n",
      "Error norm: 639.894487\n",
      "Active features: 62605\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.342\n",
      "\n",
      "***** Iteration #194 *****\n",
      "Loss: 94551.559506\n",
      "Feature norm: 121.922555\n",
      "Error norm: 1765.917274\n",
      "Active features: 62592\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.042\n",
      "\n",
      "***** Iteration #195 *****\n",
      "Loss: 94549.864113\n",
      "Feature norm: 121.927547\n",
      "Error norm: 834.726373\n",
      "Active features: 62568\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.466\n",
      "\n",
      "***** Iteration #196 *****\n",
      "Loss: 94548.925040\n",
      "Feature norm: 121.930949\n",
      "Error norm: 575.508300\n",
      "Active features: 62567\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 38.071\n",
      "\n",
      "***** Iteration #197 *****\n",
      "Loss: 94548.364798\n",
      "Feature norm: 121.934625\n",
      "Error norm: 628.830048\n",
      "Active features: 62564\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 38.886\n",
      "\n",
      "***** Iteration #198 *****\n",
      "Loss: 94547.683511\n",
      "Feature norm: 121.939687\n",
      "Error norm: 784.871736\n",
      "Active features: 62555\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 36.795\n",
      "\n",
      "***** Iteration #199 *****\n",
      "Loss: 94546.943844\n",
      "Feature norm: 121.943753\n",
      "Error norm: 615.056634\n",
      "Active features: 62543\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 36.191\n",
      "\n",
      "***** Iteration #200 *****\n",
      "Loss: 94546.239306\n",
      "Feature norm: 121.951009\n",
      "Error norm: 997.495422\n",
      "Active features: 62532\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 37.720\n",
      "\n",
      "***** Iteration #201 *****\n",
      "Loss: 94545.242505\n",
      "Feature norm: 121.957087\n",
      "Error norm: 577.114856\n",
      "Active features: 62502\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 35.884\n",
      "\n",
      "***** Iteration #202 *****\n",
      "Loss: 94544.701130\n",
      "Feature norm: 121.966364\n",
      "Error norm: 1135.240479\n",
      "Active features: 62478\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 39.863\n",
      "\n",
      "***** Iteration #203 *****\n",
      "Loss: 94543.478793\n",
      "Feature norm: 121.971838\n",
      "Error norm: 383.712012\n",
      "Active features: 62469\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 37.732\n",
      "\n",
      "***** Iteration #204 *****\n",
      "Loss: 94543.122508\n",
      "Feature norm: 121.978467\n",
      "Error norm: 1040.073319\n",
      "Active features: 62451\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 36.050\n",
      "\n",
      "***** Iteration #205 *****\n",
      "Loss: 94542.996449\n",
      "Feature norm: 121.984576\n",
      "Error norm: 1402.978655\n",
      "Active features: 62434\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.328\n",
      "\n",
      "***** Iteration #206 *****\n",
      "Loss: 94541.343047\n",
      "Feature norm: 121.993984\n",
      "Error norm: 953.731375\n",
      "Active features: 62440\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.226\n",
      "\n",
      "***** Iteration #207 *****\n",
      "Loss: 94540.806805\n",
      "Feature norm: 121.996606\n",
      "Error norm: 779.446233\n",
      "Active features: 62423\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.932\n",
      "\n",
      "***** Iteration #208 *****\n",
      "Loss: 94540.377380\n",
      "Feature norm: 122.002657\n",
      "Error norm: 1238.743608\n",
      "Active features: 62423\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.923\n",
      "\n",
      "***** Iteration #209 *****\n",
      "Loss: 94539.530533\n",
      "Feature norm: 122.005792\n",
      "Error norm: 642.669267\n",
      "Active features: 62400\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 21.699\n",
      "\n",
      "***** Iteration #210 *****\n",
      "Loss: 94539.040732\n",
      "Feature norm: 122.006891\n",
      "Error norm: 812.839154\n",
      "Active features: 62399\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.073\n",
      "\n",
      "***** Iteration #211 *****\n",
      "Loss: 94538.615392\n",
      "Feature norm: 122.009894\n",
      "Error norm: 665.284037\n",
      "Active features: 62388\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.780\n",
      "\n",
      "***** Iteration #212 *****\n",
      "Loss: 94538.386133\n",
      "Feature norm: 122.010877\n",
      "Error norm: 1172.806951\n",
      "Active features: 62372\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.817\n",
      "\n",
      "***** Iteration #213 *****\n",
      "Loss: 94537.595994\n",
      "Feature norm: 122.014466\n",
      "Error norm: 646.942694\n",
      "Active features: 62361\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.715\n",
      "\n",
      "***** Iteration #214 *****\n",
      "Loss: 94537.505842\n",
      "Feature norm: 122.016599\n",
      "Error norm: 1302.521518\n",
      "Active features: 62358\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.410\n",
      "\n",
      "***** Iteration #215 *****\n",
      "Loss: 94536.535439\n",
      "Feature norm: 122.020739\n",
      "Error norm: 525.834119\n",
      "Active features: 62354\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.373\n",
      "\n",
      "***** Iteration #216 *****\n",
      "Loss: 94536.379454\n",
      "Feature norm: 122.025554\n",
      "Error norm: 1041.015898\n",
      "Active features: 62339\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.436\n",
      "\n",
      "***** Iteration #217 *****\n",
      "Loss: 94535.686971\n",
      "Feature norm: 122.030612\n",
      "Error norm: 418.691150\n",
      "Active features: 62331\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.432\n",
      "\n",
      "***** Iteration #218 *****\n",
      "Loss: 94535.682392\n",
      "Feature norm: 122.036033\n",
      "Error norm: 1148.198426\n",
      "Active features: 62296\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.747\n",
      "\n",
      "***** Iteration #219 *****\n",
      "Loss: 94534.932404\n",
      "Feature norm: 122.041353\n",
      "Error norm: 476.537300\n",
      "Active features: 62297\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.241\n",
      "\n",
      "***** Iteration #220 *****\n",
      "Loss: 94534.575846\n",
      "Feature norm: 122.044466\n",
      "Error norm: 410.642274\n",
      "Active features: 62297\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 38.049\n",
      "\n",
      "***** Iteration #221 *****\n",
      "Loss: 94534.301849\n",
      "Feature norm: 122.047561\n",
      "Error norm: 354.083356\n",
      "Active features: 62289\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 37.379\n",
      "\n",
      "***** Iteration #222 *****\n",
      "Loss: 94534.051858\n",
      "Feature norm: 122.050876\n",
      "Error norm: 664.667819\n",
      "Active features: 62283\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 38.628\n",
      "\n",
      "***** Iteration #223 *****\n",
      "Loss: 94533.566210\n",
      "Feature norm: 122.055593\n",
      "Error norm: 340.891065\n",
      "Active features: 62275\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 37.409\n",
      "\n",
      "***** Iteration #224 *****\n",
      "Loss: 94533.314848\n",
      "Feature norm: 122.061675\n",
      "Error norm: 735.346608\n",
      "Active features: 62258\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 33.256\n",
      "\n",
      "***** Iteration #225 *****\n",
      "Loss: 94532.748375\n",
      "Feature norm: 122.069184\n",
      "Error norm: 346.567039\n",
      "Active features: 62244\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 39.396\n",
      "\n",
      "***** Iteration #226 *****\n",
      "Loss: 94532.474503\n",
      "Feature norm: 122.078300\n",
      "Error norm: 777.499320\n",
      "Active features: 62246\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 38.996\n",
      "\n",
      "***** Iteration #227 *****\n",
      "Loss: 94531.893228\n",
      "Feature norm: 122.085663\n",
      "Error norm: 323.610626\n",
      "Active features: 62244\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 35.994\n",
      "\n",
      "***** Iteration #228 *****\n",
      "Loss: 94531.600516\n",
      "Feature norm: 122.093605\n",
      "Error norm: 767.920474\n",
      "Active features: 62231\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.782\n",
      "\n",
      "***** Iteration #229 *****\n",
      "Loss: 94531.009994\n",
      "Feature norm: 122.102411\n",
      "Error norm: 285.770137\n",
      "Active features: 62230\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 36.232\n",
      "\n",
      "***** Iteration #230 *****\n",
      "Loss: 94530.704695\n",
      "Feature norm: 122.110192\n",
      "Error norm: 790.377297\n",
      "Active features: 62208\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 32.665\n",
      "\n",
      "***** Iteration #231 *****\n",
      "Loss: 94530.067257\n",
      "Feature norm: 122.118074\n",
      "Error norm: 290.667539\n",
      "Active features: 62188\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 35.781\n",
      "\n",
      "***** Iteration #232 *****\n",
      "Loss: 94529.766506\n",
      "Feature norm: 122.125275\n",
      "Error norm: 863.706432\n",
      "Active features: 62193\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 36.874\n",
      "\n",
      "***** Iteration #233 *****\n",
      "Loss: 94529.120844\n",
      "Feature norm: 122.130959\n",
      "Error norm: 285.294396\n",
      "Active features: 62173\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 36.295\n",
      "\n",
      "***** Iteration #234 *****\n",
      "Loss: 94528.900962\n",
      "Feature norm: 122.137002\n",
      "Error norm: 888.864284\n",
      "Active features: 62156\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 36.884\n",
      "\n",
      "***** Iteration #235 *****\n",
      "Loss: 94528.203523\n",
      "Feature norm: 122.141493\n",
      "Error norm: 204.606860\n",
      "Active features: 62133\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 38.534\n",
      "\n",
      "***** Iteration #236 *****\n",
      "Loss: 94527.928144\n",
      "Feature norm: 122.148014\n",
      "Error norm: 909.211088\n",
      "Active features: 62124\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.967\n",
      "\n",
      "***** Iteration #237 *****\n",
      "Loss: 94527.340493\n",
      "Feature norm: 122.151323\n",
      "Error norm: 161.545823\n",
      "Active features: 62115\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 37.413\n",
      "\n",
      "***** Iteration #238 *****\n",
      "Loss: 94527.085555\n",
      "Feature norm: 122.157912\n",
      "Error norm: 1040.464849\n",
      "Active features: 62102\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 38.400\n",
      "\n",
      "***** Iteration #239 *****\n",
      "Loss: 94526.879565\n",
      "Feature norm: 122.163686\n",
      "Error norm: 1054.919055\n",
      "Active features: 62087\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.428\n",
      "\n",
      "***** Iteration #240 *****\n",
      "Loss: 94526.183818\n",
      "Feature norm: 122.175186\n",
      "Error norm: 1475.094602\n",
      "Active features: 62071\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.316\n",
      "\n",
      "***** Iteration #241 *****\n",
      "Loss: 94524.831708\n",
      "Feature norm: 122.179848\n",
      "Error norm: 332.412338\n",
      "Active features: 62053\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.690\n",
      "\n",
      "***** Iteration #242 *****\n",
      "Loss: 94524.506390\n",
      "Feature norm: 122.184269\n",
      "Error norm: 595.949996\n",
      "Active features: 62081\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 35.067\n",
      "\n",
      "***** Iteration #243 *****\n",
      "Loss: 94524.385309\n",
      "Feature norm: 122.190506\n",
      "Error norm: 966.359482\n",
      "Active features: 62067\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.235\n",
      "\n",
      "***** Iteration #244 *****\n",
      "Loss: 94523.801522\n",
      "Feature norm: 122.197704\n",
      "Error norm: 1072.627070\n",
      "Active features: 62051\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.230\n",
      "\n",
      "***** Iteration #245 *****\n",
      "Loss: 94523.090246\n",
      "Feature norm: 122.202828\n",
      "Error norm: 617.929091\n",
      "Active features: 62019\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.534\n",
      "\n",
      "***** Iteration #246 *****\n",
      "Loss: 94522.844841\n",
      "Feature norm: 122.210336\n",
      "Error norm: 1017.686999\n",
      "Active features: 62017\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.783\n",
      "\n",
      "***** Iteration #247 *****\n",
      "Loss: 94522.247947\n",
      "Feature norm: 122.214893\n",
      "Error norm: 428.121871\n",
      "Active features: 62008\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.326\n",
      "\n",
      "***** Iteration #248 *****\n",
      "Loss: 94521.909826\n",
      "Feature norm: 122.222442\n",
      "Error norm: 744.924506\n",
      "Active features: 62021\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.056\n",
      "\n",
      "***** Iteration #249 *****\n",
      "Loss: 94521.496271\n",
      "Feature norm: 122.224294\n",
      "Error norm: 619.671240\n",
      "Active features: 62013\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.043\n",
      "\n",
      "***** Iteration #250 *****\n",
      "Loss: 94521.390165\n",
      "Feature norm: 122.232772\n",
      "Error norm: 1156.199852\n",
      "Active features: 62006\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.639\n",
      "\n",
      "***** Iteration #251 *****\n",
      "Loss: 94520.771617\n",
      "Feature norm: 122.234986\n",
      "Error norm: 614.044119\n",
      "Active features: 62005\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.103\n",
      "\n",
      "***** Iteration #252 *****\n",
      "Loss: 94520.561823\n",
      "Feature norm: 122.242652\n",
      "Error norm: 1132.284475\n",
      "Active features: 62007\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.969\n",
      "\n",
      "***** Iteration #253 *****\n",
      "Loss: 94519.931777\n",
      "Feature norm: 122.244206\n",
      "Error norm: 355.152859\n",
      "Active features: 62006\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.458\n",
      "\n",
      "***** Iteration #254 *****\n",
      "Loss: 94519.909590\n",
      "Feature norm: 122.250580\n",
      "Error norm: 1192.441269\n",
      "Active features: 62011\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.874\n",
      "\n",
      "***** Iteration #255 *****\n",
      "Loss: 94519.267379\n",
      "Feature norm: 122.252500\n",
      "Error norm: 270.419854\n",
      "Active features: 61995\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.863\n",
      "\n",
      "***** Iteration #256 *****\n",
      "Loss: 94518.989736\n",
      "Feature norm: 122.255321\n",
      "Error norm: 496.769386\n",
      "Active features: 61999\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 36.438\n",
      "\n",
      "***** Iteration #257 *****\n",
      "Loss: 94518.766799\n",
      "Feature norm: 122.258879\n",
      "Error norm: 708.602515\n",
      "Active features: 62008\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.211\n",
      "\n",
      "***** Iteration #258 *****\n",
      "Loss: 94518.565450\n",
      "Feature norm: 122.265806\n",
      "Error norm: 1114.705839\n",
      "Active features: 61999\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.639\n",
      "\n",
      "***** Iteration #259 *****\n",
      "Loss: 94517.858450\n",
      "Feature norm: 122.270259\n",
      "Error norm: 495.583193\n",
      "Active features: 61976\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.578\n",
      "\n",
      "***** Iteration #260 *****\n",
      "Loss: 94517.755521\n",
      "Feature norm: 122.277570\n",
      "Error norm: 1139.424201\n",
      "Active features: 61973\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.754\n",
      "\n",
      "***** Iteration #261 *****\n",
      "Loss: 94517.017381\n",
      "Feature norm: 122.280149\n",
      "Error norm: 278.279939\n",
      "Active features: 61970\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.016\n",
      "\n",
      "***** Iteration #262 *****\n",
      "Loss: 94516.800822\n",
      "Feature norm: 122.284241\n",
      "Error norm: 619.303257\n",
      "Active features: 61971\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 38.749\n",
      "\n",
      "***** Iteration #263 *****\n",
      "Loss: 94516.481655\n",
      "Feature norm: 122.287327\n",
      "Error norm: 204.938171\n",
      "Active features: 61965\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.011\n",
      "\n",
      "***** Iteration #264 *****\n",
      "Loss: 94516.348075\n",
      "Feature norm: 122.291716\n",
      "Error norm: 765.184906\n",
      "Active features: 61955\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.689\n",
      "\n",
      "***** Iteration #265 *****\n",
      "Loss: 94515.921627\n",
      "Feature norm: 122.294709\n",
      "Error norm: 149.166560\n",
      "Active features: 61948\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.219\n",
      "\n",
      "***** Iteration #266 *****\n",
      "Loss: 94515.822923\n",
      "Feature norm: 122.298953\n",
      "Error norm: 815.355185\n",
      "Active features: 61937\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.553\n",
      "\n",
      "***** Iteration #267 *****\n",
      "Loss: 94515.371541\n",
      "Feature norm: 122.302160\n",
      "Error norm: 123.924621\n",
      "Active features: 61942\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 37.944\n",
      "\n",
      "***** Iteration #268 *****\n",
      "Loss: 94515.271698\n",
      "Feature norm: 122.306140\n",
      "Error norm: 828.819481\n",
      "Active features: 61941\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 38.784\n",
      "\n",
      "***** Iteration #269 *****\n",
      "Loss: 94515.174789\n",
      "Feature norm: 122.312322\n",
      "Error norm: 909.108586\n",
      "Active features: 61925\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.599\n",
      "\n",
      "***** Iteration #270 *****\n",
      "Loss: 94514.652112\n",
      "Feature norm: 122.319445\n",
      "Error norm: 1049.037052\n",
      "Active features: 61927\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.899\n",
      "\n",
      "***** Iteration #271 *****\n",
      "Loss: 94514.086648\n",
      "Feature norm: 122.322312\n",
      "Error norm: 374.919591\n",
      "Active features: 61912\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.253\n",
      "\n",
      "***** Iteration #272 *****\n",
      "Loss: 94513.816714\n",
      "Feature norm: 122.324690\n",
      "Error norm: 368.376599\n",
      "Active features: 61929\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 37.293\n",
      "\n",
      "***** Iteration #273 *****\n",
      "Loss: 94513.688244\n",
      "Feature norm: 122.328352\n",
      "Error norm: 709.255772\n",
      "Active features: 61914\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.290\n",
      "\n",
      "***** Iteration #274 *****\n",
      "Loss: 94513.498672\n",
      "Feature norm: 122.334020\n",
      "Error norm: 965.913204\n",
      "Active features: 61910\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.358\n",
      "\n",
      "***** Iteration #275 *****\n",
      "Loss: 94512.901182\n",
      "Feature norm: 122.337222\n",
      "Error norm: 401.091376\n",
      "Active features: 61914\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.513\n",
      "\n",
      "***** Iteration #276 *****\n",
      "Loss: 94512.752600\n",
      "Feature norm: 122.341022\n",
      "Error norm: 788.217015\n",
      "Active features: 61931\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.397\n",
      "\n",
      "***** Iteration #277 *****\n",
      "Loss: 94512.367446\n",
      "Feature norm: 122.344070\n",
      "Error norm: 602.862315\n",
      "Active features: 61910\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.944\n",
      "\n",
      "***** Iteration #278 *****\n",
      "Loss: 94512.183161\n",
      "Feature norm: 122.351402\n",
      "Error norm: 885.428666\n",
      "Active features: 61902\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.371\n",
      "\n",
      "***** Iteration #279 *****\n",
      "Loss: 94511.712034\n",
      "Feature norm: 122.353463\n",
      "Error norm: 602.371572\n",
      "Active features: 61896\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.276\n",
      "\n",
      "***** Iteration #280 *****\n",
      "Loss: 94511.524672\n",
      "Feature norm: 122.355507\n",
      "Error norm: 873.699322\n",
      "Active features: 61875\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.442\n",
      "\n",
      "***** Iteration #281 *****\n",
      "Loss: 94511.088466\n",
      "Feature norm: 122.358018\n",
      "Error norm: 584.258849\n",
      "Active features: 61868\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.546\n",
      "\n",
      "***** Iteration #282 *****\n",
      "Loss: 94510.973040\n",
      "Feature norm: 122.359451\n",
      "Error norm: 959.165016\n",
      "Active features: 61860\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.843\n",
      "\n",
      "***** Iteration #283 *****\n",
      "Loss: 94510.430354\n",
      "Feature norm: 122.360578\n",
      "Error norm: 431.577185\n",
      "Active features: 61844\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.560\n",
      "\n",
      "***** Iteration #284 *****\n",
      "Loss: 94510.331493\n",
      "Feature norm: 122.362162\n",
      "Error norm: 968.682716\n",
      "Active features: 61828\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.206\n",
      "\n",
      "***** Iteration #285 *****\n",
      "Loss: 94509.834241\n",
      "Feature norm: 122.362866\n",
      "Error norm: 386.082940\n",
      "Active features: 61833\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.640\n",
      "\n",
      "***** Iteration #286 *****\n",
      "Loss: 94509.572862\n",
      "Feature norm: 122.364220\n",
      "Error norm: 422.922619\n",
      "Active features: 61836\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.698\n",
      "\n",
      "***** Iteration #287 *****\n",
      "Loss: 94509.555693\n",
      "Feature norm: 122.365793\n",
      "Error norm: 892.829004\n",
      "Active features: 61826\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.251\n",
      "\n",
      "***** Iteration #288 *****\n",
      "Loss: 94509.170843\n",
      "Feature norm: 122.369049\n",
      "Error norm: 1014.994235\n",
      "Active features: 61811\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.232\n",
      "\n",
      "***** Iteration #289 *****\n",
      "Loss: 94508.633275\n",
      "Feature norm: 122.371320\n",
      "Error norm: 608.148396\n",
      "Active features: 61798\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.414\n",
      "\n",
      "***** Iteration #290 *****\n",
      "Loss: 94508.540277\n",
      "Feature norm: 122.374926\n",
      "Error norm: 1119.597913\n",
      "Active features: 61812\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.689\n",
      "\n",
      "***** Iteration #291 *****\n",
      "Loss: 94507.828635\n",
      "Feature norm: 122.375968\n",
      "Error norm: 373.123937\n",
      "Active features: 61791\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.841\n",
      "\n",
      "***** Iteration #292 *****\n",
      "Loss: 94507.756465\n",
      "Feature norm: 122.379507\n",
      "Error norm: 1113.579869\n",
      "Active features: 61786\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.658\n",
      "\n",
      "***** Iteration #293 *****\n",
      "Loss: 94507.154059\n",
      "Feature norm: 122.380973\n",
      "Error norm: 351.699337\n",
      "Active features: 61783\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 15.717\n",
      "\n",
      "***** Iteration #294 *****\n",
      "Loss: 94506.861389\n",
      "Feature norm: 122.381815\n",
      "Error norm: 484.833864\n",
      "Active features: 61771\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 33.925\n",
      "\n",
      "***** Iteration #295 *****\n",
      "Loss: 94506.824586\n",
      "Feature norm: 122.383144\n",
      "Error norm: 875.718993\n",
      "Active features: 61755\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.200\n",
      "\n",
      "***** Iteration #296 *****\n",
      "Loss: 94506.380733\n",
      "Feature norm: 122.384714\n",
      "Error norm: 954.099036\n",
      "Active features: 61754\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.042\n",
      "\n",
      "***** Iteration #297 *****\n",
      "Loss: 94505.891205\n",
      "Feature norm: 122.385730\n",
      "Error norm: 476.613710\n",
      "Active features: 61737\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.630\n",
      "\n",
      "***** Iteration #298 *****\n",
      "Loss: 94505.852022\n",
      "Feature norm: 122.387046\n",
      "Error norm: 1038.647839\n",
      "Active features: 61733\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.751\n",
      "\n",
      "***** Iteration #299 *****\n",
      "Loss: 94505.249166\n",
      "Feature norm: 122.387371\n",
      "Error norm: 332.300017\n",
      "Active features: 61721\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.189\n",
      "\n",
      "***** Iteration #300 *****\n",
      "Loss: 94505.183142\n",
      "Feature norm: 122.388755\n",
      "Error norm: 986.676784\n",
      "Active features: 61706\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.812\n",
      "\n",
      "***** Iteration #301 *****\n",
      "Loss: 94504.712411\n",
      "Feature norm: 122.389067\n",
      "Error norm: 381.127208\n",
      "Active features: 61699\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.720\n",
      "\n",
      "***** Iteration #302 *****\n",
      "Loss: 94504.606134\n",
      "Feature norm: 122.390333\n",
      "Error norm: 1008.783443\n",
      "Active features: 61680\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.243\n",
      "\n",
      "***** Iteration #303 *****\n",
      "Loss: 94504.205308\n",
      "Feature norm: 122.391355\n",
      "Error norm: 368.855403\n",
      "Active features: 61674\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.744\n",
      "\n",
      "***** Iteration #304 *****\n",
      "Loss: 94503.935675\n",
      "Feature norm: 122.392751\n",
      "Error norm: 442.809931\n",
      "Active features: 61674\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 33.577\n",
      "\n",
      "***** Iteration #305 *****\n",
      "Loss: 94503.739949\n",
      "Feature norm: 122.394508\n",
      "Error norm: 655.095755\n",
      "Active features: 61681\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 15.820\n",
      "\n",
      "***** Iteration #306 *****\n",
      "Loss: 94503.628675\n",
      "Feature norm: 122.397399\n",
      "Error norm: 950.810284\n",
      "Active features: 61690\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.377\n",
      "\n",
      "***** Iteration #307 *****\n",
      "Loss: 94503.115457\n",
      "Feature norm: 122.398914\n",
      "Error norm: 526.004321\n",
      "Active features: 61663\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 15.981\n",
      "\n",
      "***** Iteration #308 *****\n",
      "Loss: 94502.946630\n",
      "Feature norm: 122.401854\n",
      "Error norm: 783.903738\n",
      "Active features: 61652\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 15.089\n",
      "\n",
      "***** Iteration #309 *****\n",
      "Loss: 94502.551938\n",
      "Feature norm: 122.403797\n",
      "Error norm: 486.024969\n",
      "Active features: 61637\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.165\n",
      "\n",
      "***** Iteration #310 *****\n",
      "Loss: 94502.411600\n",
      "Feature norm: 122.407030\n",
      "Error norm: 681.074431\n",
      "Active features: 61651\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.391\n",
      "\n",
      "***** Iteration #311 *****\n",
      "Loss: 94502.099182\n",
      "Feature norm: 122.408928\n",
      "Error norm: 535.569365\n",
      "Active features: 61651\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.800\n",
      "\n",
      "***** Iteration #312 *****\n",
      "Loss: 94501.933982\n",
      "Feature norm: 122.411738\n",
      "Error norm: 655.413105\n",
      "Active features: 61649\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.020\n",
      "\n",
      "***** Iteration #313 *****\n",
      "Loss: 94501.621403\n",
      "Feature norm: 122.413734\n",
      "Error norm: 526.077244\n",
      "Active features: 61641\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.831\n",
      "\n",
      "***** Iteration #314 *****\n",
      "Loss: 94501.554477\n",
      "Feature norm: 122.417322\n",
      "Error norm: 831.509057\n",
      "Active features: 61636\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.171\n",
      "\n",
      "***** Iteration #315 *****\n",
      "Loss: 94501.108344\n",
      "Feature norm: 122.419264\n",
      "Error norm: 505.111235\n",
      "Active features: 61632\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.717\n",
      "\n",
      "***** Iteration #316 *****\n",
      "Loss: 94501.051644\n",
      "Feature norm: 122.422262\n",
      "Error norm: 891.663007\n",
      "Active features: 61633\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.717\n",
      "\n",
      "***** Iteration #317 *****\n",
      "Loss: 94500.560070\n",
      "Feature norm: 122.424427\n",
      "Error norm: 443.074070\n",
      "Active features: 61620\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 15.969\n",
      "\n",
      "***** Iteration #318 *****\n",
      "Loss: 94500.559236\n",
      "Feature norm: 122.427109\n",
      "Error norm: 994.256927\n",
      "Active features: 61609\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.521\n",
      "\n",
      "***** Iteration #319 *****\n",
      "Loss: 94500.010996\n",
      "Feature norm: 122.428884\n",
      "Error norm: 358.364362\n",
      "Active features: 61607\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.858\n",
      "\n",
      "***** Iteration #320 *****\n",
      "Loss: 94499.804546\n",
      "Feature norm: 122.430331\n",
      "Error norm: 407.538646\n",
      "Active features: 61607\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.463\n",
      "\n",
      "***** Iteration #321 *****\n",
      "Loss: 94499.637554\n",
      "Feature norm: 122.431901\n",
      "Error norm: 231.618770\n",
      "Active features: 61615\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.517\n",
      "\n",
      "***** Iteration #322 *****\n",
      "Loss: 94499.520187\n",
      "Feature norm: 122.434167\n",
      "Error norm: 609.355427\n",
      "Active features: 61601\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 36.859\n",
      "\n",
      "***** Iteration #323 *****\n",
      "Loss: 94499.238740\n",
      "Feature norm: 122.435796\n",
      "Error norm: 154.554053\n",
      "Active features: 61589\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 37.230\n",
      "\n",
      "***** Iteration #324 *****\n",
      "Loss: 94499.169787\n",
      "Feature norm: 122.438485\n",
      "Error norm: 696.901545\n",
      "Active features: 61582\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 35.659\n",
      "\n",
      "***** Iteration #325 *****\n",
      "Loss: 94499.109603\n",
      "Feature norm: 122.441121\n",
      "Error norm: 832.241052\n",
      "Active features: 61550\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.402\n",
      "\n",
      "***** Iteration #326 *****\n",
      "Loss: 94498.678426\n",
      "Feature norm: 122.445403\n",
      "Error norm: 894.170412\n",
      "Active features: 61552\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.098\n",
      "\n",
      "***** Iteration #327 *****\n",
      "Loss: 94498.274790\n",
      "Feature norm: 122.447631\n",
      "Error norm: 405.590168\n",
      "Active features: 61561\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.999\n",
      "\n",
      "***** Iteration #328 *****\n",
      "Loss: 94498.216117\n",
      "Feature norm: 122.450341\n",
      "Error norm: 924.531369\n",
      "Active features: 61563\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.302\n",
      "\n",
      "***** Iteration #329 *****\n",
      "Loss: 94497.770733\n",
      "Feature norm: 122.452887\n",
      "Error norm: 272.019779\n",
      "Active features: 61557\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.598\n",
      "\n",
      "***** Iteration #330 *****\n",
      "Loss: 94497.605469\n",
      "Feature norm: 122.453895\n",
      "Error norm: 369.743684\n",
      "Active features: 61554\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 33.506\n",
      "\n",
      "***** Iteration #331 *****\n",
      "Loss: 94497.575938\n",
      "Feature norm: 122.456806\n",
      "Error norm: 720.997431\n",
      "Active features: 61545\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.559\n",
      "\n",
      "***** Iteration #332 *****\n",
      "Loss: 94497.282957\n",
      "Feature norm: 122.458961\n",
      "Error norm: 731.137625\n",
      "Active features: 61547\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 20.889\n",
      "\n",
      "***** Iteration #333 *****\n",
      "Loss: 94496.992490\n",
      "Feature norm: 122.461083\n",
      "Error norm: 565.232163\n",
      "Active features: 61523\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.942\n",
      "\n",
      "***** Iteration #334 *****\n",
      "Loss: 94496.817263\n",
      "Feature norm: 122.464756\n",
      "Error norm: 749.763521\n",
      "Active features: 61524\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.439\n",
      "\n",
      "***** Iteration #335 *****\n",
      "Loss: 94496.469439\n",
      "Feature norm: 122.466830\n",
      "Error norm: 426.314987\n",
      "Active features: 61517\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.451\n",
      "\n",
      "***** Iteration #336 *****\n",
      "Loss: 94496.250961\n",
      "Feature norm: 122.468390\n",
      "Error norm: 237.966600\n",
      "Active features: 61529\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 32.434\n",
      "\n",
      "***** Iteration #337 *****\n",
      "Loss: 94496.155133\n",
      "Feature norm: 122.470435\n",
      "Error norm: 334.122150\n",
      "Active features: 61521\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 35.202\n",
      "\n",
      "***** Iteration #338 *****\n",
      "Loss: 94495.976556\n",
      "Feature norm: 122.472616\n",
      "Error norm: 416.516656\n",
      "Active features: 61514\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.136\n",
      "\n",
      "***** Iteration #339 *****\n",
      "Loss: 94495.801056\n",
      "Feature norm: 122.474960\n",
      "Error norm: 294.834617\n",
      "Active features: 61497\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.360\n",
      "\n",
      "***** Iteration #340 *****\n",
      "Loss: 94495.647618\n",
      "Feature norm: 122.476929\n",
      "Error norm: 527.419518\n",
      "Active features: 61487\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 37.806\n",
      "\n",
      "***** Iteration #341 *****\n",
      "Loss: 94495.428588\n",
      "Feature norm: 122.478025\n",
      "Error norm: 220.345055\n",
      "Active features: 61472\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 35.383\n",
      "\n",
      "***** Iteration #342 *****\n",
      "Loss: 94495.305710\n",
      "Feature norm: 122.480311\n",
      "Error norm: 567.052158\n",
      "Active features: 61459\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 33.974\n",
      "\n",
      "***** Iteration #343 *****\n",
      "Loss: 94495.056549\n",
      "Feature norm: 122.480999\n",
      "Error norm: 155.176869\n",
      "Active features: 61444\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.362\n",
      "\n",
      "***** Iteration #344 *****\n",
      "Loss: 94494.958794\n",
      "Feature norm: 122.482795\n",
      "Error norm: 639.267835\n",
      "Active features: 61438\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 32.268\n",
      "\n",
      "***** Iteration #345 *****\n",
      "Loss: 94494.668494\n",
      "Feature norm: 122.483774\n",
      "Error norm: 116.169443\n",
      "Active features: 61425\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 32.821\n",
      "\n",
      "***** Iteration #346 *****\n",
      "Loss: 94494.611647\n",
      "Feature norm: 122.486763\n",
      "Error norm: 702.990197\n",
      "Active features: 61414\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 35.787\n",
      "\n",
      "***** Iteration #347 *****\n",
      "Loss: 94494.599902\n",
      "Feature norm: 122.491405\n",
      "Error norm: 821.083452\n",
      "Active features: 61376\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.964\n",
      "\n",
      "***** Iteration #348 *****\n",
      "Loss: 94494.109663\n",
      "Feature norm: 122.496764\n",
      "Error norm: 824.758864\n",
      "Active features: 61376\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.647\n",
      "\n",
      "***** Iteration #349 *****\n",
      "Loss: 94493.728174\n",
      "Feature norm: 122.499830\n",
      "Error norm: 332.726801\n",
      "Active features: 61375\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.184\n",
      "\n",
      "***** Iteration #350 *****\n",
      "Loss: 94493.524556\n",
      "Feature norm: 122.502358\n",
      "Error norm: 313.088392\n",
      "Active features: 61397\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 34.783\n",
      "\n",
      "***** Iteration #351 *****\n",
      "Loss: 94493.486462\n",
      "Feature norm: 122.507559\n",
      "Error norm: 724.025465\n",
      "Active features: 61372\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.193\n",
      "\n",
      "***** Iteration #352 *****\n",
      "Loss: 94493.164257\n",
      "Feature norm: 122.511640\n",
      "Error norm: 688.629673\n",
      "Active features: 61374\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.363\n",
      "\n",
      "***** Iteration #353 *****\n",
      "Loss: 94492.852611\n",
      "Feature norm: 122.515801\n",
      "Error norm: 498.974009\n",
      "Active features: 61363\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 15.483\n",
      "\n",
      "***** Iteration #354 *****\n",
      "Loss: 94492.730624\n",
      "Feature norm: 122.520291\n",
      "Error norm: 733.074656\n",
      "Active features: 61376\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 15.298\n",
      "\n",
      "***** Iteration #355 *****\n",
      "Loss: 94492.375645\n",
      "Feature norm: 122.524577\n",
      "Error norm: 421.691524\n",
      "Active features: 61371\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 15.682\n",
      "\n",
      "***** Iteration #356 *****\n",
      "Loss: 94492.235722\n",
      "Feature norm: 122.528226\n",
      "Error norm: 667.452129\n",
      "Active features: 61368\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.742\n",
      "\n",
      "***** Iteration #357 *****\n",
      "Loss: 94492.019792\n",
      "Feature norm: 122.532151\n",
      "Error norm: 471.101148\n",
      "Active features: 61353\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 15.712\n",
      "\n",
      "***** Iteration #358 *****\n",
      "Loss: 94491.900039\n",
      "Feature norm: 122.536232\n",
      "Error norm: 763.323529\n",
      "Active features: 61352\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.521\n",
      "\n",
      "***** Iteration #359 *****\n",
      "Loss: 94491.587664\n",
      "Feature norm: 122.539574\n",
      "Error norm: 285.829828\n",
      "Active features: 61348\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.005\n",
      "\n",
      "***** Iteration #360 *****\n",
      "Loss: 94491.437372\n",
      "Feature norm: 122.540796\n",
      "Error norm: 262.601994\n",
      "Active features: 61353\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 36.017\n",
      "\n",
      "***** Iteration #361 *****\n",
      "Loss: 94491.432156\n",
      "Feature norm: 122.544249\n",
      "Error norm: 580.075766\n",
      "Active features: 61348\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 19.539\n",
      "\n",
      "***** Iteration #362 *****\n",
      "Loss: 94491.235582\n",
      "Feature norm: 122.548169\n",
      "Error norm: 687.777120\n",
      "Active features: 61352\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.223\n",
      "\n",
      "***** Iteration #363 *****\n",
      "Loss: 94490.968324\n",
      "Feature norm: 122.550898\n",
      "Error norm: 306.798116\n",
      "Active features: 61349\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.176\n",
      "\n",
      "***** Iteration #364 *****\n",
      "Loss: 94490.900664\n",
      "Feature norm: 122.554680\n",
      "Error norm: 694.960893\n",
      "Active features: 61343\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 15.689\n",
      "\n",
      "***** Iteration #365 *****\n",
      "Loss: 94490.591402\n",
      "Feature norm: 122.556872\n",
      "Error norm: 176.958982\n",
      "Active features: 61328\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.584\n",
      "\n",
      "***** Iteration #366 *****\n",
      "Loss: 94490.483536\n",
      "Feature norm: 122.559603\n",
      "Error norm: 373.815027\n",
      "Active features: 61322\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 32.646\n",
      "\n",
      "***** Iteration #367 *****\n",
      "Loss: 94490.348650\n",
      "Feature norm: 122.562705\n",
      "Error norm: 193.952060\n",
      "Active features: 61313\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 32.040\n",
      "\n",
      "***** Iteration #368 *****\n",
      "Loss: 94490.250418\n",
      "Feature norm: 122.566952\n",
      "Error norm: 503.543599\n",
      "Active features: 61306\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 33.660\n",
      "\n",
      "***** Iteration #369 *****\n",
      "Loss: 94490.035125\n",
      "Feature norm: 122.570728\n",
      "Error norm: 148.789595\n",
      "Active features: 61305\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 35.009\n",
      "\n",
      "***** Iteration #370 *****\n",
      "Loss: 94489.986259\n",
      "Feature norm: 122.576188\n",
      "Error norm: 574.539330\n",
      "Active features: 61312\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 33.300\n",
      "\n",
      "***** Iteration #371 *****\n",
      "Loss: 94489.962443\n",
      "Feature norm: 122.584581\n",
      "Error norm: 722.897604\n",
      "Active features: 61292\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 15.125\n",
      "\n",
      "***** Iteration #372 *****\n",
      "Loss: 94489.594178\n",
      "Feature norm: 122.587399\n",
      "Error norm: 612.145625\n",
      "Active features: 61308\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.885\n",
      "\n",
      "***** Iteration #373 *****\n",
      "Loss: 94489.381781\n",
      "Feature norm: 122.590067\n",
      "Error norm: 353.606521\n",
      "Active features: 61306\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.083\n",
      "\n",
      "***** Iteration #374 *****\n",
      "Loss: 94489.331862\n",
      "Feature norm: 122.592111\n",
      "Error norm: 700.976957\n",
      "Active features: 61321\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 18.462\n",
      "\n",
      "***** Iteration #375 *****\n",
      "Loss: 94489.047550\n",
      "Feature norm: 122.594589\n",
      "Error norm: 234.582544\n",
      "Active features: 61301\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.835\n",
      "\n",
      "***** Iteration #376 *****\n",
      "Loss: 94488.926941\n",
      "Feature norm: 122.595630\n",
      "Error norm: 268.907686\n",
      "Active features: 61304\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 35.837\n",
      "\n",
      "***** Iteration #377 *****\n",
      "Loss: 94488.908310\n",
      "Feature norm: 122.598447\n",
      "Error norm: 600.475304\n",
      "Active features: 61296\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.974\n",
      "\n",
      "***** Iteration #378 *****\n",
      "Loss: 94488.724794\n",
      "Feature norm: 122.601039\n",
      "Error norm: 610.555284\n",
      "Active features: 61296\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.283\n",
      "\n",
      "***** Iteration #379 *****\n",
      "Loss: 94488.488126\n",
      "Feature norm: 122.602192\n",
      "Error norm: 428.578721\n",
      "Active features: 61296\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.192\n",
      "\n",
      "***** Iteration #380 *****\n",
      "Loss: 94488.455985\n",
      "Feature norm: 122.603812\n",
      "Error norm: 686.804873\n",
      "Active features: 61284\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.146\n",
      "\n",
      "***** Iteration #381 *****\n",
      "Loss: 94488.121157\n",
      "Feature norm: 122.604973\n",
      "Error norm: 280.018631\n",
      "Active features: 61287\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 17.883\n",
      "\n",
      "***** Iteration #382 *****\n",
      "Loss: 94488.061066\n",
      "Feature norm: 122.606638\n",
      "Error norm: 599.680000\n",
      "Active features: 61267\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.746\n",
      "\n",
      "***** Iteration #383 *****\n",
      "Loss: 94487.881512\n",
      "Feature norm: 122.606866\n",
      "Error norm: 133.689012\n",
      "Active features: 61273\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 15.363\n",
      "\n",
      "***** Iteration #384 *****\n",
      "Loss: 94487.751428\n",
      "Feature norm: 122.607595\n",
      "Error norm: 62.294863\n",
      "Active features: 61263\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 16.051\n",
      "\n",
      "***** Iteration #385 *****\n",
      "Loss: 94487.726213\n",
      "Feature norm: 122.608147\n",
      "Error norm: 360.522347\n",
      "Active features: 61274\n",
      "Line search trials: 3\n",
      "Line search step: 0.250000\n",
      "Seconds required for this iteration: 54.129\n",
      "\n",
      "***** Iteration #386 *****\n",
      "Loss: 94487.628829\n",
      "Feature norm: 122.608475\n",
      "Error norm: 177.717072\n",
      "Active features: 61270\n",
      "Line search trials: 3\n",
      "Line search step: 0.250000\n",
      "Seconds required for this iteration: 51.693\n",
      "\n",
      "***** Iteration #387 *****\n",
      "Loss: 94487.585946\n",
      "Feature norm: 122.608924\n",
      "Error norm: 264.996838\n",
      "Active features: 61283\n",
      "Line search trials: 3\n",
      "Line search step: 0.250000\n",
      "Seconds required for this iteration: 49.709\n",
      "\n",
      "***** Iteration #388 *****\n",
      "Loss: 94487.514242\n",
      "Feature norm: 122.609574\n",
      "Error norm: 162.272692\n",
      "Active features: 61273\n",
      "Line search trials: 3\n",
      "Line search step: 0.250000\n",
      "Seconds required for this iteration: 49.023\n",
      "\n",
      "***** Iteration #389 *****\n",
      "Loss: 94487.451223\n",
      "Feature norm: 122.610353\n",
      "Error norm: 201.977301\n",
      "Active features: 61293\n",
      "Line search trials: 3\n",
      "Line search step: 0.250000\n",
      "Seconds required for this iteration: 52.103\n",
      "\n",
      "***** Iteration #390 *****\n",
      "Loss: 94487.414938\n",
      "Feature norm: 122.611072\n",
      "Error norm: 243.194205\n",
      "Active features: 61286\n",
      "Line search trials: 3\n",
      "Line search step: 0.250000\n",
      "Seconds required for this iteration: 51.631\n",
      "\n",
      "***** Iteration #391 *****\n",
      "Loss: 94487.332743\n",
      "Feature norm: 122.612700\n",
      "Error norm: 353.929865\n",
      "Active features: 61280\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 33.597\n",
      "\n",
      "L-BFGS terminated with the stopping criteria\n",
      "Total seconds required for training: 9074.743\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 61280 (6870888)\n",
      "Number of active attributes: 36428 (6731769)\n",
      "Number of active labels: 2 (2)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.178\n",
      "\n",
      "CPU times: user 2h 26min 31s, sys: 11min, total: 2h 37min 31s\n",
      "Wall time: 2h 36min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train model\n",
    "trainer = pycrfsuite.Trainer(verbose=True)\n",
    "\n",
    "for xseq, yseq in tqdm(zip(ted_x_train, ted_y_train), total=len(ted_y_train)):\n",
    "    trainer.append(xseq, yseq)\n",
    "    \n",
    "trainer.append(orchid_x_train, orchid_y_train)\n",
    "\n",
    "for xseq, yseq in tqdm(zip(fake_review_x_train, fake_review_y_train), total=len(fake_review_y_train)):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1,\n",
    "    'c2': 0,\n",
    "    'max_iterations': 1000,\n",
    "    'feature.possible_transitions': True,\n",
    "})\n",
    "\n",
    "trainer.train('models/datasets-crf.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AJv5UmIqkilU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:05<00:00, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate TED dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.66      0.77      0.71      6990\n",
      "           I       0.99      0.98      0.99    155172\n",
      "\n",
      "    accuracy                           0.97    162162\n",
      "   macro avg       0.82      0.88      0.85    162162\n",
      "weighted avg       0.98      0.97      0.97    162162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ted\n",
    "# Predict (using test set)\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('models/datasets-crf.model')\n",
    "# y_pred = [tagger.tag(xseq) for xseq in x_test]\n",
    "y_pred = []\n",
    "for xseq in tqdm(ted_x_test, total=len(ted_x_test)):\n",
    "    y_pred.append(tagger.tag(xseq))\n",
    "\n",
    "# Evaluate at word-level\n",
    "labels = {'E': 0, \"I\": 1} # classification_report() needs values in 0s and 1s\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in ted_y_test for tag in row])\n",
    "\n",
    "print(\"Validate TED dataset\")\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"E\", \"I\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3_HpFCguz09G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error space correct: 0.21750450630883236 from shape: (19972, 5)\n",
      "Accuracy space correct: 0.78\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(ted_y_test)):\n",
    "    s=0\n",
    "    for j in range(len(ted_y_test[i])):\n",
    "        results.append({'sentence_idx':f'{str(i).zfill(3)}_{str(s).zfill(3)}',\n",
    "                        'word':ted_x_test[i][j][7].split('=')[1],\n",
    "                        'y':ted_y_test[i][j],\n",
    "                        'pred':y_pred[i][j]})\n",
    "        if ted_y_test[i][j]=='E': s+=1\n",
    "result_df = pd.DataFrame(results)[['sentence_idx','word','y','pred']]\n",
    "result_df['wrong_flag'] = result_df.apply(lambda row: 0 if row.y==row.pred else 1,1)\n",
    "\n",
    "#space correct\n",
    "space_df = result_df.copy()\n",
    "space_df = space_df[space_df.word==' ']\n",
    "print(f\"Error space correct: {space_df.wrong_flag.mean()} from shape: {space_df.shape}\")\n",
    "print(f\"Accuracy space correct: {1 - space_df.wrong_flag.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uxKLM3tYkklz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate orchid dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.73      0.66      0.69      1179\n",
      "           I       0.98      0.98      0.98     17112\n",
      "\n",
      "    accuracy                           0.96     18291\n",
      "   macro avg       0.85      0.82      0.84     18291\n",
      "weighted avg       0.96      0.96      0.96     18291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# orchid\n",
    "# Predict (using test set)\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('models/datasets-crf.model')\n",
    "y_pred = tagger.tag(orchid_x_test)\n",
    "\n",
    "# Evaluate at word-level\n",
    "labels = {'E': 0, \"I\": 1} # classification_report() needs values in 0s and 1s\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in orchid_y_test for tag in row])\n",
    "\n",
    "print(\"Validate orchid dataset\")\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"E\", \"I\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "qH4hRtLP0jGl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error space correct: 0.1805809997382884 from shape: (3821, 4)\n",
      "Accuracy space correct: 0.82\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(orchid_y_test)):\n",
    "    results.append({'word':orchid_x_test[i][7].split('=')[1],\n",
    "                    'y':orchid_y_test[i],\n",
    "                    'pred':y_pred[i]})\n",
    "result_df = pd.DataFrame(results)[['word','y','pred']]\n",
    "result_df['wrong_flag'] = result_df.apply(lambda row: 0 if row.y==row.pred else 1,1)\n",
    "\n",
    "#space correct\n",
    "space_df = result_df.copy()\n",
    "space_df = space_df[space_df.word==' ']\n",
    "print(f\"Error space correct: {space_df.wrong_flag.mean()} from shape: {space_df.shape}\")\n",
    "print(f\"Accuracy space correct: {1 - space_df.wrong_flag.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DFw5T7BdkmZ9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9908/9908 [00:18<00:00, 528.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate TED dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.98      0.95      0.96     43254\n",
      "           I       1.00      1.00      1.00    568931\n",
      "\n",
      "    accuracy                           1.00    612185\n",
      "   macro avg       0.99      0.98      0.98    612185\n",
      "weighted avg       1.00      1.00      1.00    612185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fake review\n",
    "# Predict (using test set)\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('models/datasets-crf.model')\n",
    "# y_pred = [tagger.tag(xseq) for xseq in x_test]\n",
    "y_pred = []\n",
    "for xseq in tqdm(fake_review_x_test, total=len(fake_review_x_test)):\n",
    "    y_pred.append(tagger.tag(xseq))\n",
    "\n",
    "# Evaluate at word-level\n",
    "labels = {'E': 0, \"I\": 1} # classification_report() needs values in 0s and 1s\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in fake_review_y_test for tag in row])\n",
    "\n",
    "print(\"Validate TED dataset\")\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"E\", \"I\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "eAbGxRhO0zii"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error space correct: 0.03782579862110387 from shape: (79919, 5)\n",
      "Accuracy space correct: 0.96\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(fake_review_y_test)):\n",
    "    s=0\n",
    "    for j in range(len(fake_review_y_test[i])):\n",
    "        results.append({'sentence_idx':f'{str(i).zfill(3)}_{str(s).zfill(3)}',\n",
    "                        'word':fake_review_x_test[i][j][7].split('=')[1],\n",
    "                        'y':fake_review_y_test[i][j],\n",
    "                        'pred':y_pred[i][j]})\n",
    "        if fake_review_y_test[i][j]=='E': s+=1\n",
    "result_df = pd.DataFrame(results)[['sentence_idx','word','y','pred']]\n",
    "result_df['wrong_flag'] = result_df.apply(lambda row: 0 if row.y==row.pred else 1,1)\n",
    "\n",
    "#space correct\n",
    "space_df = result_df.copy()\n",
    "space_df = space_df[space_df.word==' ']\n",
    "print(f\"Error space correct: {space_df.wrong_flag.mean()} from shape: {space_df.shape}\")\n",
    "print(f\"Accuracy space correct: {1 - space_df.wrong_flag.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiZfHkID1Gi2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "สำเนาของ sentenceseg_3dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
