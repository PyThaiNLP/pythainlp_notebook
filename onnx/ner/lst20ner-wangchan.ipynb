{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817e8de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "     |████████████████████████████████| 4.9 MB 1.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (0.0.35)\n",
      "Collecting onnxconverter-common\n",
      "  Downloading onnxconverter_common-1.9.0-py2.py3-none-any.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 53.1 MB/s            \n",
      "\u001b[?25hCollecting onnxruntime-tools\n",
      "  Downloading onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)\n",
      "     |████████████████████████████████| 212 kB 37.3 MB/s            \n",
      "\u001b[?25hCollecting tf2onnx\n",
      "  Downloading tf2onnx-1.9.3-py3-none-any.whl (435 kB)\n",
      "     |████████████████████████████████| 435 kB 25.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf in /opt/conda/lib/python3.8/site-packages (from onnxruntime) (3.17.3)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.8/site-packages (from onnxruntime) (1.21.5)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.8/site-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from sacremoses) (4.62.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses) (8.0.3)\n",
      "Requirement already satisfied: onnx in /opt/conda/lib/python3.8/site-packages (from onnxconverter-common) (1.10.2)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     |████████████████████████████████| 46 kB 44.0 MB/s            \n",
      "\u001b[?25hCollecting py-cpuinfo\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "     |████████████████████████████████| 99 kB 60.0 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py3nvml\n",
      "  Downloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
      "     |████████████████████████████████| 55 kB 36.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from onnxruntime-tools) (5.8.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from onnxruntime-tools) (21.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from tf2onnx) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.8/site-packages (from onnx->onnxconverter-common) (3.7.4.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.8/site-packages (from coloredlogs->onnxruntime-tools) (10.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->onnxruntime-tools) (2.4.7)\n",
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->tf2onnx) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->tf2onnx) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->tf2onnx) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->tf2onnx) (2.0.4)\n",
      "Building wheels for collected packages: py-cpuinfo\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=fdbb1e733ed555b135e31e9849e3097eab3f85c4de86b904cbf1e681492eeb45\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sckgbv6r/wheels/57/cb/6d/bab2257f26c5be4a96ff65c3d2a7122c96529b73773ee37f36\n",
      "Successfully built py-cpuinfo\n",
      "Installing collected packages: xmltodict, py3nvml, py-cpuinfo, coloredlogs, tf2onnx, onnxruntime-tools, onnxruntime, onnxconverter-common\n",
      "Successfully installed coloredlogs-15.0.1 onnxconverter-common-1.9.0 onnxruntime-1.10.0 onnxruntime-tools-1.7.0 py-cpuinfo-8.0.0 py3nvml-0.2.7 tf2onnx-1.9.3 xmltodict-0.12.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install onnxruntime sacremoses onnxconverter-common onnxruntime-tools tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3f2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.onnx.features import FeaturesManager\n",
    "\n",
    "distilbert_features = list(FeaturesManager.get_supported_features_for_model_type(\"bert\").keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c97dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default', 'masked-lm', 'causal-lm', 'sequence-classification', 'token-classification', 'question-answering']\n"
     ]
    }
   ],
   "source": [
    "print(distilbert_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "886b0b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2022-03-15 15:03:00.695733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "usage: Hugging Face ONNX Exporter tool [-h] -m MODEL\n",
      "                                       [--feature {causal-lm,causal-lm-with-past,default,default-with-past,masked-lm,question-answering,seq2seq-lm,seq2seq-lm-with-past,sequence-classification,token-classification}]\n",
      "                                       [--opset OPSET] [--atol ATOL]\n",
      "                                       output\n",
      "\n",
      "positional arguments:\n",
      "  output                Path indicating where to store generated ONNX model.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -m MODEL, --model MODEL\n",
      "                        Model's name of path on disk to load.\n",
      "  --feature {causal-lm,causal-lm-with-past,default,default-with-past,masked-lm,question-answering,seq2seq-lm,seq2seq-lm-with-past,sequence-classification,token-classification}\n",
      "                        Export the model with some additional feature.\n",
      "  --opset OPSET         ONNX opset version to export the model with (default\n",
      "                        12).\n",
      "  --atol ATOL           Absolute difference tolerence when validating the\n",
      "                        model.\n"
     ]
    }
   ],
   "source": [
    "!python -m transformers.onnx --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d812db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Cloning into 'wangchanberta-base-att-spm-uncased'...\n",
      "remote: Enumerating objects: 251, done.\u001b[K\n",
      "remote: Counting objects: 100% (251/251), done.\u001b[K\n",
      "remote: Compressing objects: 100% (249/249), done.\u001b[K\n",
      "remote: Total 251 (delta 156), reused 0 (delta 0)\u001b[K00 KiB/s   \n",
      "Receiving objects: 100% (251/251), 603.98 KiB | 138.00 KiB/s, done.\n",
      "Resolving deltas: 100% (156/156), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50a1545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/pythainlp-work/onnx/wangchanberta-base-att-spm-uncased\n"
     ]
    }
   ],
   "source": [
    "cd wangchanberta-base-att-spm-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b18b1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Branch 'finetuned@lst20-ner' set up to track remote branch 'finetuned@lst20-ner' from 'origin'.\n",
      "Switched to a new branch 'finetuned@lst20-ner'\n"
     ]
    }
   ],
   "source": [
    "!git checkout finetuned@lst20-ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd025740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/pythainlp-work/onnx\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80a3ee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mv wangchanberta-base-att-spm-uncased cat-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c68bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e681acfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  git-lfs\n",
      "0 upgraded, 1 newly installed, 0 to remove and 17 not upgraded.\n",
      "Need to get 2129 kB of archives.\n",
      "After this operation, 7662 kB of additional disk space will be used.\n",
      "E: You don't have enough free space in /var/cache/apt/archives/.\n"
     ]
    }
   ],
   "source": [
    "!apt install -y git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e0a9a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-15 15:23:41.907191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Using framework PyTorch: 1.10.2+cu111\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "/opt/conda/lib/python3.8/site-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/opt/conda/lib/python3.8/site-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n",
      "Validating ONNX model...\n",
      "\t-[✓] ONNX model outputs' name match reference model ({'logits'})\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 8, 31) matches (2, 8, 31)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "All good, model saved at: onnx/model.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m transformers.onnx \\\n",
    "    --model=./cat-model \\\n",
    "    --feature=token-classification \\\n",
    "    onnx/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab31960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 15:25:03.551592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from onnxruntime import (\n",
    "    InferenceSession, SessionOptions, GraphOptimizationLevel\n",
    ")\n",
    "from transformers import (\n",
    "    TokenClassificationPipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c9394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = SessionOptions() # initialize session options\n",
    "options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "\n",
    "session = InferenceSession(\n",
    "    \"onnx/model.onnx\", sess_options=options, providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "\n",
    "# disable session.run() fallback mechanism, it prevents for a reset of the execution provider\n",
    "session.disable_fallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe24f8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TensorrtExecutionProvider',\n",
       " 'CUDAExecutionProvider',\n",
       " 'MIGraphXExecutionProvider',\n",
       " 'ROCMExecutionProvider',\n",
       " 'OpenVINOExecutionProvider',\n",
       " 'DnnlExecutionProvider',\n",
       " 'NupharExecutionProvider',\n",
       " 'VitisAIExecutionProvider',\n",
       " 'NnapiExecutionProvider',\n",
       " 'CoreMLExecutionProvider',\n",
       " 'ArmNNExecutionProvider',\n",
       " 'ACLExecutionProvider',\n",
       " 'DmlExecutionProvider',\n",
       " 'RknpuExecutionProvider',\n",
       " 'CPUExecutionProvider']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from onnxruntime import get_all_providers\n",
    "\n",
    "get_all_providers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc406cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnnxTokenClassificationPipeline(TokenClassificationPipeline):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    \n",
    "    def _forward(self, model_inputs):\n",
    "        \"\"\"\n",
    "        Forward pass through the model. This method is not to be called by the user directly and is only used\n",
    "        by the pipeline to perform the actual predictions.\n",
    "        This is where we will define the actual process to do inference with the ONNX model and the session created\n",
    "        before.\n",
    "        \"\"\"\n",
    "\n",
    "        # This comes from the original implementation of the pipeline\n",
    "        special_tokens_mask = model_inputs.pop(\"special_tokens_mask\")\n",
    "        offset_mapping = model_inputs.pop(\"offset_mapping\", None)\n",
    "        sentence = model_inputs.pop(\"sentence\")\n",
    "\n",
    "        inputs = {k: v.cpu().detach().numpy() for k, v in model_inputs.items()} # dict of numpy arrays\n",
    "        outputs_name = session.get_outputs()[0].name # get the name of the output tensor\n",
    "\n",
    "        logits = session.run(output_names=[outputs_name], input_feed=inputs)[0] # run the session\n",
    "        logits = torch.tensor(logits) # convert to torch tensor to be compatible with the original implementation\n",
    "\n",
    "        return {\n",
    "            \"logits\": logits,\n",
    "            \"special_tokens_mask\": special_tokens_mask,\n",
    "            \"offset_mapping\": offset_mapping,\n",
    "            \"sentence\": sentence,\n",
    "            **model_inputs,\n",
    "        }\n",
    "\n",
    "    # We need to override the preprocess method because the onnx model is waiting for the attention masks as inputs\n",
    "    # along with the embeddings.\n",
    "    def preprocess(self, sentence, offset_mapping=None):\n",
    "        truncation = True if self.tokenizer.model_max_length and self.tokenizer.model_max_length > 0 else False\n",
    "        model_inputs = self.tokenizer(\n",
    "            sentence,\n",
    "            return_attention_mask=True, # This is the only difference from the original implementation\n",
    "            return_tensors=self.framework,\n",
    "            truncation=truncation,\n",
    "            return_special_tokens_mask=True,\n",
    "            return_offsets_mapping=self.tokenizer.is_fast,\n",
    "        )\n",
    "        if offset_mapping:\n",
    "            model_inputs[\"offset_mapping\"] = offset_mapping\n",
    "\n",
    "        model_inputs[\"sentence\"] = sentence\n",
    "\n",
    "        return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3bdadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_from_hub = \"./cat-model\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_from_hub)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name_from_hub)\n",
    "\n",
    "onnx_pipeline = OnnxTokenClassificationPipeline(\n",
    "    task=\"ner\", \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\",\n",
    "    aggregation_strategy=\"simple\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13669f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_pipeline.framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86b06aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CamembertForTokenClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(25005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=31, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6425eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence  = \"ตอนนี้เวลา 19:18 น. เราจะไปไหน\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aee643ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'B_DTM',\n",
       "  'score': 0.84454143,\n",
       "  'word': 'เวลา 19:18',\n",
       "  'start': 6,\n",
       "  'end': 16},\n",
       " {'entity_group': 'E_DTM',\n",
       "  'score': 0.98721534,\n",
       "  'word': 'น.',\n",
       "  'start': 16,\n",
       "  'end': 19}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_pipeline(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf2c6224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f1b395f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence2=\"ผมเป็นแมว\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ddb8e23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [5, 330, 17, 1624, 6], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(sequence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "963891bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ca32b869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>NOTUSED', 0),\n",
       " ('<pad>', 1),\n",
       " ('</s>NOTUSED', 2),\n",
       " ('<unk>', 3),\n",
       " ('<unk>NOTUSED', 4),\n",
       " ('<s>', 5),\n",
       " ('</s>', 6),\n",
       " ('<_>', 8),\n",
       " ('า', 9),\n",
       " ('▁', 10),\n",
       " ('.', 11),\n",
       " ('ที่', 12),\n",
       " ('และ', 13),\n",
       " (',', 14),\n",
       " ('ได้', 15),\n",
       " ('ของ', 16),\n",
       " ('เป็น', 17),\n",
       " ('\"', 18),\n",
       " ('▁\"', 19),\n",
       " ('ใน', 20),\n",
       " ('ให้', 21),\n",
       " ('แล้ว', 22),\n",
       " ('มี', 23),\n",
       " ('การ', 24),\n",
       " ('(', 25),\n",
       " ('มา', 26),\n",
       " ('ว่า', 27),\n",
       " ('ไป', 28),\n",
       " (')', 29),\n",
       " ('แต่', 30),\n",
       " ('หรือ', 31),\n",
       " ('จาก', 32),\n",
       " ('กับ', 33),\n",
       " ('ๆ', 34),\n",
       " ('-', 35),\n",
       " ('ก็', 36),\n",
       " ('จะ', 37),\n",
       " ('#', 38),\n",
       " ('คน', 39),\n",
       " ('ส', 40),\n",
       " ('ค', 41),\n",
       " ('น', 42),\n",
       " ('พ', 43),\n",
       " ('นี้', 44),\n",
       " ('ด้วย', 45),\n",
       " ('ต', 46),\n",
       " ('2', 47),\n",
       " ('เลย', 48),\n",
       " ('โดย', 49),\n",
       " ('อ', 50),\n",
       " ('ไม่', 51),\n",
       " ('คือ', 52),\n",
       " ('\"\"', 53),\n",
       " ('เพื่อ', 54),\n",
       " ('อยู่', 55),\n",
       " ('ย', 56),\n",
       " ('?', 57),\n",
       " ('อย่าง', 58),\n",
       " ('1', 59),\n",
       " ('ซึ่ง', 60),\n",
       " ('ก', 61),\n",
       " (':', 62),\n",
       " ('ความ', 63),\n",
       " ('3', 64),\n",
       " ('5', 65),\n",
       " ('มัน', 66),\n",
       " ('กัน', 67),\n",
       " ('ปี', 68),\n",
       " ('เพราะ', 69),\n",
       " ('ค่ะ', 70),\n",
       " ('นาย', 71),\n",
       " ('นั้น', 72),\n",
       " ('ครับ', 73),\n",
       " ('นะ', 74),\n",
       " ('ทาง', 75),\n",
       " ('ม', 76),\n",
       " ('คุณ', 77),\n",
       " ('ไม่ได้', 78),\n",
       " ('เรื่อง', 79),\n",
       " ('เขา', 80),\n",
       " ('ดี', 81),\n",
       " ('มาก', 82),\n",
       " ('ต้อง', 83),\n",
       " ('แบบ', 84),\n",
       " ('...', 85),\n",
       " ('ป', 86),\n",
       " ('ถึง', 87),\n",
       " ('เรา', 88),\n",
       " ('ศ', 89),\n",
       " ('ตาม', 90),\n",
       " ('ตัว', 91),\n",
       " ('ผม', 92),\n",
       " ('อีก', 93),\n",
       " ('ทํา', 94),\n",
       " ('ยัง', 95),\n",
       " ('เมื่อ', 96),\n",
       " ('4', 97),\n",
       " ('ทั้ง', 98),\n",
       " ('ดู', 99),\n",
       " ('ต่อ', 100),\n",
       " ('/', 101),\n",
       " ('จ', 102),\n",
       " ('ใช้', 103),\n",
       " ('ร', 104),\n",
       " ('ก่อน', 105),\n",
       " ('ฉัน', 106),\n",
       " ('ขึ้น', 107),\n",
       " ('ท', 108),\n",
       " ('ไทย', 109),\n",
       " ('s', 110),\n",
       " ('ถูก', 111),\n",
       " ('เข้า', 112),\n",
       " ('บ', 113),\n",
       " ('ในการ', 114),\n",
       " ('ผู้', 115),\n",
       " ('ทําให้', 116),\n",
       " ('สําหรับ', 117),\n",
       " ('อะไร', 118),\n",
       " ('หน้า', 119),\n",
       " ('ด', 120),\n",
       " ('ถ้า', 121),\n",
       " ('!', 122),\n",
       " ('ว', 123),\n",
       " ('นี่', 124),\n",
       " ('วัน', 125),\n",
       " ('ใหม่', 126),\n",
       " ('หลัง', 127),\n",
       " ('เธอ', 128),\n",
       " ('พร้อม', 129),\n",
       " ('ไว้', 130),\n",
       " ('ส่วน', 131),\n",
       " ('พี่', 132),\n",
       " ('ออก', 133),\n",
       " ('”', 134),\n",
       " ('tab', 135),\n",
       " ('ประเทศ', 136),\n",
       " ('บ้าน', 137),\n",
       " ('ลูก', 138),\n",
       " ('งาน', 139),\n",
       " ('จน', 140),\n",
       " ('จึง', 141),\n",
       " ('เอา', 142),\n",
       " ('น้ํา', 143),\n",
       " ('การเมือง', 144),\n",
       " ('แม่', 145),\n",
       " (\"'\", 146),\n",
       " ('เจ้าหน้า', 147),\n",
       " ('7', 148),\n",
       " ('เครื่อง', 149),\n",
       " ('เ', 150),\n",
       " ('สามารถ', 151),\n",
       " ('6', 152),\n",
       " ('ละ', 153),\n",
       " ('ลง', 154),\n",
       " ('วันที่', 155),\n",
       " ('เวลา', 156),\n",
       " ('10', 157),\n",
       " ('กว่า', 158),\n",
       " ('ไม่มี', 159),\n",
       " (';', 160),\n",
       " ('เมือง', 161),\n",
       " ('ช', 162),\n",
       " ('ระหว่าง', 163),\n",
       " ('“', 164),\n",
       " ('จริง', 165),\n",
       " ('ขอ', 166),\n",
       " ('ใจ', 167),\n",
       " ('แห่ง', 168),\n",
       " ('ล', 169),\n",
       " ('ประชาชน', 170),\n",
       " ('กลุ่ม', 171),\n",
       " ('พล', 172),\n",
       " ('ที่จะ', 173),\n",
       " ('เช่น', 174),\n",
       " ('กําลัง', 175),\n",
       " ('เหมือน', 176),\n",
       " ('บาท', 177),\n",
       " ('ดังกล่าว', 178),\n",
       " ('รับ', 179),\n",
       " ('รถ', 180),\n",
       " ('เห็น', 181),\n",
       " ('ง', 182),\n",
       " ('หนึ่ง', 183),\n",
       " ('จังหวัด', 184),\n",
       " ('เอง', 185),\n",
       " ('ด้าน', 186),\n",
       " ('จริงๆ', 187),\n",
       " ('พระ', 188),\n",
       " ('ช่วย', 189),\n",
       " ('น้อง', 190),\n",
       " ('ท่าน', 191),\n",
       " ('ชอบ', 192),\n",
       " ('ราคา', 193),\n",
       " ('ฯ', 194),\n",
       " ('ที่มี', 195),\n",
       " ('เกี่ยวกับ', 196),\n",
       " ('ใคร', 197),\n",
       " ('แค่', 198),\n",
       " ('ผ่าน', 199),\n",
       " ('เล่น', 200),\n",
       " ('เด็ก', 201),\n",
       " ('นะคะ', 202),\n",
       " ('8', 203),\n",
       " ('บอก', 204),\n",
       " ('a', 205),\n",
       " ('▁-', 206),\n",
       " ('จํานวน', 207),\n",
       " ('ต่างๆ', 208),\n",
       " ('คิด', 209),\n",
       " ('ทั้งหมด', 210),\n",
       " ('ไม่ใช่', 211),\n",
       " ('ประเทศไทย', 212),\n",
       " ('เจ้า', 213),\n",
       " ('พื้นที่', 214),\n",
       " ('นัก', 215),\n",
       " ('เลือกตั้ง', 216),\n",
       " ('ใหญ่', 217),\n",
       " ('พรรค', 218),\n",
       " ('เดือน', 219),\n",
       " ('พอ', 220),\n",
       " ('ใส่', 221),\n",
       " ('▁และ', 222),\n",
       " ('ตอน', 223),\n",
       " ('ออกมา', 224),\n",
       " ('ทุก', 225),\n",
       " ('รัฐบาล', 226),\n",
       " ('แบบนี้', 227),\n",
       " ('เปิด', 228),\n",
       " ('ตัวเอง', 229),\n",
       " ('ทีม', 230),\n",
       " ('เปลี่ยน', 231),\n",
       " ('ชั้น', 232),\n",
       " ('ประมาณ', 233),\n",
       " ('เงิน', 234),\n",
       " ('รัก', 235),\n",
       " ('เสียง', 236),\n",
       " ('ชื่อ', 237),\n",
       " ('ซื้อ', 238),\n",
       " ('ส่ง', 239),\n",
       " ('เข้ามา', 240),\n",
       " ('กิน', 241),\n",
       " ('ตั้งแต่', 242),\n",
       " ('มากกว่า', 243),\n",
       " ('กล่าวว่า', 244),\n",
       " ('เกิดขึ้น', 245),\n",
       " ('พูด', 246),\n",
       " ('ที่ผ่านมา', 247),\n",
       " ('เริ่ม', 248),\n",
       " ('9', 249),\n",
       " ('x', 250),\n",
       " ('วันนี้', 251),\n",
       " ('ต่อไป', 252),\n",
       " ('เค้า', 253),\n",
       " ('นํา', 254),\n",
       " ('20', 255),\n",
       " ('▁&', 256),\n",
       " ('อัน', 257),\n",
       " ('ทํางาน', 258),\n",
       " ('กลับ', 259),\n",
       " ('คะ', 260),\n",
       " ('บ้าง', 261),\n",
       " ('อยู่ใน', 262),\n",
       " ('ตอนนี้', 263),\n",
       " ('▁ฉัน', 264),\n",
       " ('_', 265),\n",
       " ('ติด', 266),\n",
       " ('ค่า', 267),\n",
       " ('เท่านั้น', 268),\n",
       " ('ระบบ', 269),\n",
       " ('สี', 270),\n",
       " ('รัฐธรรมนูญ', 271),\n",
       " ('ชีวิต', 272),\n",
       " ('สร้าง', 273),\n",
       " ('สาย', 274),\n",
       " ('ตํารวจ', 275),\n",
       " ('เดียวกัน', 276),\n",
       " ('พวก', 277),\n",
       " ('เอ', 278),\n",
       " ('หา', 279),\n",
       " ('ต่าง', 280),\n",
       " ('ขาย', 281),\n",
       " ('สิ', 282),\n",
       " ('เศรษฐกิจ', 283),\n",
       " ('ข้อมูล', 284),\n",
       " ('บอกว่า', 285),\n",
       " ('เพิ่ม', 286),\n",
       " ('หนังสือ', 287),\n",
       " ('ตาย', 288),\n",
       " ('รอ', 289),\n",
       " ('โลก', 290),\n",
       " ('สอง', 291),\n",
       " ('e', 292),\n",
       " ('the', 293),\n",
       " ('▁แต่', 294),\n",
       " ('พบ', 295),\n",
       " ('▁คุณ', 296),\n",
       " ('เนื่องจาก', 297),\n",
       " ('ร้าน', 298),\n",
       " (\"&'\", 299),\n",
       " ('อะ', 300),\n",
       " ('เกิด', 301),\n",
       " ('t', 302),\n",
       " ('หัว', 303),\n",
       " ('โครงการ', 304),\n",
       " ('อยาก', 305),\n",
       " ('ภายใน', 306),\n",
       " ('ณ', 307),\n",
       " ('เสียชีวิต', 308),\n",
       " ('เลือก', 309),\n",
       " ('ซึ่งเป็น', 310),\n",
       " ('บริษัท', 311),\n",
       " ('ต้องการ', 312),\n",
       " ('30', 313),\n",
       " ('พ่อ', 314),\n",
       " ('รวม', 315),\n",
       " ('เข้าไป', 316),\n",
       " ('วัด', 317),\n",
       " ('อายุ', 318),\n",
       " ('อาหาร', 319),\n",
       " ('b', 320),\n",
       " ('อ่าน', 321),\n",
       " ('ภาพ', 322),\n",
       " ('คํา', 323),\n",
       " ('ดําเนินการ', 324),\n",
       " ('กู', 325),\n",
       " ('บน', 326),\n",
       " ('ห', 327),\n",
       " ('ได้รับ', 328),\n",
       " ('สุด', 329),\n",
       " ('▁ผม', 330),\n",
       " ('▁นาย', 331),\n",
       " ('คณะกรรมการ', 332),\n",
       " ('สูง', 333),\n",
       " ('อื่น', 334),\n",
       " ('ไหม', 335),\n",
       " ('เสีย', 336),\n",
       " ('หรือไม่', 337),\n",
       " ('15', 338),\n",
       " ('นะครับ', 339),\n",
       " ('ตําแหน่ง', 340),\n",
       " ('d', 341),\n",
       " ('เพียง', 342),\n",
       " ('ทุกคน', 343),\n",
       " ('ชุด', 344),\n",
       " ('ระดับ', 345),\n",
       " ('รู้', 346),\n",
       " ('เหมือนกัน', 347),\n",
       " ('ปัญหา', 348),\n",
       " ('เพื่อน', 349),\n",
       " ('เม', 350),\n",
       " ('ชาว', 351),\n",
       " ('โดน', 352),\n",
       " ('คง', 353),\n",
       " ('ทรง', 354),\n",
       " ('อาจ', 355),\n",
       " ('หาก', 356),\n",
       " ('ศาสตร์', 357),\n",
       " ('ร่วม', 358),\n",
       " ('ครอบครัว', 359),\n",
       " ('ตั้ง', 360),\n",
       " ('i', 361),\n",
       " ('ฝ่าย', 362),\n",
       " ('ไม่สามารถ', 363),\n",
       " ('ตรวจสอบ', 364),\n",
       " ('นาง', 365),\n",
       " ('กฎหมาย', 366),\n",
       " ('ก็ได้', 367),\n",
       " ('จะมี', 368),\n",
       " ('่', 369),\n",
       " ('มอง', 370),\n",
       " ('ที', 371),\n",
       " ('มีความ', 372),\n",
       " ('เรียก', 373),\n",
       " ('กลับมา', 374),\n",
       " ('จัด', 375),\n",
       " ('น่า', 376),\n",
       " ('โรงเรียน', 377),\n",
       " ('ขณะที่', 378),\n",
       " ('สนับสนุน', 379),\n",
       " ('ผล', 380),\n",
       " ('เรื่องนี้', 381),\n",
       " ('กล่าว', 382),\n",
       " ('ในปี', 383),\n",
       " ('เรียน', 384),\n",
       " ('บริเวณ', 385),\n",
       " ('พวกเขา', 386),\n",
       " ('ทหาร', 387),\n",
       " ('แก่', 388),\n",
       " ('รอบ', 389),\n",
       " ('เกี่ยวข้อง', 390),\n",
       " ('▁ถ้า', 391),\n",
       " ('มือ', 392),\n",
       " ('คนที่', 393),\n",
       " ('ขนาด', 394),\n",
       " ('ของเรา', 395),\n",
       " ('มิ', 396),\n",
       " ('มีการ', 397),\n",
       " ('มหาวิทยาลั', 398),\n",
       " ('สินค้า', 399),\n",
       " ('จับ', 400),\n",
       " ('คดี', 401),\n",
       " ('ช่วยเหลือ', 402),\n",
       " ('หลังจาก', 403),\n",
       " ('เพลง', 404),\n",
       " ('แห่งชาติ', 405),\n",
       " ('อ่ะ', 406),\n",
       " ('ส์', 407),\n",
       " ('หมด', 408),\n",
       " ('12', 409),\n",
       " ('ให้กับ', 410),\n",
       " ('m', 411),\n",
       " ('ในพื้นที่', 412),\n",
       " ('ผิด', 413),\n",
       " ('หลาย', 414),\n",
       " ('อย่างไร', 415),\n",
       " ('เหตุการณ์', 416),\n",
       " ('ธ', 417),\n",
       " ('เคย', 418),\n",
       " ('รัฐ', 419),\n",
       " ('ประโยชน์', 420),\n",
       " ('เจอ', 421),\n",
       " ('สิ่งที่', 422),\n",
       " ('บาง', 423),\n",
       " ('น้อย', 424),\n",
       " ('สั่ง', 425),\n",
       " ('โอ', 426),\n",
       " ('ตน', 427),\n",
       " ('ะ', 428),\n",
       " ('มากขึ้น', 429),\n",
       " ('รัฐมนตรี', 430),\n",
       " ('้', 431),\n",
       " ('ทําไม', 432),\n",
       " ('เดียว', 433),\n",
       " ('จุด', 434),\n",
       " ('ฟ', 435),\n",
       " ('ออกไป', 436),\n",
       " ('ราย', 437),\n",
       " ('หลัก', 438),\n",
       " ('19', 439),\n",
       " ('เหรอ', 440),\n",
       " ('แทน', 441),\n",
       " ('สํานักงาน', 442),\n",
       " ('ล่ะ', 443),\n",
       " ('น่ะ', 444),\n",
       " ('เดิน', 445),\n",
       " ('อย่า', 446),\n",
       " ('24', 447),\n",
       " ('ข่าว', 448),\n",
       " ('เก็บ', 449),\n",
       " ('g', 450),\n",
       " ('in', 451),\n",
       " ('กลาง', 452),\n",
       " ('จากการ', 453),\n",
       " ('พนักงาน', 454),\n",
       " ('อํานาจ', 455),\n",
       " ('▁เรา', 456),\n",
       " ('อีกครั้ง', 457),\n",
       " ('ของคุณ', 458),\n",
       " ('️', 459),\n",
       " ('ปิด', 460),\n",
       " ('ฟัง', 461),\n",
       " ('คิดว่า', 462),\n",
       " ('k', 463),\n",
       " ('ท่องเที่ยว', 464),\n",
       " ('เป็นการ', 465),\n",
       " ('ยังไม่', 466),\n",
       " ('มาจาก', 467),\n",
       " ('นั่ง', 468),\n",
       " ('พัฒนา', 469),\n",
       " ('ทอง', 470),\n",
       " ('▁มี', 471),\n",
       " ('เตรียม', 472),\n",
       " ('ร่าง', 473),\n",
       " ('▁เพราะ', 474),\n",
       " ('น่าจะ', 475),\n",
       " ('ประกาศ', 476),\n",
       " ('เพื่อให้', 477),\n",
       " ('ก็จะ', 478),\n",
       " ('ปัจจุบัน', 479),\n",
       " ('สังคม', 480),\n",
       " ('ซี', 481),\n",
       " ('เขียน', 482),\n",
       " ('ไหน', 483),\n",
       " ('ไปแล้ว', 484),\n",
       " ('เยอะ', 485),\n",
       " ('โฮ', 486),\n",
       " ('ได้รับการ', 487),\n",
       " ('ช่อง', 488),\n",
       " ('▁โดย', 489),\n",
       " ('ควร', 490),\n",
       " ('ถาม', 491),\n",
       " ('จะได้', 492),\n",
       " ('คู่', 493),\n",
       " ('โดยเฉพาะ', 494),\n",
       " ('รูป', 495),\n",
       " ('n', 496),\n",
       " ('สถานการณ์', 497),\n",
       " ('พิเศษ', 498),\n",
       " ('c', 499),\n",
       " ('ช่วง', 500),\n",
       " ('ถนน', 501),\n",
       " ('หน่อย', 502),\n",
       " ('พระองค์', 503),\n",
       " ('555', 504),\n",
       " ('นอน', 505),\n",
       " ('ขอให้', 506),\n",
       " ('\"\"\"', 507),\n",
       " ('ระชาธิปไตย', 508),\n",
       " ('การศึกษา', 509),\n",
       " ('กะ', 510),\n",
       " ('ของเขา', 511),\n",
       " ('อี', 512),\n",
       " ('เขต', 513),\n",
       " ('14', 514),\n",
       " ('จะเป็น', 515),\n",
       " ('หรอก', 516),\n",
       " ('ปลอดภัย', 517),\n",
       " ('ต่างประเทศ', 518),\n",
       " ('แรงงาน', 519),\n",
       " ('ที่สุด', 520),\n",
       " ('มึง', 521),\n",
       " ('18', 522),\n",
       " ('ภาค', 523),\n",
       " ('f', 524),\n",
       " ('หนู', 525),\n",
       " ('พิจารณา', 526),\n",
       " ('ครั้ง', 527),\n",
       " ('ข้อ', 528),\n",
       " ('ชาวบ้าน', 529),\n",
       " ('ตลอด', 530),\n",
       " ('16', 531),\n",
       " ('เกม', 532),\n",
       " ('รู้สึก', 533),\n",
       " ('จีน', 534),\n",
       " ('กระทรวง', 535),\n",
       " ('ทุกอย่าง', 536),\n",
       " ('รี', 537),\n",
       " ('สื่อ', 538),\n",
       " ('รุ่น', 539),\n",
       " ('ศาล', 540),\n",
       " ('อําเภอ', 541),\n",
       " ('11', 542),\n",
       " ('เดิม', 543),\n",
       " ('สิทธิ', 544),\n",
       " ('นัด', 545),\n",
       " ('ขึ้นมา', 546),\n",
       " ('เรือ', 547),\n",
       " ('ล้านบาท', 548),\n",
       " ('อยู่ที่', 549),\n",
       " ('สัมพันธ์', 550),\n",
       " ('ผู้หญิง', 551),\n",
       " ('13', 552),\n",
       " ('กรณี', 553),\n",
       " ('เจ้าของ', 554),\n",
       " ('แก', 555),\n",
       " ('มั้ย', 556),\n",
       " ('ก็คือ', 557),\n",
       " ('&', 558),\n",
       " ('ร้อยละ', 559),\n",
       " ('อิ', 560),\n",
       " ('คืน', 561),\n",
       " ('จะต้อง', 562),\n",
       " ('ที่เป็น', 563),\n",
       " ('รอง', 564),\n",
       " ('ร์', 565),\n",
       " ('เนื้อ', 566),\n",
       " ('ยิง', 567),\n",
       " ('วง', 568),\n",
       " ('ญี่ปุ่น', 569),\n",
       " ('25', 570),\n",
       " ('นโยบาย', 571),\n",
       " ('สวย', 572),\n",
       " ('ปาก', 573),\n",
       " ('แรก', 574),\n",
       " ('นั่น', 575),\n",
       " ('สําคัญ', 576),\n",
       " ('เมื่อวัน', 577),\n",
       " ('คนอื่น', 578),\n",
       " ('เกิดเหตุ', 579),\n",
       " ('ห้อง', 580),\n",
       " ('หญิง', 581),\n",
       " ('ตลาด', 582),\n",
       " ('ประจํา', 583),\n",
       " ('พยายาม', 584),\n",
       " ('อาจจะ', 585),\n",
       " ('ตี', 586),\n",
       " ('อดีต', 587),\n",
       " ('ข้าว', 588),\n",
       " ('ข', 589),\n",
       " ('จบ', 590),\n",
       " ('ส่วนใหญ่', 591),\n",
       " ('ยิ่ง', 592),\n",
       " ('โต', 593),\n",
       " ('ชาติ', 594),\n",
       " ('การแข่งขัน', 595),\n",
       " ('ชาย', 596),\n",
       " ('สาม', 597),\n",
       " ('ไฟ', 598),\n",
       " ('▁ซึ่ง', 599),\n",
       " ('ตัด', 600),\n",
       " ('หน่วยงาน', 601),\n",
       " ('สุดท้าย', 602),\n",
       " ('สอบสวน', 603),\n",
       " ('ตก', 604),\n",
       " ('คณะ', 605),\n",
       " ('ร่วมกัน', 606),\n",
       " ('of', 607),\n",
       " ('ยังไง', 608),\n",
       " ('ใด', 609),\n",
       " ('y', 610),\n",
       " ('แรง', 611),\n",
       " ('ปกติ', 612),\n",
       " ('ใบ', 613),\n",
       " ('รักษา', 614),\n",
       " ('ลด', 615),\n",
       " ('ตร', 616),\n",
       " ('แน่นอน', 617),\n",
       " ('ราช', 618),\n",
       " ('ในช่วง', 619),\n",
       " ('พระเจ้า', 620),\n",
       " ('กุ', 621),\n",
       " ('ล่าสุด', 622),\n",
       " ('ยาว', 623),\n",
       " ('เน', 624),\n",
       " ('com', 625),\n",
       " ('กําหนด', 626),\n",
       " ('▁แล้ว', 627),\n",
       " ('ของฉัน', 628),\n",
       " ('ดูแล', 629),\n",
       " ('ออกจาก', 630),\n",
       " ('ลอง', 631),\n",
       " ('กลัว', 632),\n",
       " ('แสดง', 633),\n",
       " ('อื่นๆ', 634),\n",
       " ('ชัย', 635),\n",
       " ('▁ส่วน', 636),\n",
       " ('ชม', 637),\n",
       " ('ล้าน', 638),\n",
       " ('ครู', 639),\n",
       " ('กลายเป็น', 640),\n",
       " ('รายงาน', 641),\n",
       " ('ศรี', 642),\n",
       " ('ตัดสินใจ', 643),\n",
       " ('▁เมื่อ', 644),\n",
       " ('▁เธอ', 645),\n",
       " ('รวมทั้ง', 646),\n",
       " ('เหล่านี้', 647),\n",
       " ('พิมพ์', 648),\n",
       " ('ติดตาม', 649),\n",
       " ('เห็นว่า', 650),\n",
       " ('ดีกว่า', 651),\n",
       " ('ต่อเนื่อง', 652),\n",
       " ('ทั้งนี้', 653),\n",
       " ('โรงพยาบาล', 654),\n",
       " ('ชนะ', 655),\n",
       " ('รายการ', 656),\n",
       " ('เรียกร้อง', 657),\n",
       " ('ดัง', 658),\n",
       " ('เป็นคน', 659),\n",
       " ('พร', 660),\n",
       " ('▁มัน', 661),\n",
       " ('p', 662),\n",
       " ('50', 663),\n",
       " ('รวมถึง', 664),\n",
       " ('อยู่แล้ว', 665),\n",
       " ('ซ', 666),\n",
       " ('โก', 667),\n",
       " ('17', 668),\n",
       " ('์', 669),\n",
       " ('ธุรกิจ', 670),\n",
       " ('ศูนย์', 671),\n",
       " ('แดง', 672),\n",
       " ('เล็ก', 673),\n",
       " ('ไม่ต้อง', 674),\n",
       " ('เดินทาง', 675),\n",
       " ('สมาชิก', 676),\n",
       " ('เป็นผู้', 677),\n",
       " ('แล้วก็', 678),\n",
       " ('เพิ่มเติม', 679),\n",
       " ('น่ารัก', 680),\n",
       " ('เข้าใจ', 681),\n",
       " ('เพิ่มขึ้น', 682),\n",
       " ('กระบวนการ', 683),\n",
       " ('หนัง', 684),\n",
       " ('ก็มี', 685),\n",
       " ('พบว่า', 686),\n",
       " ('ยก', 687),\n",
       " ('th', 688),\n",
       " ('ธรรม', 689),\n",
       " ('=', 690),\n",
       " ('แจ้ง', 691),\n",
       " ('.\"', 692),\n",
       " ('ที่ดี', 693),\n",
       " ('วิ่ง', 694),\n",
       " ('บัตร', 695),\n",
       " ('://', 696),\n",
       " ('คัน', 697),\n",
       " ('ต้น', 698),\n",
       " ('สาว', 699),\n",
       " ('100', 700),\n",
       " ('จํานวนมาก', 701),\n",
       " ('ยังมี', 702),\n",
       " ('และการ', 703),\n",
       " ('ตรง', 704),\n",
       " ('นาที', 705),\n",
       " ('จํากัด', 706),\n",
       " ('ไม่เคย', 707),\n",
       " ('▁เขา', 708),\n",
       " ('ครั้งแรก', 709),\n",
       " ('แก้ว', 710),\n",
       " (']', 711),\n",
       " ('หยุด', 712),\n",
       " ('ปรับ', 713),\n",
       " ('v', 714),\n",
       " ('ชน', 715),\n",
       " ('ตอบ', 716),\n",
       " ('ไม้', 717),\n",
       " ('แปลง', 718),\n",
       " ('องค์กร', 719),\n",
       " ('ในวันที่', 720),\n",
       " ('เป็นเรื่อง', 721),\n",
       " ('เราก็', 722),\n",
       " ('เลี้ยง', 723),\n",
       " ('ซา', 724),\n",
       " ('เด', 725),\n",
       " ('โทรศัพท์', 726),\n",
       " ('วาง', 727),\n",
       " ('ศึกษา', 728),\n",
       " ('▁ไม่', 729),\n",
       " ('มากๆ', 730),\n",
       " ('สําเร็จ', 731),\n",
       " ('ลี', 732),\n",
       " ('สุ', 733),\n",
       " ('ขณะ', 734),\n",
       " ('จัง', 735),\n",
       " ('เฉพาะ', 736),\n",
       " ('w', 737),\n",
       " ('ไม่รู้', 738),\n",
       " ('ติ', 739),\n",
       " ('ข้า', 740),\n",
       " ('ก็ต้อง', 741),\n",
       " ('เก่า', 742),\n",
       " ('o', 743),\n",
       " ('ส่วนตัว', 744),\n",
       " ('กด', 745),\n",
       " ('ยู', 746),\n",
       " ('ประเด็น', 747),\n",
       " ('ธรรมชาติ', 748),\n",
       " ('ยาก', 749),\n",
       " ('ไปยัง', 750),\n",
       " ('เกิน', 751),\n",
       " ('ปล่อย', 752),\n",
       " ('l', 753),\n",
       " ('เต็ม', 754),\n",
       " ('นิ', 755),\n",
       " ('ขาด', 756),\n",
       " ('วัย', 757),\n",
       " ('40', 758),\n",
       " ('ครั้งนี้', 759),\n",
       " ('ชุมชน', 760),\n",
       " ('ทิ้ง', 761),\n",
       " ('ใช่', 762),\n",
       " ('เชื่อว่า', 763),\n",
       " ('สภาพ', 764),\n",
       " ('โค', 765),\n",
       " ('to', 766),\n",
       " ('เข้าร่วม', 767),\n",
       " ('ระบุว่า', 768),\n",
       " ('ปลา', 769),\n",
       " ('มากมาย', 770),\n",
       " ('สถาบัน', 771),\n",
       " ('เหนือ', 772),\n",
       " ('▁\"\"\"', 773),\n",
       " ('แฟน', 774),\n",
       " ('บี', 775),\n",
       " ('กรัฐมนตรี', 776),\n",
       " ('ร้อง', 777),\n",
       " ('มนุษย์', 778),\n",
       " ('เสียหาย', 779),\n",
       " ('เลยค่ะ', 780),\n",
       " ('สาร', 781),\n",
       " ('ดังนั้น', 782),\n",
       " ('ห้าม', 783),\n",
       " ('ที่นี่', 784),\n",
       " ('คนเดียว', 785),\n",
       " ('ฆ่า', 786),\n",
       " ('ใต้', 787),\n",
       " ('จะไม่', 788),\n",
       " ('ศักดิ์', 789),\n",
       " ('23', 790),\n",
       " ('ประธาน', 791),\n",
       " ('ป้องกัน', 792),\n",
       " ('เซ', 793),\n",
       " ('หนัก', 794),\n",
       " ('ประเภท', 795),\n",
       " ('หาย', 796),\n",
       " ('ชั่วโมง', 797),\n",
       " ('หมอ', 798),\n",
       " ('สูงสุด', 799),\n",
       " ('ด้วยกัน', 800),\n",
       " ('คับ', 801),\n",
       " ('ทําอะไร', 802),\n",
       " ('บริการ', 803),\n",
       " ('ท่า', 804),\n",
       " ('มาตรา', 805),\n",
       " ('คอ', 806),\n",
       " ('ตะวันออก', 807),\n",
       " ('ดิ', 808),\n",
       " ('จ้า', 809),\n",
       " ('ได้แก่', 810),\n",
       " ('นอกจากนี้', 811),\n",
       " ('❤', 812),\n",
       " ('ดํา', 813),\n",
       " ('ควบคุม', 814),\n",
       " ('การทํางาน', 815),\n",
       " ('ประตู', 816),\n",
       " ('ซิ', 817),\n",
       " ('แยก', 818),\n",
       " ('สภ', 819),\n",
       " ('ไร', 820),\n",
       " ('จําเป็น', 821),\n",
       " ('น้ํามัน', 822),\n",
       " ('r', 823),\n",
       " ('ประ', 824),\n",
       " ('ภ', 825),\n",
       " ('โร', 826),\n",
       " ('ความรู้สึก', 827),\n",
       " ('คนไทย', 828),\n",
       " ('ไอ้', 829),\n",
       " ('เจ', 830),\n",
       " ('หรอ', 831),\n",
       " ('มาแล้ว', 832),\n",
       " ('กร', 833),\n",
       " ('–', 834),\n",
       " ('นักเรียน', 835),\n",
       " ('สอน', 836),\n",
       " ('ริ', 837),\n",
       " ('แก้ไข', 838),\n",
       " ('เหลือ', 839),\n",
       " ('จ่าย', 840),\n",
       " ('เส้น', 841),\n",
       " ('จัดการ', 842),\n",
       " ('ลูกค้า', 843),\n",
       " ('สาขา', 844),\n",
       " ('โน', 845),\n",
       " ('เกือบ', 846),\n",
       " ('ไอ', 847),\n",
       " ('วา', 848),\n",
       " ('อุตสาหกรรม', 849),\n",
       " ('21', 850),\n",
       " ('เชื่อ', 851),\n",
       " ('เร', 852),\n",
       " ('หัวหน้า', 853),\n",
       " ('ที่ดิน', 854),\n",
       " ('บุญ', 855),\n",
       " ('รายละเอียด', 856),\n",
       " (\"▁&'\", 857),\n",
       " ('ความจริง', 858),\n",
       " ('ทั้งสอง', 859),\n",
       " ('60', 860),\n",
       " ('เครือข่าย', 861),\n",
       " ('▁section', 862),\n",
       " ('22', 863),\n",
       " ('ยอด', 864),\n",
       " ('โม', 865),\n",
       " ('ก่อนหน้า', 866),\n",
       " ('อาการ', 867),\n",
       " ('ไม่ให้', 868),\n",
       " ('แน่', 869),\n",
       " ('อิน', 870),\n",
       " ('คสช', 871),\n",
       " ('ระ', 872),\n",
       " ('รับผิดชอบ', 873),\n",
       " ('▁พี่', 874),\n",
       " ('re', 875),\n",
       " ('เชียงใหม่', 876),\n",
       " ('ทั่วไป', 877),\n",
       " ('เรียบร้อย', 878),\n",
       " ('หรือเปล่า', 879),\n",
       " ('นาน', 880),\n",
       " ('เนี่ย', 881),\n",
       " ('การประชุม', 882),\n",
       " ('สนใจ', 883),\n",
       " ('กระ', 884),\n",
       " ('แม้', 885),\n",
       " ('▁อ', 886),\n",
       " ('คะแนน', 887),\n",
       " ('พวกเรา', 888),\n",
       " ('เร่ง', 889),\n",
       " ('แนะนํา', 890),\n",
       " ('มาตรฐาน', 891),\n",
       " ('อเมริกา', 892),\n",
       " ('ส่งเสริม', 893),\n",
       " ('ไง', 894),\n",
       " ('+', 895),\n",
       " ('อยู่กับ', 896),\n",
       " ('ประวัติ', 897),\n",
       " ('เสนอ', 898),\n",
       " ('ร่วมกับ', 899),\n",
       " ('สัก', 900),\n",
       " ('ฮา', 901),\n",
       " ('ป่า', 902),\n",
       " ('ในประเทศ', 903),\n",
       " ('หลักฐาน', 904),\n",
       " ('ว่าจะ', 905),\n",
       " ('ทาน', 906),\n",
       " ('เบอร์', 907),\n",
       " ('ต์', 908),\n",
       " ('งบประมาณ', 909),\n",
       " ('ขับ', 910),\n",
       " ('จะทําให้', 911),\n",
       " ('28', 912),\n",
       " ('เมตร', 913),\n",
       " ('เราจะ', 914),\n",
       " ('โดยมี', 915),\n",
       " ('ระบุ', 916),\n",
       " ('ในเรื่อง', 917),\n",
       " ('บุคคล', 918),\n",
       " ('ing', 919),\n",
       " ('เจริญ', 920),\n",
       " ('26', 921),\n",
       " ('วะ', 922),\n",
       " ('ตรวจ', 923),\n",
       " ('มีความสุข', 924),\n",
       " ('ดาว', 925),\n",
       " ('ระเบิด', 926),\n",
       " ('อาคาร', 927),\n",
       " ('กิจกรรม', 928),\n",
       " ('อยากให้', 929),\n",
       " ('ขาว', 930),\n",
       " ('หลายคน', 931),\n",
       " ('ผลิต', 932),\n",
       " ('แพ้', 933),\n",
       " ('เอกสาร', 934),\n",
       " ('เทคโนโลยี', 935),\n",
       " ('แต่ก็', 936),\n",
       " ('วัฒนธรรม', 937),\n",
       " ('ตะ', 938),\n",
       " ('ได้อย่าง', 939),\n",
       " ('นี', 940),\n",
       " ('ผ้า', 941),\n",
       " ('ผู้ต้องหา', 942),\n",
       " ('อังกฤษ', 943),\n",
       " ('นักศึกษา', 944),\n",
       " ('ดิน', 945),\n",
       " ('ยังคง', 946),\n",
       " ('สถานที่', 947),\n",
       " ('เก่ง', 948),\n",
       " (';&', 949),\n",
       " ('รู้ว่า', 950),\n",
       " ('รถยนต์', 951),\n",
       " ('เค', 952),\n",
       " ('แต่ละ', 953),\n",
       " ('สร้างความ', 954),\n",
       " ('สิ่ง', 955),\n",
       " ('หัวใจ', 956),\n",
       " ('อาจารย์', 957),\n",
       " ('ภาษา', 958),\n",
       " ('ทะเล', 959),\n",
       " ('ร่างกาย', 960),\n",
       " ('เริ่มต้น', 961),\n",
       " ('เช่นกัน', 962),\n",
       " ('ต่อมา', 963),\n",
       " ('ซะ', 964),\n",
       " ('เถอะ', 965),\n",
       " ('ก่อสร้าง', 966),\n",
       " ('ยุติธรรม', 967),\n",
       " ('ผู้นํา', 968),\n",
       " ('หน่วย', 969),\n",
       " ('เคลื่อนไหว', 970),\n",
       " ('สัตว์', 971),\n",
       " ('แก้', 972),\n",
       " ('ยืนยัน', 973),\n",
       " ('ทุกวัน', 974),\n",
       " ('u', 975),\n",
       " ('แตก', 976),\n",
       " ('โล', 977),\n",
       " ('การใช้', 978),\n",
       " ('ภาพยนตร์', 979),\n",
       " ('เหตุ', 980),\n",
       " ('หนี', 981),\n",
       " ('ของเธอ', 982),\n",
       " ('คิดถึง', 983),\n",
       " ('▁วันนี้', 984),\n",
       " ('เผย', 985),\n",
       " ('—', 986),\n",
       " ('ง่าย', 987),\n",
       " ('ลบ', 988),\n",
       " ('กําลังใจ', 989),\n",
       " ('ขอบคุณ', 990),\n",
       " ('ใกล้', 991),\n",
       " ('สม', 992),\n",
       " ('รู้จัก', 993),\n",
       " ('กรรมการ', 994),\n",
       " ('เข้าสู่', 995),\n",
       " ('โรค', 996),\n",
       " ('ก็ไม่', 997),\n",
       " ('คุณภาพ', 998),\n",
       " ('h', 999),\n",
       " ('!!', 1000),\n",
       " ...]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(i,c[i]) for i in c.keys()],key=lambda tup: tup[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d994b636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[326, 13, 1620]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.encode(sequence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8551774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer(\n",
    "            sequence,\n",
    "            return_attention_mask=True, # This is the only difference from the original implementation\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            return_special_tokens_mask=True,\n",
    "            return_offsets_mapping=tokenizer.is_fast,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3191d891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    5,  1416,   156,    10,   439,    62,   522,    10,    42,    11,\n",
       "           456, 10965,     6]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'special_tokens_mask': tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]), 'offset_mapping': tensor([[[ 0,  0],\n",
       "         [ 0,  6],\n",
       "         [ 6, 10],\n",
       "         [10, 11],\n",
       "         [11, 13],\n",
       "         [13, 14],\n",
       "         [14, 16],\n",
       "         [16, 17],\n",
       "         [17, 18],\n",
       "         [18, 19],\n",
       "         [19, 23],\n",
       "         [23, 30],\n",
       "         [ 0,  0]]])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a6445a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    5,  1416,   156,    10,   439,    62,   522,    10,    42,    11,\n",
       "          456, 10965,     6])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "93d2f003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1416, 156, 10, 439, 62, 522, 10, 42, 11, 456, 10965]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i+4 for i in sp.encode(sequence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc530bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens_mask = model_inputs.pop(\"special_tokens_mask\")\n",
    "offset_mapping = model_inputs.pop(\"offset_mapping\", None)\n",
    "#sentence = model_inputs.pop(\"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4aa781ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {k: v.cpu().detach().numpy() for k, v in model_inputs.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cd4f6597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[    5,  1416,   156,    10,   439,    62,   522,    10,    42,\n",
       "            11,   456, 10965,     6]]),\n",
       " 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d79a136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_name = session.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9bef88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = session.run(output_names=[outputs_name], input_feed=inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da2ee8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.tensor(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "16e597ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.3768, -2.0700, -0.5485,  8.1550, -0.4456, -0.2665, -0.9346, -0.1501,\n",
       "        -0.7186, -0.9373, -0.8703, -1.9875, -1.0404,  3.8525, -0.9652, -0.2769,\n",
       "        -2.3533,  0.4932, -1.5370, -1.8904, -1.7153, -2.6149, -1.1447,  1.0322,\n",
       "        -2.3711, -1.1148, -2.1653, -0.1513, -0.9360, -2.0010, -1.8746])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa9d431a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logits[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ff48a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7b974baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='cat-model/sentencepiece.bpe.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9be5ead0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ตอนนี้เวลา 19:18 น. เราจะไปไหน'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "888433c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁ตอนนี้', 'เวลา', '▁', '19', ':', '18', '▁', 'น', '.', '▁เรา', 'จะไปไหน']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.EncodeAsPieces(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a8df7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='./cat-model', vocab_size=25005, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True), 'additional_special_tokens': ['<s>NOTUSED', '</s>NOTUSED', '<_>']})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "50710cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9d04dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tokenizer(sent):\n",
    "    _t = [5]+[i+4 for i in sp.encode(sent)]+[6]\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"input_ids\"]=np.array([_t])\n",
    "    model_inputs[\"attention_mask\"]=np.array([[1]*len(_t)])\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cc3eae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_c=build_tokenizer(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5521bdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[    5,  1416,   156,    10,   439,    62,   522,    10,    42,\n",
       "            11,   456, 10965,     6]]),\n",
       " 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4079eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = session.run(output_names=[outputs_name], input_feed=i_c)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9f99d55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.380878  , -1.6673179 , -1.1982256 ,  6.3787613 , -1.0288123 ,\n",
       "        -0.50097805, -0.47615245, -0.49537125, -0.49321952, -1.1285951 ,\n",
       "        -0.7383426 , -1.1578354 , -2.0872838 ,  5.027358  , -1.4874482 ,\n",
       "         0.23384863, -1.237948  , -0.7719777 , -1.0478671 , -1.7059261 ,\n",
       "        -2.0042663 , -1.7156132 , -1.2701837 ,  4.7759585 , -1.2704831 ,\n",
       "        -0.6026307 , -1.727892  , -0.780291  , -0.6802486 , -1.8957199 ,\n",
       "        -2.2440815 ],\n",
       "       [ 7.331868  , -1.5951151 , -0.9564124 ,  6.9455357 , -0.55916536,\n",
       "        -0.28192207, -1.0282085 ,  0.11319103, -0.35786018, -1.6785506 ,\n",
       "        -0.7617464 , -2.2966197 , -1.8616681 ,  2.5820844 , -0.7152224 ,\n",
       "         0.3366683 , -1.6750131 ,  0.05212411, -1.5421431 , -2.1218092 ,\n",
       "        -1.8217936 , -2.3663418 , -1.1259866 ,  0.8986639 , -1.4895829 ,\n",
       "        -0.6464236 , -2.2468598 , -0.13723528, -1.196146  , -2.0824785 ,\n",
       "        -1.7626154 ],\n",
       "       [ 5.376783  , -2.0700448 , -0.54854214,  8.15497   , -0.4456482 ,\n",
       "        -0.26647317, -0.9345638 , -0.15012181, -0.7185704 , -0.93731856,\n",
       "        -0.8703221 , -1.9874517 , -1.0403717 ,  3.8525398 , -0.9652425 ,\n",
       "        -0.2769364 , -2.3533227 ,  0.49323598, -1.5369811 , -1.8904058 ,\n",
       "        -1.7152803 , -2.6148825 , -1.1447221 ,  1.0321752 , -2.3711128 ,\n",
       "        -1.1148043 , -2.1653476 , -0.15125561, -0.93603957, -2.0009727 ,\n",
       "        -1.8745857 ],\n",
       "       [ 1.9164083 , -1.8736442 , -0.9781924 ,  8.420903  , -1.6121633 ,\n",
       "         1.1253792 ,  1.2116796 , -1.1968373 , -1.4075664 , -0.64640355,\n",
       "        -0.88365936, -1.3199251 , -0.7042167 ,  6.1620665 , -1.0785865 ,\n",
       "        -0.5772833 , -1.8662171 , -0.03420306, -1.033807  , -1.601433  ,\n",
       "        -1.138894  , -1.8964005 , -1.3859005 ,  2.479776  , -1.9556463 ,\n",
       "        -1.2995805 , -1.7345243 , -0.79851514, -1.0440544 , -1.5381807 ,\n",
       "        -1.7296033 ],\n",
       "       [ 1.9416711 , -1.7666177 , -0.924245  ,  8.453953  , -1.3048558 ,\n",
       "         0.9542218 ,  0.7714293 , -1.1286311 , -1.2214624 , -0.6628919 ,\n",
       "        -1.0428431 , -1.3087304 , -0.76701057,  6.15581   , -1.1881791 ,\n",
       "        -0.47369504, -1.8224993 , -0.04040841, -1.040833  , -1.5056229 ,\n",
       "        -1.0941273 , -1.6341345 , -1.5198789 ,  2.488454  , -1.9380355 ,\n",
       "        -1.4495875 , -1.6887585 , -0.77172035, -0.8388442 , -1.4763104 ,\n",
       "        -1.664881  ],\n",
       "       [ 2.0821311 , -1.8893001 , -0.8330621 ,  8.258942  , -1.3438888 ,\n",
       "         0.8249249 ,  0.62733185, -1.2028203 , -1.3330628 , -0.7021507 ,\n",
       "        -1.0375247 , -1.4864517 , -0.848025  ,  6.3170085 , -1.1669021 ,\n",
       "        -0.58629346, -1.5646818 , -0.13398199, -1.1603361 , -1.5374612 ,\n",
       "        -1.2596431 , -1.6131691 , -1.5438249 ,  3.028082  , -1.7618585 ,\n",
       "        -1.5053854 , -1.7453792 , -0.65201366, -0.9946838 , -1.6634067 ,\n",
       "        -1.8379705 ],\n",
       "       [ 1.9176105 , -1.7785168 , -0.80402136,  7.6121593 , -1.5374398 ,\n",
       "         0.8129966 ,  0.7979226 , -1.3816932 , -1.4555702 , -0.7691498 ,\n",
       "        -1.2722207 , -1.3729007 , -1.0271342 ,  7.0540524 , -1.1439577 ,\n",
       "        -0.3623862 , -1.7586217 , -0.04748753, -1.1948661 , -1.6719947 ,\n",
       "        -1.3209978 , -1.7116222 , -1.784367  ,  3.212986  , -1.5623921 ,\n",
       "        -1.374415  , -1.3823254 , -0.90340596, -0.91422033, -1.8202103 ,\n",
       "        -1.945575  ],\n",
       "       [ 1.0566787 , -1.4317635 , -0.89956486,  4.124804  , -1.5455333 ,\n",
       "         0.27162805, -0.17202805, -0.47807816, -1.1433027 , -0.70779306,\n",
       "        -1.6383444 , -1.3525075 , -1.3673964 ,  4.7717876 , -1.6878189 ,\n",
       "        -0.08479076, -1.0361984 , -0.6440682 , -2.3107157 , -2.1534712 ,\n",
       "        -0.5946878 , -0.91744375, -1.2056957 ,  9.099442  , -0.35310614,\n",
       "         1.0037394 , -1.0170884 , -1.869435  , -1.3402505 , -1.1389765 ,\n",
       "        -1.645886  ],\n",
       "       [ 1.2748463 , -1.2145545 , -0.68829614,  4.113945  , -0.4728018 ,\n",
       "         0.39485368, -0.40370739, -0.09428898, -1.1038152 , -0.43224356,\n",
       "        -1.6547105 , -1.7608854 , -1.2081277 ,  3.894517  , -1.7465314 ,\n",
       "        -0.6296344 , -0.89175063, -0.94933933, -2.3720427 , -2.0366044 ,\n",
       "        -0.6107977 , -0.5656523 , -1.5105447 ,  9.681296  , -0.24620202,\n",
       "         0.9180759 , -1.0832999 , -1.3103882 , -1.38974   , -0.7304291 ,\n",
       "        -1.5872214 ],\n",
       "       [ 1.0750562 , -1.1995355 , -0.74915487,  4.045348  , -0.21080373,\n",
       "         0.5599208 , -0.7202819 , -0.30030644, -0.95467484, -0.5747432 ,\n",
       "        -1.3773448 , -1.4484555 , -1.5200272 ,  4.2901626 , -1.752689  ,\n",
       "        -0.8916926 , -1.2036728 , -0.8461107 , -2.3449655 , -1.9690285 ,\n",
       "        -0.743191  , -0.57861775, -0.82870907,  9.696796  , -0.25201297,\n",
       "         1.064112  , -1.2329172 , -1.3523018 , -1.4343036 , -0.8291779 ,\n",
       "        -1.472913  ],\n",
       "       [ 8.456515  , -0.97285867, -1.5567168 ,  0.9409332 , -0.64852405,\n",
       "         0.99727273, -0.12777658,  0.67223537,  1.8199999 , -0.15259743,\n",
       "        -0.1075593 , -2.2517955 , -2.8272083 ,  0.42781532, -2.4603639 ,\n",
       "         0.9598073 , -0.96368307, -1.8167031 , -2.4731717 , -2.673175  ,\n",
       "        -2.7871637 , -2.583661  , -1.2339922 ,  2.1773539 , -0.35796246,\n",
       "         0.95131993, -2.1478286 , -0.81998676, -1.8024311 , -2.3194053 ,\n",
       "        -2.4402523 ],\n",
       "       [ 9.016193  , -0.9175941 , -1.7648035 ,  1.1086183 ,  0.6186468 ,\n",
       "         0.750427  , -0.48407754,  1.2525022 ,  1.9346673 , -0.74836874,\n",
       "        -0.88341707, -2.5226882 , -2.8688214 , -0.3500773 , -1.4256346 ,\n",
       "        -0.41897574, -1.1997833 , -1.7927798 , -1.8347485 , -1.9785439 ,\n",
       "        -3.5390403 , -2.4777572 , -1.3047268 ,  1.7188939 ,  0.1477417 ,\n",
       "         0.32556322, -2.552861  ,  0.17971903, -0.92282057, -1.903106  ,\n",
       "        -2.1611772 ],\n",
       "       [ 4.3808756 , -1.6673177 , -1.1982267 ,  6.3787594 , -1.0288128 ,\n",
       "        -0.5009781 , -0.47615176, -0.4953721 , -0.49321947, -1.1285951 ,\n",
       "        -0.7383415 , -1.1578344 , -2.087283  ,  5.027359  , -1.4874479 ,\n",
       "         0.23384917, -1.2379476 , -0.77197725, -1.0478663 , -1.7059251 ,\n",
       "        -2.004266  , -1.715613  , -1.2701834 ,  4.77596   , -1.2704827 ,\n",
       "        -0.60263014, -1.727891  , -0.78029114, -0.6802489 , -1.8957199 ,\n",
       "        -2.244081  ]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ce8bfc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3787613],\n",
       "       [7.331868 ],\n",
       "       [8.15497  ],\n",
       "       [8.420903 ],\n",
       "       [8.453953 ],\n",
       "       [8.258942 ],\n",
       "       [7.6121593],\n",
       "       [9.099442 ],\n",
       "       [9.681296 ],\n",
       "       [9.696796 ],\n",
       "       [8.456515 ],\n",
       "       [9.016193 ],\n",
       "       [6.3787594]], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(logits[0], axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1806a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(logits_data):\n",
    "    logits_t = logits_data[0]\n",
    "    maxes = np.max(logits_t, axis=-1, keepdims=True)\n",
    "    shifted_exp = np.exp(logits_t - maxes)\n",
    "    scores = shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "28b0164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2tag={\n",
    "    \"0\": \"O\",\n",
    "    \"1\": \"B_BRN\",\n",
    "    \"2\": \"B_DES\",\n",
    "    \"3\": \"B_DTM\",\n",
    "    \"4\": \"B_LOC\",\n",
    "    \"5\": \"B_MEA\",\n",
    "    \"6\": \"B_NUM\",\n",
    "    \"7\": \"B_ORG\",\n",
    "    \"8\": \"B_PER\",\n",
    "    \"9\": \"B_TRM\",\n",
    "    \"10\": \"B_TTL\",\n",
    "    \"11\": \"I_BRN\",\n",
    "    \"12\": \"I_DES\",\n",
    "    \"13\": \"I_DTM\",\n",
    "    \"14\": \"I_LOC\",\n",
    "    \"15\": \"I_MEA\",\n",
    "    \"16\": \"I_NUM\",\n",
    "    \"17\": \"I_ORG\",\n",
    "    \"18\": \"I_PER\",\n",
    "    \"19\": \"I_TRM\",\n",
    "    \"20\": \"I_TTL\",\n",
    "    \"21\": \"E_BRN\",\n",
    "    \"22\": \"E_DES\",\n",
    "    \"23\": \"E_DTM\",\n",
    "    \"24\": \"E_LOC\",\n",
    "    \"25\": \"E_MEA\",\n",
    "    \"26\": \"E_NUM\",\n",
    "    \"27\": \"E_ORG\",\n",
    "    \"28\": \"E_PER\",\n",
    "    \"29\": \"E_TRM\",\n",
    "    \"30\": \"E_TTL\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "84d7cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def totag(post,sent):\n",
    "    tag= []\n",
    "    _s=sp.EncodeAsPieces(sent)\n",
    "    for i in range(len(_s)):\n",
    "        tag.append(\n",
    "            (\n",
    "                _s[i],\n",
    "                id2tag[str(list(post[i+1]).index(max(list(post[i+1]))))]\n",
    "            )\n",
    "        )\n",
    "    return tag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1bd7b25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁ตอนนี้', 'O'),\n",
       " ('เวลา', 'B_DTM'),\n",
       " ('▁', 'B_DTM'),\n",
       " ('19', 'B_DTM'),\n",
       " (':', 'B_DTM'),\n",
       " ('18', 'B_DTM'),\n",
       " ('▁', 'E_DTM'),\n",
       " ('น', 'E_DTM'),\n",
       " ('.', 'E_DTM'),\n",
       " ('▁เรา', 'O'),\n",
       " ('จะไปไหน', 'O')]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totag(postprocess(logits),sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4cb47204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(sent):\n",
    "    _s=build_tokenizer(sent)\n",
    "    logits = session.run(output_names=[outputs_name], input_feed=_s)[0]\n",
    "    return totag(postprocess(logits),sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "18134a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁', 'O'),\n",
       " ('เมื่อไร', 'O'),\n",
       " ('จะ', 'O'),\n",
       " ('เวลา', 'B_DTM'),\n",
       " ('▁', 'B_DTM'),\n",
       " ('11', 'B_DTM'),\n",
       " (':00', 'B_DTM'),\n",
       " ('▁', 'E_DTM'),\n",
       " ('น', 'E_DTM'),\n",
       " ('.', 'E_DTM'),\n",
       " ('▁เราจะ', 'O'),\n",
       " ('ไปทําอะไร', 'O'),\n",
       " ('ที่', 'O'),\n",
       " ('โร', 'O'),\n",
       " ('เรียน', 'O'),\n",
       " ('อําเภอ', 'O'),\n",
       " ('นาง', 'O'),\n",
       " ('รอง', 'O'),\n",
       " ('▁', 'O'),\n",
       " ('จังหวัด', 'O'),\n",
       " ('บุรีรัมย์', 'O')]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"เมื่อไรจะเวลา 11:00 น. เราจะไปทำอะไรที่โรเรียนอำเภอนางรอง จังหวัดบุรีรัมย์\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7fa37445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(postprocess(logits)[1]).index(list(postprocess(logits))[1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e531403e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86657107"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(postprocess(logits)[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3bded460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6273591"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(postprocess(logits)[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "15a28e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0021105963,\n",
       " 5.2383824e-05,\n",
       " 0.00013880829,\n",
       " 0.6273591,\n",
       " 6.666468e-05,\n",
       " 0.00069932215,\n",
       " 0.0006888598,\n",
       " 7.789968e-05,\n",
       " 7.235209e-05,\n",
       " 0.00014373407,\n",
       " 8.691182e-05,\n",
       " 7.858766e-05,\n",
       " 0.00011105001,\n",
       " 0.35903227,\n",
       " 9.880592e-05,\n",
       " 0.00021588136,\n",
       " 5.343647e-05,\n",
       " 0.0002957834,\n",
       " 9.390179e-05,\n",
       " 5.8271926e-05,\n",
       " 8.277429e-05,\n",
       " 5.6007877e-05,\n",
       " 5.2078285e-05,\n",
       " 0.007708671,\n",
       " 6.502185e-05,\n",
       " 7.846872e-05,\n",
       " 7.785043e-05,\n",
       " 0.00012567629,\n",
       " 0.00012432446,\n",
       " 5.0244704e-05,\n",
       " 4.43246e-05]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(postprocess(logits)[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0304651d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(postprocess(logits)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffae8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
